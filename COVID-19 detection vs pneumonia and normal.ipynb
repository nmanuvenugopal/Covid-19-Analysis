{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from os.path import isdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(filename, required_size=(200, 200)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    image = image.resize(required_size)\n",
    "    pixels = asarray(image, dtype=np.float32)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        img = extract_images(path)\n",
    "        # store\n",
    "        images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):\n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_images(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 100 examples for class: PNEUMONIA\n",
      ">loaded 100 examples for class: NORMAL\n",
      ">loaded 94 examples for class: Covid\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset('xray_dataset_covid19/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "trainy = le.fit_transform(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 200, 200, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainy, testy = train_test_split(trainX, trainy, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((147, 200, 200, 3), (147,), (147, 200, 200, 3), (147,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainy.shape,testX.shape,testy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "\n",
    "Now that we've gotten our feet we with a simple DNN, let's try something more advanced. Although the process is the same, we'll be working with some additional features:\n",
    "- Convolution, pooling, and dropout layers for building more complex models\n",
    "- Visualizing training with TensorBoard\n",
    "- Validation and test set evaluation for measuring generalizability\n",
    "- Exporting with SavedModel to save training progress and deploy trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = tf.keras.Sequential([\n",
    "    layers.Reshape(\n",
    "        target_shape=[200, 200, 3],\n",
    "        input_shape=(200, 200,3)),\n",
    "    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation=tf.nn.relu),\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dropout(rate=0.4),\n",
    "    layers.Dense(3)])\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, images, labels):\n",
    "\n",
    "    # Record the operations used to compute the loss, so that the gradient\n",
    "    # of the loss with respect to the variables can be computed.\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(images, training=True)\n",
    "        loss = compute_loss(labels, logits)\n",
    "        compute_accuracy(labels, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataset, log_freq=50):\n",
    "    \"\"\"\n",
    "    Trains model on `dataset` using `optimizer`.\n",
    "    \"\"\"\n",
    "    # Metrics are stateful. They accumulate values and return a cumulative\n",
    "    # result when you call .result(). Clear accumulated values with .reset_states()\n",
    "    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "    # Datasets can be iterated over like any other Python iterable.\n",
    "    for images, labels in dataset:\n",
    "        loss = train_step(model, optimizer, images, labels)\n",
    "        avg_loss(loss)\n",
    "\n",
    "        if tf.equal(optimizer.iterations % log_freq, 0):\n",
    "            # summary_ops_v2.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
    "            # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=optimizer.iterations)\n",
    "            print('step:', int(optimizer.iterations),\n",
    "                  'loss:', avg_loss.result().numpy(),\n",
    "                  'acc:', compute_accuracy.result().numpy())\n",
    "            avg_loss.reset_states()\n",
    "            compute_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, step_num):\n",
    "    \"\"\"\n",
    "    Perform an evaluation of `model` on the examples from `dataset`.\n",
    "    \"\"\"\n",
    "    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "    for (images, labels) in dataset:\n",
    "        logits = model(images, training=False)\n",
    "        avg_loss(compute_loss(labels, logits))\n",
    "        compute_accuracy(labels, logits)\n",
    "\n",
    "    print('Model test set loss: {:0.4f} accuracy: {:0.2f}%'.format(\n",
    "        avg_loss.result(), compute_accuracy.result() * 100))\n",
    "\n",
    "    print('loss:', avg_loss.result(), 'acc:', compute_accuracy.result())\n",
    "    # summary_ops_v2.scalar('loss', avg_loss.result(), step=step_num)\n",
    "    # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=step_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #1 (2 total steps): 3.8560259342193604\n",
      "Model test set loss: 1.0904 accuracy: 36.39%\n",
      "loss: tf.Tensor(1.0904262, shape=(), dtype=float32) acc: tf.Tensor(0.36394557, shape=(), dtype=float32)\n",
      "Train time for epoch #2 (4 total steps): 4.786633014678955\n",
      "Model test set loss: 1.0809 accuracy: 34.69%\n",
      "loss: tf.Tensor(1.0808611, shape=(), dtype=float32) acc: tf.Tensor(0.3469388, shape=(), dtype=float32)\n",
      "Train time for epoch #3 (6 total steps): 4.103327989578247\n",
      "Model test set loss: 1.0580 accuracy: 37.07%\n",
      "loss: tf.Tensor(1.0580037, shape=(), dtype=float32) acc: tf.Tensor(0.3707483, shape=(), dtype=float32)\n",
      "Train time for epoch #4 (8 total steps): 5.34101414680481\n",
      "Model test set loss: 1.0442 accuracy: 39.03%\n",
      "loss: tf.Tensor(1.0441842, shape=(), dtype=float32) acc: tf.Tensor(0.39030612, shape=(), dtype=float32)\n",
      "Train time for epoch #5 (10 total steps): 4.284988164901733\n",
      "Model test set loss: 1.0232 accuracy: 41.22%\n",
      "loss: tf.Tensor(1.0231919, shape=(), dtype=float32) acc: tf.Tensor(0.4122449, shape=(), dtype=float32)\n",
      "Train time for epoch #6 (12 total steps): 5.910924196243286\n",
      "Model test set loss: 0.9876 accuracy: 44.05%\n",
      "loss: tf.Tensor(0.9876071, shape=(), dtype=float32) acc: tf.Tensor(0.44047618, shape=(), dtype=float32)\n",
      "Train time for epoch #7 (14 total steps): 4.244980812072754\n",
      "Model test set loss: 0.9022 accuracy: 47.08%\n",
      "loss: tf.Tensor(0.90219635, shape=(), dtype=float32) acc: tf.Tensor(0.4708455, shape=(), dtype=float32)\n",
      "Train time for epoch #8 (16 total steps): 4.224592924118042\n",
      "Model test set loss: 0.9202 accuracy: 49.11%\n",
      "loss: tf.Tensor(0.9202407, shape=(), dtype=float32) acc: tf.Tensor(0.49107143, shape=(), dtype=float32)\n",
      "Train time for epoch #9 (18 total steps): 4.049444913864136\n",
      "Model test set loss: 1.3447 accuracy: 49.55%\n",
      "loss: tf.Tensor(1.3446777, shape=(), dtype=float32) acc: tf.Tensor(0.49546486, shape=(), dtype=float32)\n",
      "Train time for epoch #10 (20 total steps): 3.982901096343994\n",
      "Model test set loss: 1.1206 accuracy: 48.61%\n",
      "loss: tf.Tensor(1.12055, shape=(), dtype=float32) acc: tf.Tensor(0.48605442, shape=(), dtype=float32)\n",
      "Train time for epoch #11 (22 total steps): 3.982640266418457\n",
      "Model test set loss: 1.0898 accuracy: 47.59%\n",
      "loss: tf.Tensor(1.0897814, shape=(), dtype=float32) acc: tf.Tensor(0.47588125, shape=(), dtype=float32)\n",
      "Train time for epoch #12 (24 total steps): 3.99100399017334\n",
      "Model test set loss: 1.0640 accuracy: 47.00%\n",
      "loss: tf.Tensor(1.0640198, shape=(), dtype=float32) acc: tf.Tensor(0.46995464, shape=(), dtype=float32)\n",
      "Train time for epoch #13 (26 total steps): 3.940232992172241\n",
      "Model test set loss: 1.0397 accuracy: 47.15%\n",
      "loss: tf.Tensor(1.0396857, shape=(), dtype=float32) acc: tf.Tensor(0.4714809, shape=(), dtype=float32)\n",
      "Train time for epoch #14 (28 total steps): 3.9670488834381104\n",
      "Model test set loss: 1.0161 accuracy: 47.59%\n",
      "loss: tf.Tensor(1.0161238, shape=(), dtype=float32) acc: tf.Tensor(0.47594753, shape=(), dtype=float32)\n",
      "Train time for epoch #15 (30 total steps): 3.9554193019866943\n",
      "Model test set loss: 0.9885 accuracy: 48.14%\n",
      "loss: tf.Tensor(0.98845357, shape=(), dtype=float32) acc: tf.Tensor(0.48140588, shape=(), dtype=float32)\n",
      "Train time for epoch #16 (32 total steps): 3.927157163619995\n",
      "Model test set loss: 0.9597 accuracy: 48.72%\n",
      "loss: tf.Tensor(0.9597353, shape=(), dtype=float32) acc: tf.Tensor(0.4872449, shape=(), dtype=float32)\n",
      "Train time for epoch #17 (34 total steps): 3.989849090576172\n",
      "Model test set loss: 0.8985 accuracy: 49.62%\n",
      "loss: tf.Tensor(0.8985301, shape=(), dtype=float32) acc: tf.Tensor(0.49619848, shape=(), dtype=float32)\n",
      "Train time for epoch #18 (36 total steps): 3.9623301029205322\n",
      "Model test set loss: 0.8605 accuracy: 50.70%\n",
      "loss: tf.Tensor(0.8605491, shape=(), dtype=float32) acc: tf.Tensor(0.5069917, shape=(), dtype=float32)\n",
      "Train time for epoch #19 (38 total steps): 3.9169769287109375\n",
      "Model test set loss: 0.8627 accuracy: 51.49%\n",
      "loss: tf.Tensor(0.8626778, shape=(), dtype=float32) acc: tf.Tensor(0.5148586, shape=(), dtype=float32)\n",
      "Train time for epoch #20 (40 total steps): 3.9528679847717285\n",
      "Model test set loss: 0.7977 accuracy: 52.40%\n",
      "loss: tf.Tensor(0.7977489, shape=(), dtype=float32) acc: tf.Tensor(0.5239796, shape=(), dtype=float32)\n",
      "Train time for epoch #21 (42 total steps): 3.935405969619751\n",
      "Model test set loss: 0.7824 accuracy: 53.32%\n",
      "loss: tf.Tensor(0.7824359, shape=(), dtype=float32) acc: tf.Tensor(0.5332038, shape=(), dtype=float32)\n",
      "Train time for epoch #22 (44 total steps): 3.8979830741882324\n",
      "Model test set loss: 0.7984 accuracy: 54.25%\n",
      "loss: tf.Tensor(0.79841304, shape=(), dtype=float32) acc: tf.Tensor(0.542517, shape=(), dtype=float32)\n",
      "Train time for epoch #23 (46 total steps): 3.894605875015259\n",
      "Model test set loss: 0.7494 accuracy: 55.19%\n",
      "loss: tf.Tensor(0.7494266, shape=(), dtype=float32) acc: tf.Tensor(0.5519077, shape=(), dtype=float32)\n",
      "Train time for epoch #24 (48 total steps): 4.409371852874756\n",
      "Model test set loss: 0.8076 accuracy: 55.97%\n",
      "loss: tf.Tensor(0.807634, shape=(), dtype=float32) acc: tf.Tensor(0.55966556, shape=(), dtype=float32)\n",
      "Train time for epoch #25 (50 total steps): 3.9181697368621826\n",
      "Model test set loss: 0.7141 accuracy: 56.69%\n",
      "loss: tf.Tensor(0.71407235, shape=(), dtype=float32) acc: tf.Tensor(0.56693876, shape=(), dtype=float32)\n",
      "Train time for epoch #26 (52 total steps): 3.965066909790039\n",
      "Model test set loss: 0.7623 accuracy: 57.26%\n",
      "loss: tf.Tensor(0.76232827, shape=(), dtype=float32) acc: tf.Tensor(0.57260597, shape=(), dtype=float32)\n",
      "Train time for epoch #27 (54 total steps): 3.896637201309204\n",
      "Model test set loss: 0.6508 accuracy: 57.96%\n",
      "loss: tf.Tensor(0.650803, shape=(), dtype=float32) acc: tf.Tensor(0.579617, shape=(), dtype=float32)\n",
      "Train time for epoch #28 (56 total steps): 3.9046199321746826\n",
      "Model test set loss: 0.8872 accuracy: 58.54%\n",
      "loss: tf.Tensor(0.88716006, shape=(), dtype=float32) acc: tf.Tensor(0.58539844, shape=(), dtype=float32)\n",
      "Train time for epoch #29 (58 total steps): 3.9428670406341553\n",
      "Model test set loss: 1.3881 accuracy: 58.77%\n",
      "loss: tf.Tensor(1.3881265, shape=(), dtype=float32) acc: tf.Tensor(0.58773166, shape=(), dtype=float32)\n",
      "Train time for epoch #30 (60 total steps): 4.035186052322388\n",
      "Model test set loss: 1.0012 accuracy: 58.58%\n",
      "loss: tf.Tensor(1.0011874, shape=(), dtype=float32) acc: tf.Tensor(0.58582765, shape=(), dtype=float32)\n",
      "Train time for epoch #31 (62 total steps): 3.8861618041992188\n",
      "Model test set loss: 1.0164 accuracy: 58.29%\n",
      "loss: tf.Tensor(1.0164305, shape=(), dtype=float32) acc: tf.Tensor(0.5829493, shape=(), dtype=float32)\n",
      "Train time for epoch #32 (64 total steps): 3.921977996826172\n",
      "Model test set loss: 0.9967 accuracy: 57.95%\n",
      "loss: tf.Tensor(0.99667674, shape=(), dtype=float32) acc: tf.Tensor(0.5795068, shape=(), dtype=float32)\n",
      "Train time for epoch #33 (66 total steps): 3.8961212635040283\n",
      "Model test set loss: 0.9711 accuracy: 57.73%\n",
      "loss: tf.Tensor(0.97105277, shape=(), dtype=float32) acc: tf.Tensor(0.57730365, shape=(), dtype=float32)\n",
      "Train time for epoch #34 (68 total steps): 3.8508570194244385\n",
      "Model test set loss: 0.9435 accuracy: 57.62%\n",
      "loss: tf.Tensor(0.94349754, shape=(), dtype=float32) acc: tf.Tensor(0.57623047, shape=(), dtype=float32)\n",
      "Train time for epoch #35 (70 total steps): 3.9472179412841797\n",
      "Model test set loss: 0.9141 accuracy: 57.55%\n",
      "loss: tf.Tensor(0.9140769, shape=(), dtype=float32) acc: tf.Tensor(0.5755102, shape=(), dtype=float32)\n",
      "Train time for epoch #36 (72 total steps): 3.8715970516204834\n",
      "Model test set loss: 0.8844 accuracy: 57.59%\n",
      "loss: tf.Tensor(0.8844385, shape=(), dtype=float32) acc: tf.Tensor(0.57586926, shape=(), dtype=float32)\n",
      "Train time for epoch #37 (74 total steps): 3.8822591304779053\n",
      "Model test set loss: 0.8558 accuracy: 57.62%\n",
      "loss: tf.Tensor(0.85580975, shape=(), dtype=float32) acc: tf.Tensor(0.5762089, shape=(), dtype=float32)\n",
      "Train time for epoch #38 (76 total steps): 3.9597721099853516\n",
      "Model test set loss: 0.8332 accuracy: 57.71%\n",
      "loss: tf.Tensor(0.8331591, shape=(), dtype=float32) acc: tf.Tensor(0.5770677, shape=(), dtype=float32)\n",
      "Train time for epoch #39 (78 total steps): 3.862931966781616\n",
      "Model test set loss: 0.8173 accuracy: 57.85%\n",
      "loss: tf.Tensor(0.8172656, shape=(), dtype=float32) acc: tf.Tensor(0.57849294, shape=(), dtype=float32)\n",
      "Train time for epoch #40 (80 total steps): 3.871903896331787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 0.8014 accuracy: 57.96%\n",
      "loss: tf.Tensor(0.8014352, shape=(), dtype=float32) acc: tf.Tensor(0.5795918, shape=(), dtype=float32)\n",
      "Train time for epoch #41 (82 total steps): 3.8710761070251465\n",
      "Model test set loss: 0.7914 accuracy: 58.11%\n",
      "loss: tf.Tensor(0.7913521, shape=(), dtype=float32) acc: tf.Tensor(0.5811349, shape=(), dtype=float32)\n",
      "Train time for epoch #42 (84 total steps): 3.887695789337158\n",
      "Model test set loss: 0.8063 accuracy: 58.28%\n",
      "loss: tf.Tensor(0.80628335, shape=(), dtype=float32) acc: tf.Tensor(0.5827664, shape=(), dtype=float32)\n",
      "Train time for epoch #43 (86 total steps): 3.8976988792419434\n",
      "Model test set loss: 0.8095 accuracy: 58.44%\n",
      "loss: tf.Tensor(0.8094934, shape=(), dtype=float32) acc: tf.Tensor(0.5844012, shape=(), dtype=float32)\n",
      "Train time for epoch #44 (88 total steps): 3.9059619903564453\n",
      "Model test set loss: 0.9064 accuracy: 58.60%\n",
      "loss: tf.Tensor(0.9064321, shape=(), dtype=float32) acc: tf.Tensor(0.58596164, shape=(), dtype=float32)\n",
      "Train time for epoch #45 (90 total steps): 4.90256404876709\n",
      "Model test set loss: 0.7563 accuracy: 58.87%\n",
      "loss: tf.Tensor(0.7562558, shape=(), dtype=float32) acc: tf.Tensor(0.58866215, shape=(), dtype=float32)\n",
      "Train time for epoch #46 (92 total steps): 4.9339988231658936\n",
      "Model test set loss: 0.7748 accuracy: 59.15%\n",
      "loss: tf.Tensor(0.7747685, shape=(), dtype=float32) acc: tf.Tensor(0.591541, shape=(), dtype=float32)\n",
      "Train time for epoch #47 (94 total steps): 4.883835077285767\n",
      "Model test set loss: 0.8075 accuracy: 59.44%\n",
      "loss: tf.Tensor(0.80750996, shape=(), dtype=float32) acc: tf.Tensor(0.59436965, shape=(), dtype=float32)\n",
      "Train time for epoch #48 (96 total steps): 4.98014497756958\n",
      "Model test set loss: 0.7539 accuracy: 59.74%\n",
      "loss: tf.Tensor(0.753868, shape=(), dtype=float32) acc: tf.Tensor(0.59736395, shape=(), dtype=float32)\n",
      "Train time for epoch #49 (98 total steps): 4.741237640380859\n",
      "Model test set loss: 0.7516 accuracy: 60.04%\n",
      "loss: tf.Tensor(0.75164706, shape=(), dtype=float32) acc: tf.Tensor(0.6003748, shape=(), dtype=float32)\n",
      "Train time for epoch #50 (100 total steps): 3.9263062477111816\n",
      "Model test set loss: 0.7512 accuracy: 60.36%\n",
      "loss: tf.Tensor(0.7512489, shape=(), dtype=float32) acc: tf.Tensor(0.60360545, shape=(), dtype=float32)\n",
      "Train time for epoch #51 (102 total steps): 3.87817120552063\n",
      "Model test set loss: 0.8030 accuracy: 60.66%\n",
      "loss: tf.Tensor(0.80302393, shape=(), dtype=float32) acc: tf.Tensor(0.60657597, shape=(), dtype=float32)\n",
      "Train time for epoch #52 (104 total steps): 3.9210102558135986\n",
      "Model test set loss: 0.7208 accuracy: 60.98%\n",
      "loss: tf.Tensor(0.7207603, shape=(), dtype=float32) acc: tf.Tensor(0.6097593, shape=(), dtype=float32)\n",
      "Train time for epoch #53 (106 total steps): 3.988875150680542\n",
      "Model test set loss: 0.8230 accuracy: 61.23%\n",
      "loss: tf.Tensor(0.8230451, shape=(), dtype=float32) acc: tf.Tensor(0.6123091, shape=(), dtype=float32)\n",
      "Train time for epoch #54 (108 total steps): 3.913098096847534\n",
      "Model test set loss: 0.7041 accuracy: 61.51%\n",
      "loss: tf.Tensor(0.7040664, shape=(), dtype=float32) acc: tf.Tensor(0.61514235, shape=(), dtype=float32)\n",
      "Train time for epoch #55 (110 total steps): 3.898181200027466\n",
      "Model test set loss: 0.7738 accuracy: 61.79%\n",
      "loss: tf.Tensor(0.77380955, shape=(), dtype=float32) acc: tf.Tensor(0.61793447, shape=(), dtype=float32)\n",
      "Train time for epoch #56 (112 total steps): 3.878404140472412\n",
      "Model test set loss: 0.7097 accuracy: 62.08%\n",
      "loss: tf.Tensor(0.7096854, shape=(), dtype=float32) acc: tf.Tensor(0.620809, shape=(), dtype=float32)\n",
      "Train time for epoch #57 (114 total steps): 3.8482351303100586\n",
      "Model test set loss: 0.8166 accuracy: 62.36%\n",
      "loss: tf.Tensor(0.81664336, shape=(), dtype=float32) acc: tf.Tensor(0.62364244, shape=(), dtype=float32)\n",
      "Train time for epoch #58 (116 total steps): 3.840155839920044\n",
      "Model test set loss: 0.6802 accuracy: 62.66%\n",
      "loss: tf.Tensor(0.6802192, shape=(), dtype=float32) acc: tf.Tensor(0.6265541, shape=(), dtype=float32)\n",
      "Train time for epoch #59 (118 total steps): 3.8799221515655518\n",
      "Model test set loss: 0.7544 accuracy: 62.90%\n",
      "loss: tf.Tensor(0.7544397, shape=(), dtype=float32) acc: tf.Tensor(0.6289635, shape=(), dtype=float32)\n",
      "Train time for epoch #60 (120 total steps): 3.880549907684326\n",
      "Model test set loss: 0.6819 accuracy: 63.21%\n",
      "loss: tf.Tensor(0.68190897, shape=(), dtype=float32) acc: tf.Tensor(0.63208616, shape=(), dtype=float32)\n",
      "Train time for epoch #61 (122 total steps): 3.8936901092529297\n",
      "Model test set loss: 0.7323 accuracy: 63.54%\n",
      "loss: tf.Tensor(0.73228604, shape=(), dtype=float32) acc: tf.Tensor(0.63544106, shape=(), dtype=float32)\n",
      "Train time for epoch #62 (124 total steps): 3.9066429138183594\n",
      "Model test set loss: 0.9238 accuracy: 63.81%\n",
      "loss: tf.Tensor(0.923772, shape=(), dtype=float32) acc: tf.Tensor(0.6381391, shape=(), dtype=float32)\n",
      "Train time for epoch #63 (126 total steps): 3.874453067779541\n",
      "Model test set loss: 0.6932 accuracy: 64.12%\n",
      "loss: tf.Tensor(0.69324785, shape=(), dtype=float32) acc: tf.Tensor(0.64118344, shape=(), dtype=float32)\n",
      "Train time for epoch #64 (128 total steps): 3.860427141189575\n",
      "Model test set loss: 0.9971 accuracy: 64.39%\n",
      "loss: tf.Tensor(0.99706113, shape=(), dtype=float32) acc: tf.Tensor(0.64392006, shape=(), dtype=float32)\n",
      "Train time for epoch #65 (130 total steps): 3.9478237628936768\n",
      "Model test set loss: 0.6653 accuracy: 64.67%\n",
      "loss: tf.Tensor(0.665341, shape=(), dtype=float32) acc: tf.Tensor(0.64672947, shape=(), dtype=float32)\n",
      "Train time for epoch #66 (132 total steps): 3.8662290573120117\n",
      "Model test set loss: 0.7649 accuracy: 64.95%\n",
      "loss: tf.Tensor(0.7649369, shape=(), dtype=float32) acc: tf.Tensor(0.6494537, shape=(), dtype=float32)\n",
      "Train time for epoch #67 (134 total steps): 3.896559238433838\n",
      "Model test set loss: 1.0477 accuracy: 65.10%\n",
      "loss: tf.Tensor(1.0477391, shape=(), dtype=float32) acc: tf.Tensor(0.65103054, shape=(), dtype=float32)\n",
      "Train time for epoch #68 (136 total steps): 3.8936359882354736\n",
      "Model test set loss: 0.6802 accuracy: 65.37%\n",
      "loss: tf.Tensor(0.68021256, shape=(), dtype=float32) acc: tf.Tensor(0.6536615, shape=(), dtype=float32)\n",
      "Train time for epoch #69 (138 total steps): 3.9068689346313477\n",
      "Model test set loss: 0.9311 accuracy: 65.60%\n",
      "loss: tf.Tensor(0.93113345, shape=(), dtype=float32) acc: tf.Tensor(0.6560189, shape=(), dtype=float32)\n",
      "Train time for epoch #70 (140 total steps): 3.8652639389038086\n",
      "Model test set loss: 0.7409 accuracy: 65.87%\n",
      "loss: tf.Tensor(0.7409289, shape=(), dtype=float32) acc: tf.Tensor(0.65874636, shape=(), dtype=float32)\n",
      "Train time for epoch #71 (142 total steps): 3.9285173416137695\n",
      "Model test set loss: 1.0917 accuracy: 66.09%\n",
      "loss: tf.Tensor(1.0916644, shape=(), dtype=float32) acc: tf.Tensor(0.6609179, shape=(), dtype=float32)\n",
      "Train time for epoch #72 (144 total steps): 3.8966808319091797\n",
      "Model test set loss: 0.8813 accuracy: 66.35%\n",
      "loss: tf.Tensor(0.8812846, shape=(), dtype=float32) acc: tf.Tensor(0.6634543, shape=(), dtype=float32)\n",
      "Train time for epoch #73 (146 total steps): 3.9191911220550537\n",
      "Model test set loss: 0.7711 accuracy: 66.56%\n",
      "loss: tf.Tensor(0.77106255, shape=(), dtype=float32) acc: tf.Tensor(0.6656416, shape=(), dtype=float32)\n",
      "Train time for epoch #74 (148 total steps): 3.9227499961853027\n",
      "Model test set loss: 0.9644 accuracy: 66.74%\n",
      "loss: tf.Tensor(0.964378, shape=(), dtype=float32) acc: tf.Tensor(0.66735613, shape=(), dtype=float32)\n",
      "Train time for epoch #75 (150 total steps): 3.8278329372406006\n",
      "Model test set loss: 0.6969 accuracy: 66.94%\n",
      "loss: tf.Tensor(0.6969283, shape=(), dtype=float32) acc: tf.Tensor(0.66938776, shape=(), dtype=float32)\n",
      "Train time for epoch #76 (152 total steps): 3.848755121231079\n",
      "Model test set loss: 1.0303 accuracy: 67.09%\n",
      "loss: tf.Tensor(1.0303198, shape=(), dtype=float32) acc: tf.Tensor(0.67091835, shape=(), dtype=float32)\n",
      "Train time for epoch #77 (154 total steps): 3.8826382160186768\n",
      "Model test set loss: 0.7211 accuracy: 67.32%\n",
      "loss: tf.Tensor(0.72107446, shape=(), dtype=float32) acc: tf.Tensor(0.6732485, shape=(), dtype=float32)\n",
      "Train time for epoch #78 (156 total steps): 4.0951011180877686\n",
      "Model test set loss: 0.8340 accuracy: 67.54%\n",
      "loss: tf.Tensor(0.8339939, shape=(), dtype=float32) acc: tf.Tensor(0.6753881, shape=(), dtype=float32)\n",
      "Train time for epoch #79 (158 total steps): 5.782536268234253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 0.8472 accuracy: 67.77%\n",
      "loss: tf.Tensor(0.8471523, shape=(), dtype=float32) acc: tf.Tensor(0.6777319, shape=(), dtype=float32)\n",
      "Train time for epoch #80 (160 total steps): 3.984592914581299\n",
      "Model test set loss: 0.9174 accuracy: 68.00%\n",
      "loss: tf.Tensor(0.9173987, shape=(), dtype=float32) acc: tf.Tensor(0.680017, shape=(), dtype=float32)\n",
      "Train time for epoch #81 (162 total steps): 3.993367910385132\n",
      "Model test set loss: 0.8994 accuracy: 68.22%\n",
      "loss: tf.Tensor(0.89937246, shape=(), dtype=float32) acc: tf.Tensor(0.68216175, shape=(), dtype=float32)\n",
      "Train time for epoch #82 (164 total steps): 4.039628744125366\n",
      "Model test set loss: 0.8791 accuracy: 68.40%\n",
      "loss: tf.Tensor(0.8791445, shape=(), dtype=float32) acc: tf.Tensor(0.6840053, shape=(), dtype=float32)\n",
      "Train time for epoch #83 (166 total steps): 4.230347156524658\n",
      "Model test set loss: 0.7969 accuracy: 68.60%\n",
      "loss: tf.Tensor(0.79693246, shape=(), dtype=float32) acc: tf.Tensor(0.68600935, shape=(), dtype=float32)\n",
      "Train time for epoch #84 (168 total steps): 3.9593863487243652\n",
      "Model test set loss: 0.7362 accuracy: 68.85%\n",
      "loss: tf.Tensor(0.73615086, shape=(), dtype=float32) acc: tf.Tensor(0.68849206, shape=(), dtype=float32)\n",
      "Train time for epoch #85 (170 total steps): 3.8934128284454346\n",
      "Model test set loss: 1.0655 accuracy: 69.02%\n",
      "loss: tf.Tensor(1.0655355, shape=(), dtype=float32) acc: tf.Tensor(0.6902361, shape=(), dtype=float32)\n",
      "Train time for epoch #86 (172 total steps): 3.920245885848999\n",
      "Model test set loss: 0.8595 accuracy: 69.23%\n",
      "loss: tf.Tensor(0.8595084, shape=(), dtype=float32) acc: tf.Tensor(0.69233507, shape=(), dtype=float32)\n",
      "Train time for epoch #87 (174 total steps): 3.8645811080932617\n",
      "Model test set loss: 0.8475 accuracy: 69.45%\n",
      "loss: tf.Tensor(0.8475492, shape=(), dtype=float32) acc: tf.Tensor(0.69450307, shape=(), dtype=float32)\n",
      "Train time for epoch #88 (176 total steps): 3.9163599014282227\n",
      "Model test set loss: 0.8614 accuracy: 69.66%\n",
      "loss: tf.Tensor(0.8613763, shape=(), dtype=float32) acc: tf.Tensor(0.69662184, shape=(), dtype=float32)\n",
      "Train time for epoch #89 (178 total steps): 3.892256021499634\n",
      "Model test set loss: 0.9912 accuracy: 69.85%\n",
      "loss: tf.Tensor(0.9912057, shape=(), dtype=float32) acc: tf.Tensor(0.6985401, shape=(), dtype=float32)\n",
      "Train time for epoch #90 (180 total steps): 3.8624091148376465\n",
      "Model test set loss: 1.0275 accuracy: 70.06%\n",
      "loss: tf.Tensor(1.0274578, shape=(), dtype=float32) acc: tf.Tensor(0.7005669, shape=(), dtype=float32)\n",
      "Train time for epoch #91 (182 total steps): 3.871717929840088\n",
      "Model test set loss: 0.8984 accuracy: 70.27%\n",
      "loss: tf.Tensor(0.8984463, shape=(), dtype=float32) acc: tf.Tensor(0.70269865, shape=(), dtype=float32)\n",
      "Train time for epoch #92 (184 total steps): 3.8835809230804443\n",
      "Model test set loss: 1.4813 accuracy: 70.40%\n",
      "loss: tf.Tensor(1.4812845, shape=(), dtype=float32) acc: tf.Tensor(0.7040077, shape=(), dtype=float32)\n",
      "Train time for epoch #93 (186 total steps): 3.8965938091278076\n",
      "Model test set loss: 2.1396 accuracy: 70.35%\n",
      "loss: tf.Tensor(2.139617, shape=(), dtype=float32) acc: tf.Tensor(0.70345986, shape=(), dtype=float32)\n",
      "Train time for epoch #94 (188 total steps): 3.8968586921691895\n",
      "Model test set loss: 0.8073 accuracy: 70.33%\n",
      "loss: tf.Tensor(0.8073054, shape=(), dtype=float32) acc: tf.Tensor(0.70332175, shape=(), dtype=float32)\n",
      "Train time for epoch #95 (190 total steps): 3.9118850231170654\n",
      "Model test set loss: 0.7805 accuracy: 70.35%\n",
      "loss: tf.Tensor(0.7805381, shape=(), dtype=float32) acc: tf.Tensor(0.70354456, shape=(), dtype=float32)\n",
      "Train time for epoch #96 (192 total steps): 3.833711862564087\n",
      "Model test set loss: 0.7219 accuracy: 70.41%\n",
      "loss: tf.Tensor(0.7219119, shape=(), dtype=float32) acc: tf.Tensor(0.70408165, shape=(), dtype=float32)\n",
      "Train time for epoch #97 (194 total steps): 3.8795487880706787\n",
      "Model test set loss: 0.6874 accuracy: 70.50%\n",
      "loss: tf.Tensor(0.6874018, shape=(), dtype=float32) acc: tf.Tensor(0.70499337, shape=(), dtype=float32)\n",
      "Train time for epoch #98 (196 total steps): 3.887948989868164\n",
      "Model test set loss: 0.7126 accuracy: 70.61%\n",
      "loss: tf.Tensor(0.7125829, shape=(), dtype=float32) acc: tf.Tensor(0.7060947, shape=(), dtype=float32)\n",
      "Train time for epoch #99 (198 total steps): 3.8820302486419678\n",
      "Model test set loss: 0.7099 accuracy: 70.72%\n",
      "loss: tf.Tensor(0.7099056, shape=(), dtype=float32) acc: tf.Tensor(0.70717376, shape=(), dtype=float32)\n",
      "Train time for epoch #100 (200 total steps): 3.8920490741729736\n",
      "Model test set loss: 0.6982 accuracy: 70.85%\n",
      "loss: tf.Tensor(0.6981574, shape=(), dtype=float32) acc: tf.Tensor(0.7085374, shape=(), dtype=float32)\n",
      "Train time for epoch #101 (202 total steps): 3.9022178649902344\n",
      "Model test set loss: 0.7339 accuracy: 70.97%\n",
      "loss: tf.Tensor(0.7339416, shape=(), dtype=float32) acc: tf.Tensor(0.70970565, shape=(), dtype=float32)\n",
      "Train time for epoch #102 (204 total steps): 3.969818115234375\n",
      "Model test set loss: 0.6794 accuracy: 71.11%\n",
      "loss: tf.Tensor(0.67942744, shape=(), dtype=float32) acc: tf.Tensor(0.7110844, shape=(), dtype=float32)\n",
      "Train time for epoch #103 (206 total steps): 4.194257020950317\n",
      "Model test set loss: 0.8055 accuracy: 71.23%\n",
      "loss: tf.Tensor(0.8054699, shape=(), dtype=float32) acc: tf.Tensor(0.7123374, shape=(), dtype=float32)\n",
      "Train time for epoch #104 (208 total steps): 3.8898727893829346\n",
      "Model test set loss: 0.6773 accuracy: 71.35%\n",
      "loss: tf.Tensor(0.6772845, shape=(), dtype=float32) acc: tf.Tensor(0.71353346, shape=(), dtype=float32)\n",
      "Train time for epoch #105 (210 total steps): 3.895250082015991\n",
      "Model test set loss: 0.8047 accuracy: 71.48%\n",
      "loss: tf.Tensor(0.80473316, shape=(), dtype=float32) acc: tf.Tensor(0.7147716, shape=(), dtype=float32)\n",
      "Train time for epoch #106 (212 total steps): 3.8748252391815186\n",
      "Model test set loss: 0.8617 accuracy: 71.61%\n",
      "loss: tf.Tensor(0.8616672, shape=(), dtype=float32) acc: tf.Tensor(0.71608263, shape=(), dtype=float32)\n",
      "Train time for epoch #107 (214 total steps): 3.8841938972473145\n",
      "Model test set loss: 0.7270 accuracy: 71.73%\n",
      "loss: tf.Tensor(0.7269854, shape=(), dtype=float32) acc: tf.Tensor(0.7173056, shape=(), dtype=float32)\n",
      "Train time for epoch #108 (216 total steps): 3.897188186645508\n",
      "Model test set loss: 0.8142 accuracy: 71.86%\n",
      "loss: tf.Tensor(0.8141959, shape=(), dtype=float32) acc: tf.Tensor(0.7186004, shape=(), dtype=float32)\n",
      "Train time for epoch #109 (218 total steps): 3.8676578998565674\n",
      "Model test set loss: 0.8306 accuracy: 71.97%\n",
      "loss: tf.Tensor(0.83064914, shape=(), dtype=float32) acc: tf.Tensor(0.7197466, shape=(), dtype=float32)\n",
      "Train time for epoch #110 (220 total steps): 3.890591859817505\n",
      "Model test set loss: 1.1099 accuracy: 72.08%\n",
      "loss: tf.Tensor(1.1099197, shape=(), dtype=float32) acc: tf.Tensor(0.7208101, shape=(), dtype=float32)\n",
      "Train time for epoch #111 (222 total steps): 3.9060211181640625\n",
      "Model test set loss: 0.7619 accuracy: 72.22%\n",
      "loss: tf.Tensor(0.7618872, shape=(), dtype=float32) acc: tf.Tensor(0.72216094, shape=(), dtype=float32)\n",
      "Train time for epoch #112 (224 total steps): 3.8387057781219482\n",
      "Model test set loss: 0.7544 accuracy: 72.36%\n",
      "loss: tf.Tensor(0.75443983, shape=(), dtype=float32) acc: tf.Tensor(0.7236394, shape=(), dtype=float32)\n",
      "Train time for epoch #113 (226 total steps): 3.8892269134521484\n",
      "Model test set loss: 0.8945 accuracy: 72.50%\n",
      "loss: tf.Tensor(0.8945001, shape=(), dtype=float32) acc: tf.Tensor(0.7249714, shape=(), dtype=float32)\n",
      "Train time for epoch #114 (228 total steps): 3.8874120712280273\n",
      "Model test set loss: 0.8468 accuracy: 72.63%\n",
      "loss: tf.Tensor(0.846758, shape=(), dtype=float32) acc: tf.Tensor(0.72630984, shape=(), dtype=float32)\n",
      "Train time for epoch #115 (230 total steps): 3.879162073135376\n",
      "Model test set loss: 0.8660 accuracy: 72.76%\n",
      "loss: tf.Tensor(0.8660439, shape=(), dtype=float32) acc: tf.Tensor(0.72762495, shape=(), dtype=float32)\n",
      "Train time for epoch #116 (232 total steps): 3.891326904296875\n",
      "Model test set loss: 0.8281 accuracy: 72.91%\n",
      "loss: tf.Tensor(0.8281489, shape=(), dtype=float32) acc: tf.Tensor(0.7291227, shape=(), dtype=float32)\n",
      "Train time for epoch #117 (234 total steps): 3.821467161178589\n",
      "Model test set loss: 0.9017 accuracy: 73.05%\n",
      "loss: tf.Tensor(0.90173405, shape=(), dtype=float32) acc: tf.Tensor(0.7305076, shape=(), dtype=float32)\n",
      "Train time for epoch #118 (236 total steps): 3.9177498817443848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 0.8831 accuracy: 73.19%\n",
      "loss: tf.Tensor(0.8830513, shape=(), dtype=float32) acc: tf.Tensor(0.73186904, shape=(), dtype=float32)\n",
      "Train time for epoch #119 (238 total steps): 3.8619110584259033\n",
      "Model test set loss: 0.9147 accuracy: 73.33%\n",
      "loss: tf.Tensor(0.91468346, shape=(), dtype=float32) acc: tf.Tensor(0.73326474, shape=(), dtype=float32)\n",
      "Train time for epoch #120 (240 total steps): 3.8467679023742676\n",
      "Model test set loss: 1.0827 accuracy: 73.44%\n",
      "loss: tf.Tensor(1.082701, shape=(), dtype=float32) acc: tf.Tensor(0.7343537, shape=(), dtype=float32)\n",
      "Train time for epoch #121 (242 total steps): 3.8873541355133057\n",
      "Model test set loss: 0.9810 accuracy: 73.57%\n",
      "loss: tf.Tensor(0.98099774, shape=(), dtype=float32) acc: tf.Tensor(0.73570585, shape=(), dtype=float32)\n",
      "Train time for epoch #122 (244 total steps): 3.8583710193634033\n",
      "Model test set loss: 1.0057 accuracy: 73.71%\n",
      "loss: tf.Tensor(1.0056632, shape=(), dtype=float32) acc: tf.Tensor(0.7370637, shape=(), dtype=float32)\n",
      "Train time for epoch #123 (246 total steps): 3.840341806411743\n",
      "Model test set loss: 1.1169 accuracy: 73.82%\n",
      "loss: tf.Tensor(1.1168867, shape=(), dtype=float32) acc: tf.Tensor(0.73820585, shape=(), dtype=float32)\n",
      "Train time for epoch #124 (248 total steps): 3.904839038848877\n",
      "Model test set loss: 1.1156 accuracy: 73.94%\n",
      "loss: tf.Tensor(1.1155508, shape=(), dtype=float32) acc: tf.Tensor(0.7394393, shape=(), dtype=float32)\n",
      "Train time for epoch #125 (250 total steps): 3.875249147415161\n",
      "Model test set loss: 1.0272 accuracy: 74.06%\n",
      "loss: tf.Tensor(1.0272193, shape=(), dtype=float32) acc: tf.Tensor(0.7405986, shape=(), dtype=float32)\n",
      "Train time for epoch #126 (252 total steps): 3.9542109966278076\n",
      "Model test set loss: 0.9921 accuracy: 74.18%\n",
      "loss: tf.Tensor(0.99212396, shape=(), dtype=float32) acc: tf.Tensor(0.7418205, shape=(), dtype=float32)\n",
      "Train time for epoch #127 (254 total steps): 3.8845407962799072\n",
      "Model test set loss: 1.0694 accuracy: 74.30%\n",
      "loss: tf.Tensor(1.069361, shape=(), dtype=float32) acc: tf.Tensor(0.7429964, shape=(), dtype=float32)\n",
      "Train time for epoch #128 (256 total steps): 3.9072587490081787\n",
      "Model test set loss: 1.1875 accuracy: 74.41%\n",
      "loss: tf.Tensor(1.1874886, shape=(), dtype=float32) acc: tf.Tensor(0.74407417, shape=(), dtype=float32)\n",
      "Train time for epoch #129 (258 total steps): 3.9180400371551514\n",
      "Model test set loss: 1.1394 accuracy: 74.53%\n",
      "loss: tf.Tensor(1.1393688, shape=(), dtype=float32) acc: tf.Tensor(0.7452671, shape=(), dtype=float32)\n",
      "Train time for epoch #130 (260 total steps): 3.847038984298706\n",
      "Model test set loss: 1.2127 accuracy: 74.63%\n",
      "loss: tf.Tensor(1.212738, shape=(), dtype=float32) acc: tf.Tensor(0.746337, shape=(), dtype=float32)\n",
      "Train time for epoch #131 (262 total steps): 3.9400532245635986\n",
      "Model test set loss: 1.2359 accuracy: 74.75%\n",
      "loss: tf.Tensor(1.2358652, shape=(), dtype=float32) acc: tf.Tensor(0.7474944, shape=(), dtype=float32)\n",
      "Train time for epoch #132 (264 total steps): 4.02522611618042\n",
      "Model test set loss: 1.1561 accuracy: 74.87%\n",
      "loss: tf.Tensor(1.1560541, shape=(), dtype=float32) acc: tf.Tensor(0.7486601, shape=(), dtype=float32)\n",
      "Train time for epoch #133 (266 total steps): 4.56869101524353\n",
      "Model test set loss: 1.3217 accuracy: 74.97%\n",
      "loss: tf.Tensor(1.3216746, shape=(), dtype=float32) acc: tf.Tensor(0.7497059, shape=(), dtype=float32)\n",
      "Train time for epoch #134 (268 total steps): 4.61140513420105\n",
      "Model test set loss: 1.2435 accuracy: 75.06%\n",
      "loss: tf.Tensor(1.2435197, shape=(), dtype=float32) acc: tf.Tensor(0.7506346, shape=(), dtype=float32)\n",
      "Train time for epoch #135 (270 total steps): 4.0493528842926025\n",
      "Model test set loss: 1.9548 accuracy: 75.14%\n",
      "loss: tf.Tensor(1.9547555, shape=(), dtype=float32) acc: tf.Tensor(0.7513983, shape=(), dtype=float32)\n",
      "Train time for epoch #136 (272 total steps): 3.9743568897247314\n",
      "Model test set loss: 0.9891 accuracy: 75.25%\n",
      "loss: tf.Tensor(0.9890898, shape=(), dtype=float32) acc: tf.Tensor(0.752451, shape=(), dtype=float32)\n",
      "Train time for epoch #137 (274 total steps): 3.8532509803771973\n",
      "Model test set loss: 1.0515 accuracy: 75.35%\n",
      "loss: tf.Tensor(1.0515184, shape=(), dtype=float32) acc: tf.Tensor(0.7535131, shape=(), dtype=float32)\n",
      "Train time for epoch #138 (276 total steps): 3.862623691558838\n",
      "Model test set loss: 1.1355 accuracy: 75.44%\n",
      "loss: tf.Tensor(1.1355354, shape=(), dtype=float32) acc: tf.Tensor(0.75443655, shape=(), dtype=float32)\n",
      "Train time for epoch #139 (278 total steps): 3.905978202819824\n",
      "Model test set loss: 1.4446 accuracy: 75.54%\n",
      "loss: tf.Tensor(1.4446422, shape=(), dtype=float32) acc: tf.Tensor(0.7553957, shape=(), dtype=float32)\n",
      "Train time for epoch #140 (280 total steps): 3.8524558544158936\n",
      "Model test set loss: 1.1058 accuracy: 75.63%\n",
      "loss: tf.Tensor(1.1057642, shape=(), dtype=float32) acc: tf.Tensor(0.7563411, shape=(), dtype=float32)\n",
      "Train time for epoch #141 (282 total steps): 3.853860855102539\n",
      "Model test set loss: 1.1857 accuracy: 75.73%\n",
      "loss: tf.Tensor(1.1856558, shape=(), dtype=float32) acc: tf.Tensor(0.75727314, shape=(), dtype=float32)\n",
      "Train time for epoch #142 (284 total steps): 3.892194986343384\n",
      "Model test set loss: 1.5867 accuracy: 75.82%\n",
      "loss: tf.Tensor(1.5866687, shape=(), dtype=float32) acc: tf.Tensor(0.75816804, shape=(), dtype=float32)\n",
      "Train time for epoch #143 (286 total steps): 3.850253105163574\n",
      "Model test set loss: 1.1876 accuracy: 75.91%\n",
      "loss: tf.Tensor(1.1875879, shape=(), dtype=float32) acc: tf.Tensor(0.7591456, shape=(), dtype=float32)\n",
      "Train time for epoch #144 (288 total steps): 4.14202880859375\n",
      "Model test set loss: 1.1808 accuracy: 76.02%\n",
      "loss: tf.Tensor(1.1808318, shape=(), dtype=float32) acc: tf.Tensor(0.76015687, shape=(), dtype=float32)\n",
      "Train time for epoch #145 (290 total steps): 3.898970127105713\n",
      "Model test set loss: 1.3205 accuracy: 76.12%\n",
      "loss: tf.Tensor(1.3204715, shape=(), dtype=float32) acc: tf.Tensor(0.7611541, shape=(), dtype=float32)\n",
      "Train time for epoch #146 (292 total steps): 3.8990590572357178\n",
      "Model test set loss: 1.3778 accuracy: 76.21%\n",
      "loss: tf.Tensor(1.3778062, shape=(), dtype=float32) acc: tf.Tensor(0.76206785, shape=(), dtype=float32)\n",
      "Train time for epoch #147 (294 total steps): 3.912900686264038\n",
      "Model test set loss: 1.1844 accuracy: 76.30%\n",
      "loss: tf.Tensor(1.1844208, shape=(), dtype=float32) acc: tf.Tensor(0.76296914, shape=(), dtype=float32)\n",
      "Train time for epoch #148 (296 total steps): 3.8693041801452637\n",
      "Model test set loss: 1.8628 accuracy: 76.37%\n",
      "loss: tf.Tensor(1.8628275, shape=(), dtype=float32) acc: tf.Tensor(0.76365143, shape=(), dtype=float32)\n",
      "Train time for epoch #149 (298 total steps): 3.8829288482666016\n",
      "Model test set loss: 1.2104 accuracy: 76.45%\n",
      "loss: tf.Tensor(1.2103896, shape=(), dtype=float32) acc: tf.Tensor(0.7644615, shape=(), dtype=float32)\n",
      "Train time for epoch #150 (300 total steps): 3.9280781745910645\n",
      "Model test set loss: 1.3030 accuracy: 76.53%\n",
      "loss: tf.Tensor(1.3030062, shape=(), dtype=float32) acc: tf.Tensor(0.7653288, shape=(), dtype=float32)\n",
      "Train time for epoch #151 (302 total steps): 3.8959758281707764\n",
      "Model test set loss: 1.4833 accuracy: 76.61%\n",
      "loss: tf.Tensor(1.4832853, shape=(), dtype=float32) acc: tf.Tensor(0.76611704, shape=(), dtype=float32)\n",
      "Train time for epoch #152 (304 total steps): 3.8437187671661377\n",
      "Model test set loss: 1.5432 accuracy: 76.69%\n",
      "loss: tf.Tensor(1.5431643, shape=(), dtype=float32) acc: tf.Tensor(0.7669397, shape=(), dtype=float32)\n",
      "Train time for epoch #153 (306 total steps): 3.902367353439331\n",
      "Model test set loss: 1.4621 accuracy: 76.78%\n",
      "loss: tf.Tensor(1.4621, shape=(), dtype=float32) acc: tf.Tensor(0.767796, shape=(), dtype=float32)\n",
      "Train time for epoch #154 (308 total steps): 3.8398587703704834\n",
      "Model test set loss: 1.5672 accuracy: 76.85%\n",
      "loss: tf.Tensor(1.5672226, shape=(), dtype=float32) acc: tf.Tensor(0.7685087, shape=(), dtype=float32)\n",
      "Train time for epoch #155 (310 total steps): 3.861983060836792\n",
      "Model test set loss: 1.8963 accuracy: 76.94%\n",
      "loss: tf.Tensor(1.8962834, shape=(), dtype=float32) acc: tf.Tensor(0.7693658, shape=(), dtype=float32)\n",
      "Train time for epoch #156 (312 total steps): 3.9504621028900146\n",
      "Model test set loss: 1.2661 accuracy: 77.02%\n",
      "loss: tf.Tensor(1.2660707, shape=(), dtype=float32) acc: tf.Tensor(0.7701683, shape=(), dtype=float32)\n",
      "Train time for epoch #157 (314 total steps): 4.85675311088562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 1.2834 accuracy: 77.10%\n",
      "loss: tf.Tensor(1.2834141, shape=(), dtype=float32) acc: tf.Tensor(0.77098227, shape=(), dtype=float32)\n",
      "Train time for epoch #158 (316 total steps): 3.913874864578247\n",
      "Model test set loss: 1.3070 accuracy: 77.17%\n",
      "loss: tf.Tensor(1.3069899, shape=(), dtype=float32) acc: tf.Tensor(0.7717429, shape=(), dtype=float32)\n",
      "Train time for epoch #159 (318 total steps): 3.8081159591674805\n",
      "Model test set loss: 1.5034 accuracy: 77.24%\n",
      "loss: tf.Tensor(1.5034063, shape=(), dtype=float32) acc: tf.Tensor(0.77238697, shape=(), dtype=float32)\n",
      "Train time for epoch #160 (320 total steps): 4.496499061584473\n",
      "Model test set loss: 1.6811 accuracy: 77.30%\n",
      "loss: tf.Tensor(1.6810734, shape=(), dtype=float32) acc: tf.Tensor(0.7730442, shape=(), dtype=float32)\n",
      "Train time for epoch #161 (322 total steps): 5.471065998077393\n",
      "Model test set loss: 1.7138 accuracy: 77.37%\n",
      "loss: tf.Tensor(1.7138298, shape=(), dtype=float32) acc: tf.Tensor(0.7736933, shape=(), dtype=float32)\n",
      "Train time for epoch #162 (324 total steps): 4.172015905380249\n",
      "Model test set loss: 1.5438 accuracy: 77.43%\n",
      "loss: tf.Tensor(1.5438496, shape=(), dtype=float32) acc: tf.Tensor(0.77431345, shape=(), dtype=float32)\n",
      "Train time for epoch #163 (326 total steps): 4.224486827850342\n",
      "Model test set loss: 1.4830 accuracy: 77.50%\n",
      "loss: tf.Tensor(1.4829694, shape=(), dtype=float32) acc: tf.Tensor(0.77503026, shape=(), dtype=float32)\n",
      "Train time for epoch #164 (328 total steps): 4.678900957107544\n",
      "Model test set loss: 1.5404 accuracy: 77.57%\n",
      "loss: tf.Tensor(1.5403881, shape=(), dtype=float32) acc: tf.Tensor(0.77573836, shape=(), dtype=float32)\n",
      "Train time for epoch #165 (330 total steps): 4.2843053340911865\n",
      "Model test set loss: 1.5442 accuracy: 77.64%\n",
      "loss: tf.Tensor(1.5442388, shape=(), dtype=float32) acc: tf.Tensor(0.7764378, shape=(), dtype=float32)\n",
      "Train time for epoch #166 (332 total steps): 4.248830318450928\n",
      "Model test set loss: 1.5615 accuracy: 77.71%\n",
      "loss: tf.Tensor(1.561478, shape=(), dtype=float32) acc: tf.Tensor(0.77710843, shape=(), dtype=float32)\n",
      "Train time for epoch #167 (334 total steps): 3.9735260009765625\n",
      "Model test set loss: 1.4743 accuracy: 77.78%\n",
      "loss: tf.Tensor(1.4743246, shape=(), dtype=float32) acc: tf.Tensor(0.777771, shape=(), dtype=float32)\n",
      "Train time for epoch #168 (336 total steps): 3.8456740379333496\n",
      "Model test set loss: 1.3900 accuracy: 77.85%\n",
      "loss: tf.Tensor(1.3900182, shape=(), dtype=float32) acc: tf.Tensor(0.7784864, shape=(), dtype=float32)\n",
      "Train time for epoch #169 (338 total steps): 3.822842836380005\n",
      "Model test set loss: 1.4399 accuracy: 77.92%\n",
      "loss: tf.Tensor(1.4398668, shape=(), dtype=float32) acc: tf.Tensor(0.77919334, shape=(), dtype=float32)\n",
      "Train time for epoch #170 (340 total steps): 3.8434338569641113\n",
      "Model test set loss: 1.5513 accuracy: 77.99%\n",
      "loss: tf.Tensor(1.5513115, shape=(), dtype=float32) acc: tf.Tensor(0.77987194, shape=(), dtype=float32)\n",
      "Train time for epoch #171 (342 total steps): 3.7745437622070312\n",
      "Model test set loss: 1.6876 accuracy: 78.05%\n",
      "loss: tf.Tensor(1.6875563, shape=(), dtype=float32) acc: tf.Tensor(0.78050286, shape=(), dtype=float32)\n",
      "Train time for epoch #172 (344 total steps): 3.8003621101379395\n",
      "Model test set loss: 1.7355 accuracy: 78.11%\n",
      "loss: tf.Tensor(1.7355382, shape=(), dtype=float32) acc: tf.Tensor(0.78114617, shape=(), dtype=float32)\n",
      "Train time for epoch #173 (346 total steps): 3.7869839668273926\n",
      "Model test set loss: 1.7114 accuracy: 78.18%\n",
      "loss: tf.Tensor(1.7113965, shape=(), dtype=float32) acc: tf.Tensor(0.7817821, shape=(), dtype=float32)\n",
      "Train time for epoch #174 (348 total steps): 3.8569982051849365\n",
      "Model test set loss: 1.6971 accuracy: 78.24%\n",
      "loss: tf.Tensor(1.6971196, shape=(), dtype=float32) acc: tf.Tensor(0.78239113, shape=(), dtype=float32)\n",
      "Train time for epoch #175 (350 total steps): 3.7678449153900146\n",
      "Model test set loss: 1.7467 accuracy: 78.30%\n",
      "loss: tf.Tensor(1.7466677, shape=(), dtype=float32) acc: tf.Tensor(0.78297377, shape=(), dtype=float32)\n",
      "Train time for epoch #176 (352 total steps): 3.7937510013580322\n",
      "Model test set loss: 1.8138 accuracy: 78.35%\n",
      "loss: tf.Tensor(1.8138005, shape=(), dtype=float32) acc: tf.Tensor(0.7835111, shape=(), dtype=float32)\n",
      "Train time for epoch #177 (354 total steps): 3.7866640090942383\n",
      "Model test set loss: 1.5977 accuracy: 78.41%\n",
      "loss: tf.Tensor(1.5976686, shape=(), dtype=float32) acc: tf.Tensor(0.7841385, shape=(), dtype=float32)\n",
      "Train time for epoch #178 (356 total steps): 3.77107310295105\n",
      "Model test set loss: 1.6256 accuracy: 78.47%\n",
      "loss: tf.Tensor(1.6255919, shape=(), dtype=float32) acc: tf.Tensor(0.78473973, shape=(), dtype=float32)\n",
      "Train time for epoch #179 (358 total steps): 3.7899529933929443\n",
      "Model test set loss: 1.7418 accuracy: 78.53%\n",
      "loss: tf.Tensor(1.7417946, shape=(), dtype=float32) acc: tf.Tensor(0.78529626, shape=(), dtype=float32)\n",
      "Train time for epoch #180 (360 total steps): 3.7987263202667236\n",
      "Model test set loss: 1.8421 accuracy: 78.58%\n",
      "loss: tf.Tensor(1.8421111, shape=(), dtype=float32) acc: tf.Tensor(0.78584653, shape=(), dtype=float32)\n",
      "Train time for epoch #181 (362 total steps): 3.8049252033233643\n",
      "Model test set loss: 1.8546 accuracy: 78.64%\n",
      "loss: tf.Tensor(1.8546329, shape=(), dtype=float32) acc: tf.Tensor(0.78644717, shape=(), dtype=float32)\n",
      "Train time for epoch #182 (364 total steps): 3.7758257389068604\n",
      "Model test set loss: 1.9692 accuracy: 78.70%\n",
      "loss: tf.Tensor(1.9692334, shape=(), dtype=float32) acc: tf.Tensor(0.7869851, shape=(), dtype=float32)\n",
      "Train time for epoch #183 (366 total steps): 3.8121237754821777\n",
      "Model test set loss: 1.9726 accuracy: 78.76%\n",
      "loss: tf.Tensor(1.9725763, shape=(), dtype=float32) acc: tf.Tensor(0.7875544, shape=(), dtype=float32)\n",
      "Train time for epoch #184 (368 total steps): 3.8280389308929443\n",
      "Model test set loss: 1.8739 accuracy: 78.81%\n",
      "loss: tf.Tensor(1.8739377, shape=(), dtype=float32) acc: tf.Tensor(0.7881359, shape=(), dtype=float32)\n",
      "Train time for epoch #185 (370 total steps): 3.80873703956604\n",
      "Model test set loss: 1.8649 accuracy: 78.87%\n",
      "loss: tf.Tensor(1.8648677, shape=(), dtype=float32) acc: tf.Tensor(0.7886928, shape=(), dtype=float32)\n",
      "Train time for epoch #186 (372 total steps): 3.7615931034088135\n",
      "Model test set loss: 2.1490 accuracy: 78.92%\n",
      "loss: tf.Tensor(2.149021, shape=(), dtype=float32) acc: tf.Tensor(0.78922534, shape=(), dtype=float32)\n",
      "Train time for epoch #187 (374 total steps): 3.8027141094207764\n",
      "Model test set loss: 1.9569 accuracy: 78.98%\n",
      "loss: tf.Tensor(1.9569352, shape=(), dtype=float32) acc: tf.Tensor(0.78975224, shape=(), dtype=float32)\n",
      "Train time for epoch #188 (376 total steps): 3.8474061489105225\n",
      "Model test set loss: 1.8630 accuracy: 79.03%\n",
      "loss: tf.Tensor(1.8630385, shape=(), dtype=float32) acc: tf.Tensor(0.7903459, shape=(), dtype=float32)\n",
      "Train time for epoch #189 (378 total steps): 3.7757041454315186\n",
      "Model test set loss: 1.8843 accuracy: 79.09%\n",
      "loss: tf.Tensor(1.8843125, shape=(), dtype=float32) acc: tf.Tensor(0.7909333, shape=(), dtype=float32)\n",
      "Train time for epoch #190 (380 total steps): 3.7969160079956055\n",
      "Model test set loss: 1.9182 accuracy: 79.15%\n",
      "loss: tf.Tensor(1.9182252, shape=(), dtype=float32) acc: tf.Tensor(0.7914966, shape=(), dtype=float32)\n",
      "Train time for epoch #191 (382 total steps): 3.81172513961792\n",
      "Model test set loss: 1.9854 accuracy: 79.21%\n",
      "loss: tf.Tensor(1.9854074, shape=(), dtype=float32) acc: tf.Tensor(0.7920718, shape=(), dtype=float32)\n",
      "Train time for epoch #192 (384 total steps): 3.828627347946167\n",
      "Model test set loss: 1.9078 accuracy: 79.26%\n",
      "loss: tf.Tensor(1.9077742, shape=(), dtype=float32) acc: tf.Tensor(0.79264104, shape=(), dtype=float32)\n",
      "Train time for epoch #193 (386 total steps): 3.821302890777588\n",
      "Model test set loss: 1.9463 accuracy: 79.32%\n",
      "loss: tf.Tensor(1.9463191, shape=(), dtype=float32) acc: tf.Tensor(0.7931867, shape=(), dtype=float32)\n",
      "Train time for epoch #194 (388 total steps): 3.7695038318634033\n",
      "Model test set loss: 1.9961 accuracy: 79.37%\n",
      "loss: tf.Tensor(1.9961395, shape=(), dtype=float32) acc: tf.Tensor(0.7937092, shape=(), dtype=float32)\n",
      "Train time for epoch #195 (390 total steps): 3.8039889335632324\n",
      "Model test set loss: 2.0454 accuracy: 79.42%\n",
      "loss: tf.Tensor(2.0454378, shape=(), dtype=float32) acc: tf.Tensor(0.7942439, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #196 (392 total steps): 3.784600019454956\n",
      "Model test set loss: 2.0489 accuracy: 79.48%\n",
      "loss: tf.Tensor(2.048857, shape=(), dtype=float32) acc: tf.Tensor(0.79475564, shape=(), dtype=float32)\n",
      "Train time for epoch #197 (394 total steps): 3.8019001483917236\n",
      "Model test set loss: 1.9716 accuracy: 79.53%\n",
      "loss: tf.Tensor(1.9715587, shape=(), dtype=float32) acc: tf.Tensor(0.7952623, shape=(), dtype=float32)\n",
      "Train time for epoch #198 (396 total steps): 3.8084049224853516\n",
      "Model test set loss: 1.9433 accuracy: 79.58%\n",
      "loss: tf.Tensor(1.9432611, shape=(), dtype=float32) acc: tf.Tensor(0.7957981, shape=(), dtype=float32)\n",
      "Train time for epoch #199 (398 total steps): 3.9074811935424805\n",
      "Model test set loss: 1.9599 accuracy: 79.63%\n",
      "loss: tf.Tensor(1.959893, shape=(), dtype=float32) acc: tf.Tensor(0.7963286, shape=(), dtype=float32)\n",
      "Train time for epoch #200 (400 total steps): 3.7992000579833984\n",
      "Model test set loss: 2.0042 accuracy: 79.69%\n",
      "loss: tf.Tensor(2.0041966, shape=(), dtype=float32) acc: tf.Tensor(0.7968537, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_EPOCHS = 200\n",
    "\n",
    "for i in range(NUM_TRAIN_EPOCHS):\n",
    "    start = time.time()\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((trainX, trainy))\n",
    "    train_ds = train_ds.shuffle(200).batch(100)\n",
    "    #   with train_summary_writer.as_default():\n",
    "    train(CNN_model, optimizer, train_ds, log_freq=500)\n",
    "    end = time.time()\n",
    "    print('Train time for epoch #{} ({} total steps): {}'.format(\n",
    "        i + 1, int(optimizer.iterations), end - start))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((testX, testy))\n",
    "    test_ds = test_ds.batch(80)\n",
    "    test(CNN_model, test_ds, optimizer.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_Model_Covid_Pneumonia_Normal/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(CNN_model,'CNN_Model_Covid_Pneumonia_Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Network\n",
    "\n",
    "Here we train a tf.keras implementation of InceptionV3\n",
    "\n",
    "\n",
    "![](inception.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(keras.Model):\n",
    "    \n",
    "    def __init__(self, ch, kernelsz=3, strides=1, padding='same'):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        \n",
    "        self.model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(ch, kernelsz, strides=strides, padding=padding),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU()\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        x = self.model(x, training=training)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlk(keras.Model):\n",
    "    \n",
    "    def __init__(self, ch, strides=1):\n",
    "        super(InceptionBlk, self).__init__()\n",
    "        \n",
    "        self.ch = ch\n",
    "        self.strides = strides\n",
    "        \n",
    "        self.conv1 = ConvBNRelu(ch, strides=strides)\n",
    "        self.conv2 = ConvBNRelu(ch, kernelsz=3, strides=strides)\n",
    "        self.conv3_1 = ConvBNRelu(ch, kernelsz=3, strides=strides)\n",
    "        self.conv3_2 = ConvBNRelu(ch, kernelsz=3, strides=1)\n",
    "        \n",
    "        self.pool = keras.layers.MaxPooling2D(3, strides=1, padding='same')\n",
    "        self.pool_conv = ConvBNRelu(ch, strides=strides)\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        \n",
    "        x1 = self.conv1(x, training=training)\n",
    "\n",
    "        x2 = self.conv2(x, training=training)\n",
    "                \n",
    "        x3_1 = self.conv3_1(x, training=training)\n",
    "        x3_2 = self.conv3_2(x3_1, training=training)\n",
    "                \n",
    "        x4 = self.pool(x)\n",
    "        x4 = self.pool_conv(x4, training=training)\n",
    "        \n",
    "        # concat along axis=channel\n",
    "        x = tf.concat([x1, x2, x3_2, x4], axis=3)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(keras.Model):\n",
    "    \n",
    "    def __init__(self, num_layers, num_classes, init_ch=16, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        \n",
    "        self.in_channels = init_ch\n",
    "        self.out_channels = init_ch\n",
    "        self.num_layers = num_layers\n",
    "        self.init_ch = init_ch\n",
    "        \n",
    "        self.conv1 = ConvBNRelu(init_ch)\n",
    "        \n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "        \n",
    "        for block_id in range(num_layers):\n",
    "            \n",
    "            for layer_id in range(2):\n",
    "                \n",
    "                if layer_id == 0:\n",
    "                    \n",
    "                    block = InceptionBlk(self.out_channels, strides=2)\n",
    "                    \n",
    "                else:\n",
    "                    block = InceptionBlk(self.out_channels, strides=1)\n",
    "                    \n",
    "                self.blocks.add(block)\n",
    "            \n",
    "            # enlarger out_channels per block    \n",
    "            self.out_channels *= 2\n",
    "            \n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        out = self.conv1(x, training=training)\n",
    "        \n",
    "        out = self.blocks(out, training=training)\n",
    "        \n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_relu_41 (ConvBNRelu) multiple                  512       \n",
      "_________________________________________________________________\n",
      "dynamic-blocks (Sequential)  multiple                  5094624   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1539      \n",
      "=================================================================\n",
      "Total params: 5,096,675\n",
      "Trainable params: 5,091,843\n",
      "Non-trainable params: 4,832\n",
      "_________________________________________________________________\n",
      "0 0 loss: 7.8019147\n",
      "0 evaluation acc: 0.3537415\n",
      "1 0 loss: 192.97495\n",
      "1 evaluation acc: 0.2993197\n",
      "2 0 loss: 66.97399\n",
      "2 evaluation acc: 0.2993197\n",
      "3 0 loss: 7.861458\n",
      "3 evaluation acc: 0.2993197\n",
      "4 0 loss: 1.7335942\n",
      "4 evaluation acc: 0.2993197\n",
      "5 0 loss: 1.1752476\n",
      "5 evaluation acc: 0.2993197\n",
      "6 0 loss: 1.1062373\n",
      "6 evaluation acc: 0.2993197\n",
      "7 0 loss: 1.0983416\n",
      "7 evaluation acc: 0.3537415\n",
      "8 0 loss: 1.0969471\n",
      "8 evaluation acc: 0.5510204\n",
      "9 0 loss: 1.0900409\n",
      "9 evaluation acc: 0.2993197\n",
      "10 0 loss: 1.0856178\n",
      "10 evaluation acc: 0.2993197\n",
      "11 0 loss: 1.0780073\n",
      "11 evaluation acc: 0.53741497\n",
      "12 0 loss: 1.0660444\n",
      "12 evaluation acc: 0.33333334\n",
      "13 0 loss: 1.043428\n",
      "13 evaluation acc: 0.53061223\n",
      "14 0 loss: 1.0171645\n",
      "14 evaluation acc: 0.2993197\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-96ecaf606949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInception_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInception_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_MaxPoolGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       data_format=op.get_attr(\"data_format\"))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_grad\u001b[0;34m(orig_input, orig_output, grad, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   6114\u001b[0m         \u001b[0;34m\"MaxPoolGrad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6115\u001b[0m         \u001b[0morig_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ksize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6116\u001b[0;31m         padding, \"data_format\", data_format)\n\u001b[0m\u001b[1;32m   6117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6118\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build model and optimizer\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "Inception_model = Inception(4, 3)\n",
    "# derive input shape for every layers.\n",
    "Inception_model.build(input_shape=(None, 200, 200, 3))\n",
    "Inception_model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "acc_meter = keras.metrics.Accuracy()\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((trainX, trainy)).batch(256)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(256)\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "\n",
    "    for step, (x, y) in enumerate(db_train):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # print(x.shape, y.shape)\n",
    "            # [b, 10]\n",
    "            logits = Inception_model(x)\n",
    "            # [b] vs [b, 10]\n",
    "            loss = criteon(tf.one_hot(y, depth=3), logits)\n",
    "\n",
    "        grads = tape.gradient(loss, Inception_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, Inception_model.trainable_variables))\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(epoch, step, 'loss:', loss.numpy())\n",
    "\n",
    "\n",
    "    acc_meter.reset_states()\n",
    "    for x, y in db_test:\n",
    "        # [b, 10]\n",
    "        logits = Inception_model(x, training=False)\n",
    "        # [b, 10] => [b]\n",
    "        pred = tf.argmax(logits, axis=1)\n",
    "        # [b] vs [b, 10]\n",
    "        acc_meter.update_state(y, pred)\n",
    "\n",
    "    print(epoch, 'evaluation acc:', acc_meter.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(Inception_model,'Inception_Model_Covid_Pneumonia_Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(channels, stride=1, kernel=(3, 3)):\n",
    "    return keras.layers.Conv2D(channels, kernel, strides=stride, padding='same',\n",
    "                               use_bias=False,\n",
    "                            kernel_initializer=tf.random_normal_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(keras.Model):\n",
    "\n",
    "    def __init__(self, channels, strides=1, residual_path=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.residual_path = residual_path\n",
    "\n",
    "        self.conv1 = conv3x3(channels, strides)\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = conv3x3(channels)\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "\n",
    "        if residual_path:\n",
    "            self.down_conv = conv3x3(channels, strides, kernel=(1, 1))\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.bn1(inputs, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # this module can be added into self.\n",
    "        # however, module in for can not be added.\n",
    "        if self.residual_path:\n",
    "            residual = self.down_bn(inputs, training=training)\n",
    "            residual = tf.nn.relu(residual)\n",
    "            residual = self.down_conv(residual)\n",
    "\n",
    "        x = x + residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(keras.Model):\n",
    "\n",
    "    def __init__(self, block_list, num_classes, initial_filters=16, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_blocks = len(block_list)\n",
    "        self.block_list = block_list\n",
    "\n",
    "        self.in_channels = initial_filters\n",
    "        self.out_channels = initial_filters\n",
    "        self.conv_initial = conv3x3(self.out_channels)\n",
    "\n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "\n",
    "        # build all the blocks\n",
    "        for block_id in range(len(block_list)):\n",
    "            for layer_id in range(block_list[block_id]):\n",
    "\n",
    "                if block_id != 0 and layer_id == 0:\n",
    "                    block = ResnetBlock(self.out_channels, strides=2, residual_path=True)\n",
    "                else:\n",
    "                    if self.in_channels != self.out_channels:\n",
    "                        residual_path = True\n",
    "                    else:\n",
    "                        residual_path = False\n",
    "                    block = ResnetBlock(self.out_channels, residual_path=residual_path)\n",
    "\n",
    "                self.in_channels = self.out_channels\n",
    "\n",
    "                self.blocks.add(block)\n",
    "\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.final_bn = keras.layers.BatchNormalization()\n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        out = self.conv_initial(inputs)\n",
    "\n",
    "        out = self.blocks(out, training=training)\n",
    "\n",
    "        out = self.final_bn(out, training=training)\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in the model : 577\n",
      "Model: \"res_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_82 (Conv2D)           multiple                  432       \n",
      "_________________________________________________________________\n",
      "dynamic-blocks (Sequential)  multiple                  1024000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat multiple                  256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  195       \n",
      "=================================================================\n",
      "Total params: 1,024,883\n",
      "Trainable params: 1,018,611\n",
      "Non-trainable params: 6,272\n",
      "_________________________________________________________________\n",
      "Train on 147 samples, validate on 147 samples\n",
      "Epoch 1/200\n",
      "147/147 [==============================] - 632s 4s/sample - loss: 0.9965 - accuracy: 0.4830 - val_loss: 1098.8406 - val_accuracy: 0.2993\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 552s 4s/sample - loss: 0.6939 - accuracy: 0.7823 - val_loss: 3770.9448 - val_accuracy: 0.2993\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 561s 4s/sample - loss: 0.5726 - accuracy: 0.8027 - val_loss: 1649.9211 - val_accuracy: 0.2993\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 649s 4s/sample - loss: 0.5058 - accuracy: 0.8299 - val_loss: 578.5244 - val_accuracy: 0.2993\n",
      "Epoch 5/200\n",
      " 32/147 [=====>........................] - ETA: 6:22"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-97558e5c0366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m ResNet_model.fit(trainX, y_ohe, batch_size=batch_size, epochs=epochs,\n\u001b[0;32m---> 19\u001b[0;31m           validation_data=(testX, testy_ohe), verbose=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "# build model and optimizer\n",
    "ResNet_model = ResNet([32, 16, 8], num_classes)\n",
    "ResNet_model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "ResNet_model.build(input_shape=(None, 200,200,3))\n",
    "print(\"Number of variables in the model :\", len(ResNet_model.variables))\n",
    "ResNet_model.summary()\n",
    "\n",
    "y_ohe = tf.one_hot(trainy, depth=3).numpy()\n",
    "testy_ohe = tf.one_hot(testy, depth=3).numpy()\n",
    "\n",
    "# train\n",
    "ResNet_model.fit(trainX, y_ohe, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(testX, testy_ohe), verbose=1)\n",
    "\n",
    "# evaluate on test set\n",
    "scores = ResNet_model.evaluate(testX, testy_ohe, batch_size, verbose=1)\n",
    "print(\"Final test loss and accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(ResNet_model,'ResNet_Model_Covid_Pneumonia_Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(models.Model):\n",
    "\n",
    "\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_shape: [32, 32, 3]\n",
    "        \"\"\"\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        weight_decay = 0.000\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=input_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(self.num_classes))\n",
    "        # model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 1.1591172218322754 acc: 0.3265306\n",
      "test acc: 0.3469388\n",
      "1 0 loss: 3.0694644451141357 acc: 0.33333334\n",
      "test acc: 0.2993197\n",
      "2 0 loss: 1.541196584701538 acc: 0.34013605\n",
      "test acc: 0.30612245\n",
      "3 0 loss: 1.079532504081726 acc: 0.34013605\n",
      "test acc: 0.3537415\n",
      "4 0 loss: 1.0796326398849487 acc: 0.33333334\n",
      "test acc: 0.3809524\n",
      "5 0 loss: 1.072597861289978 acc: 0.37414965\n",
      "test acc: 0.3809524\n",
      "6 0 loss: 1.0601069927215576 acc: 0.3877551\n",
      "test acc: 0.5986394\n",
      "7 0 loss: 1.0440694093704224 acc: 0.6530612\n",
      "test acc: 0.65986395\n",
      "8 0 loss: 1.0198856592178345 acc: 0.68707484\n",
      "test acc: 0.63265306\n",
      "9 0 loss: 0.9812823534011841 acc: 0.67346936\n",
      "test acc: 0.67346936\n",
      "10 0 loss: 0.9239126443862915 acc: 0.6938776\n",
      "test acc: 0.82312924\n",
      "11 0 loss: 0.835117518901825 acc: 0.89115644\n",
      "test acc: 0.8367347\n",
      "12 0 loss: 0.713874876499176 acc: 0.8027211\n",
      "test acc: 0.59183675\n",
      "13 0 loss: 0.8679106831550598 acc: 0.5986394\n",
      "test acc: 0.3469388\n",
      "14 0 loss: 1.5182301998138428 acc: 0.33333334\n",
      "test acc: 0.6122449\n",
      "15 0 loss: 0.7862218022346497 acc: 0.61904764\n",
      "test acc: 0.7619048\n",
      "16 0 loss: 0.6158617734909058 acc: 0.8095238\n",
      "test acc: 0.6258503\n",
      "17 0 loss: 0.7853065133094788 acc: 0.6122449\n",
      "test acc: 0.7823129\n",
      "18 0 loss: 0.6348512768745422 acc: 0.7346939\n",
      "test acc: 0.85714287\n",
      "19 0 loss: 0.5894452333450317 acc: 0.8707483\n",
      "test acc: 0.8639456\n",
      "20 0 loss: 0.606975257396698 acc: 0.8435374\n",
      "test acc: 0.8639456\n",
      "21 0 loss: 0.5466083288192749 acc: 0.8367347\n",
      "test acc: 0.8639456\n",
      "22 0 loss: 0.4387938380241394 acc: 0.88435376\n",
      "test acc: 0.8367347\n",
      "23 0 loss: 0.3805891275405884 acc: 0.8707483\n",
      "test acc: 0.85714287\n",
      "24 0 loss: 0.36085134744644165 acc: 0.8639456\n",
      "test acc: 0.8503401\n",
      "25 0 loss: 0.3010934591293335 acc: 0.88435376\n",
      "test acc: 0.8707483\n",
      "26 0 loss: 0.2666119635105133 acc: 0.8707483\n",
      "test acc: 0.8503401\n",
      "27 0 loss: 0.2776346504688263 acc: 0.8639456\n",
      "test acc: 0.88435376\n",
      "28 0 loss: 0.2722017467021942 acc: 0.89115644\n",
      "test acc: 0.81632656\n",
      "29 0 loss: 0.25948598980903625 acc: 0.877551\n",
      "test acc: 0.88435376\n",
      "30 0 loss: 0.2176181823015213 acc: 0.91156465\n",
      "test acc: 0.88435376\n",
      "31 0 loss: 0.17004606127738953 acc: 0.9455782\n",
      "test acc: 0.8367347\n",
      "32 0 loss: 0.1641421914100647 acc: 0.93877554\n",
      "test acc: 0.8979592\n",
      "33 0 loss: 0.1665409356355667 acc: 0.93877554\n",
      "test acc: 0.89115644\n",
      "34 0 loss: 0.12709863483905792 acc: 0.9455782\n",
      "test acc: 0.8707483\n",
      "35 0 loss: 0.12594689428806305 acc: 0.9455782\n",
      "test acc: 0.877551\n",
      "36 0 loss: 0.09794812649488449 acc: 0.9591837\n",
      "test acc: 0.89115644\n",
      "37 0 loss: 0.08928656578063965 acc: 0.9727891\n",
      "test acc: 0.91156465\n",
      "38 0 loss: 0.07690834254026413 acc: 0.9659864\n",
      "test acc: 0.8367347\n",
      "39 0 loss: 0.10444068163633347 acc: 0.95238096\n",
      "test acc: 0.9047619\n",
      "40 0 loss: 0.13138841092586517 acc: 0.93877554\n",
      "test acc: 0.8435374\n",
      "41 0 loss: 0.08263640105724335 acc: 0.9591837\n",
      "test acc: 0.9047619\n",
      "42 0 loss: 0.0435933955013752 acc: 0.9863946\n",
      "test acc: 0.9183673\n",
      "43 0 loss: 0.05637911707162857 acc: 0.97959185\n",
      "test acc: 0.91156465\n",
      "44 0 loss: 0.02319611795246601 acc: 1.0\n",
      "test acc: 0.8707483\n",
      "45 0 loss: 0.04383937269449234 acc: 0.97959185\n",
      "test acc: 0.92517006\n",
      "46 0 loss: 0.030623773112893105 acc: 0.99319726\n",
      "test acc: 0.91156465\n",
      "47 0 loss: 0.024109486490488052 acc: 1.0\n",
      "test acc: 0.877551\n",
      "48 0 loss: 0.017715780064463615 acc: 1.0\n",
      "test acc: 0.92517006\n",
      "49 0 loss: 0.014305450022220612 acc: 0.99319726\n",
      "test acc: 0.89115644\n",
      "50 0 loss: 0.017321446910500526 acc: 0.99319726\n",
      "test acc: 0.8979592\n",
      "51 0 loss: 0.01281034667044878 acc: 1.0\n",
      "test acc: 0.88435376\n",
      "52 0 loss: 0.0058193691074848175 acc: 1.0\n",
      "test acc: 0.9183673\n",
      "53 0 loss: 0.009461998008191586 acc: 1.0\n",
      "test acc: 0.9183673\n",
      "54 0 loss: 0.009608002379536629 acc: 1.0\n",
      "test acc: 0.9183673\n",
      "55 0 loss: 0.0014389670686796308 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "56 0 loss: 0.002262955531477928 acc: 1.0\n",
      "test acc: 0.877551\n",
      "57 0 loss: 0.006943637039512396 acc: 1.0\n",
      "test acc: 0.9047619\n",
      "58 0 loss: 0.0021019282285124063 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "59 0 loss: 0.000573190045543015 acc: 1.0\n",
      "test acc: 0.92517006\n",
      "60 0 loss: 0.0009644064120948315 acc: 1.0\n",
      "test acc: 0.92517006\n",
      "61 0 loss: 0.00228315987624228 acc: 1.0\n",
      "test acc: 0.92517006\n",
      "62 0 loss: 0.0019059363985434175 acc: 1.0\n",
      "test acc: 0.92517006\n",
      "63 0 loss: 0.0006937059224583209 acc: 1.0\n",
      "test acc: 0.9183673\n",
      "64 0 loss: 0.0002564543974585831 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "65 0 loss: 0.00019348683417774737 acc: 1.0\n",
      "test acc: 0.89115644\n",
      "66 0 loss: 0.0004378067678771913 acc: 1.0\n",
      "test acc: 0.88435376\n",
      "67 0 loss: 0.0007837965385988355 acc: 1.0\n",
      "test acc: 0.88435376\n",
      "68 0 loss: 0.00035058913636021316 acc: 1.0\n",
      "test acc: 0.8979592\n",
      "69 0 loss: 0.00014943226415198296 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "70 0 loss: 9.259830403607339e-05 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "71 0 loss: 7.985456613823771e-05 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "72 0 loss: 8.902452827896923e-05 acc: 1.0\n",
      "test acc: 0.91156465\n",
      "73 0 loss: 0.0001204291038447991 acc: 1.0\n",
      "test acc: 0.9183673\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1b478ad64bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVGG16_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# MUST clip gradient here or it will disconverge!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    604\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    607\u001b[0m   ]\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VGG16_model = VGG16([200, 200, 3], 3)\n",
    "\n",
    "\n",
    "# must specify from_logits=True!\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((trainX, trainy)).batch(256)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(256)\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    for step, (x, y) in enumerate(db_train):\n",
    "        # [b, 1] => [b]\n",
    "        # y = tf.squeeze(y, axis=1)\n",
    "        # [b, 10]\n",
    "        y = tf.one_hot(y, depth=3)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = VGG16_model(x)\n",
    "            loss = criteon(y, logits)\n",
    "            # loss2 = compute_loss(logits, tf.argmax(y, axis=1))\n",
    "            # mse_loss = tf.reduce_sum(tf.square(y-logits))\n",
    "            # print(y.shape, logits.shape)\n",
    "            metric.update_state(y, logits)\n",
    "\n",
    "        grads = tape.gradient(loss, VGG16_model.trainable_variables)\n",
    "        # MUST clip gradient here or it will disconverge!\n",
    "        grads = [ tf.clip_by_norm(g, 15) for g in grads]\n",
    "        optimizer.apply_gradients(zip(grads, VGG16_model.trainable_variables))\n",
    "\n",
    "        if step % 40 == 0:\n",
    "            # for g in grads:\n",
    "            #     print(tf.norm(g).numpy())\n",
    "            print(epoch, step, 'loss:', float(loss), 'acc:', metric.result().numpy())\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "\n",
    "        metric = keras.metrics.CategoricalAccuracy()\n",
    "        for x, y in db_test:\n",
    "            # [b, 1] => [b]\n",
    "            # y = tf.squeeze(y, axis=1)\n",
    "            # [b, 10]\n",
    "            y = tf.one_hot(y, depth=3)\n",
    "\n",
    "            logits = VGG16_model.predict(x)\n",
    "            # be careful, these functions can accept y as [b] without warnning.\n",
    "            metric.update_state(y, logits)\n",
    "        print('test acc:', metric.result().numpy())\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: VGG16_Model_Covid_Pneumonia_Normal/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(VGG16_model,'VGG16_Model_Covid_Pneumonia_Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
