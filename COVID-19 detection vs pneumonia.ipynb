{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from os.path import isdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(filename, required_size=(200, 200)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    image = image.resize(required_size)\n",
    "    pixels = asarray(image, dtype=np.float32)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        img = extract_images(path)\n",
    "        # store\n",
    "        images.append(img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in ['Covid', 'PNEUMONIA']:\n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_images(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 94 examples for class: Covid\n",
      ">loaded 100 examples for class: PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset('xray_dataset_covid19/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "trainy = le.fit_transform(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 200, 200, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainy, testy = train_test_split(trainX, trainy, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 200, 200, 3), (97,), (97, 200, 200, 3), (97,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainy.shape,testX.shape,testy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "\n",
    "Now that we've gotten our feet we with a simple DNN, let's try something more advanced. Although the process is the same, we'll be working with some additional features:\n",
    "- Convolution, pooling, and dropout layers for building more complex models\n",
    "- Visualizing training with TensorBoard\n",
    "- Validation and test set evaluation for measuring generalizability\n",
    "- Exporting with SavedModel to save training progress and deploy trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = tf.keras.Sequential([\n",
    "    layers.Reshape(\n",
    "        target_shape=[200, 200, 3],\n",
    "        input_shape=(200, 200,3)),\n",
    "    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dropout(rate=0.4),\n",
    "    layers.Dense(3)])\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, images, labels):\n",
    "\n",
    "    # Record the operations used to compute the loss, so that the gradient\n",
    "    # of the loss with respect to the variables can be computed.\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(images, training=True)\n",
    "        loss = compute_loss(labels, logits)\n",
    "        compute_accuracy(labels, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataset, log_freq=50):\n",
    "    \"\"\"\n",
    "    Trains model on `dataset` using `optimizer`.\n",
    "    \"\"\"\n",
    "    # Metrics are stateful. They accumulate values and return a cumulative\n",
    "    # result when you call .result(). Clear accumulated values with .reset_states()\n",
    "    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "    # Datasets can be iterated over like any other Python iterable.\n",
    "    for images, labels in dataset:\n",
    "        loss = train_step(model, optimizer, images, labels)\n",
    "        avg_loss(loss)\n",
    "\n",
    "        if tf.equal(optimizer.iterations % log_freq, 0):\n",
    "            # summary_ops_v2.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
    "            # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=optimizer.iterations)\n",
    "            print('step:', int(optimizer.iterations),\n",
    "                  'loss:', avg_loss.result().numpy(),\n",
    "                  'acc:', compute_accuracy.result().numpy())\n",
    "            avg_loss.reset_states()\n",
    "            compute_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, step_num):\n",
    "    \"\"\"\n",
    "    Perform an evaluation of `model` on the examples from `dataset`.\n",
    "    \"\"\"\n",
    "    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "    for (images, labels) in dataset:\n",
    "        logits = model(images, training=False)\n",
    "        avg_loss(compute_loss(labels, logits))\n",
    "        compute_accuracy(labels, logits)\n",
    "\n",
    "    print('Model test set loss: {:0.4f} accuracy: {:0.2f}%'.format(\n",
    "        avg_loss.result(), compute_accuracy.result() * 100))\n",
    "\n",
    "    print('loss:', avg_loss.result(), 'acc:', compute_accuracy.result())\n",
    "    # summary_ops_v2.scalar('loss', avg_loss.result(), step=step_num)\n",
    "    # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=step_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #1 (1 total steps): 2.382455825805664\n",
      "Model test set loss: 6.5183 accuracy: 10.31%\n",
      "loss: tf.Tensor(6.5182695, shape=(), dtype=float32) acc: tf.Tensor(0.10309278, shape=(), dtype=float32)\n",
      "Train time for epoch #2 (2 total steps): 2.4777748584747314\n",
      "Model test set loss: 1.0361 accuracy: 27.58%\n",
      "loss: tf.Tensor(1.0361073, shape=(), dtype=float32) acc: tf.Tensor(0.2757732, shape=(), dtype=float32)\n",
      "Train time for epoch #3 (3 total steps): 2.3673200607299805\n",
      "Model test set loss: 0.7117 accuracy: 35.40%\n",
      "loss: tf.Tensor(0.7117114, shape=(), dtype=float32) acc: tf.Tensor(0.3539519, shape=(), dtype=float32)\n",
      "Train time for epoch #4 (4 total steps): 2.3240468502044678\n",
      "Model test set loss: 0.6975 accuracy: 38.53%\n",
      "loss: tf.Tensor(0.69751537, shape=(), dtype=float32) acc: tf.Tensor(0.38530928, shape=(), dtype=float32)\n",
      "Train time for epoch #5 (5 total steps): 2.2381420135498047\n",
      "Model test set loss: 0.6971 accuracy: 40.52%\n",
      "loss: tf.Tensor(0.6970622, shape=(), dtype=float32) acc: tf.Tensor(0.40515465, shape=(), dtype=float32)\n",
      "Train time for epoch #6 (6 total steps): 2.1987111568450928\n",
      "Model test set loss: 0.6959 accuracy: 42.01%\n",
      "loss: tf.Tensor(0.6959229, shape=(), dtype=float32) acc: tf.Tensor(0.4201031, shape=(), dtype=float32)\n",
      "Train time for epoch #7 (7 total steps): 2.237334966659546\n",
      "Model test set loss: 0.6942 accuracy: 43.37%\n",
      "loss: tf.Tensor(0.6941879, shape=(), dtype=float32) acc: tf.Tensor(0.43372607, shape=(), dtype=float32)\n",
      "Train time for epoch #8 (8 total steps): 2.3444459438323975\n",
      "Model test set loss: 0.6930 accuracy: 44.72%\n",
      "loss: tf.Tensor(0.69295603, shape=(), dtype=float32) acc: tf.Tensor(0.44716495, shape=(), dtype=float32)\n",
      "Train time for epoch #9 (9 total steps): 2.269705057144165\n",
      "Model test set loss: 0.6927 accuracy: 45.70%\n",
      "loss: tf.Tensor(0.69266415, shape=(), dtype=float32) acc: tf.Tensor(0.45704466, shape=(), dtype=float32)\n",
      "Train time for epoch #10 (10 total steps): 3.064957857131958\n",
      "Model test set loss: 0.6925 accuracy: 46.44%\n",
      "loss: tf.Tensor(0.69253045, shape=(), dtype=float32) acc: tf.Tensor(0.46443298, shape=(), dtype=float32)\n",
      "Train time for epoch #11 (11 total steps): 2.901232957839966\n",
      "Model test set loss: 0.6924 accuracy: 46.49%\n",
      "loss: tf.Tensor(0.692412, shape=(), dtype=float32) acc: tf.Tensor(0.46485475, shape=(), dtype=float32)\n",
      "Train time for epoch #12 (12 total steps): 2.640545129776001\n",
      "Model test set loss: 0.6924 accuracy: 46.65%\n",
      "loss: tf.Tensor(0.6923559, shape=(), dtype=float32) acc: tf.Tensor(0.46649486, shape=(), dtype=float32)\n",
      "Train time for epoch #13 (13 total steps): 2.784899950027466\n",
      "Model test set loss: 0.6924 accuracy: 47.11%\n",
      "loss: tf.Tensor(0.69237316, shape=(), dtype=float32) acc: tf.Tensor(0.47105473, shape=(), dtype=float32)\n",
      "Train time for epoch #14 (14 total steps): 2.779705762863159\n",
      "Model test set loss: 0.6924 accuracy: 47.42%\n",
      "loss: tf.Tensor(0.692381, shape=(), dtype=float32) acc: tf.Tensor(0.4742268, shape=(), dtype=float32)\n",
      "Train time for epoch #15 (15 total steps): 3.0418753623962402\n",
      "Model test set loss: 0.6924 accuracy: 47.73%\n",
      "loss: tf.Tensor(0.6923913, shape=(), dtype=float32) acc: tf.Tensor(0.4773196, shape=(), dtype=float32)\n",
      "Train time for epoch #16 (16 total steps): 2.5912139415740967\n",
      "Model test set loss: 0.6924 accuracy: 48.16%\n",
      "loss: tf.Tensor(0.69243366, shape=(), dtype=float32) acc: tf.Tensor(0.48163658, shape=(), dtype=float32)\n",
      "Train time for epoch #17 (17 total steps): 2.415994167327881\n",
      "Model test set loss: 0.6925 accuracy: 48.18%\n",
      "loss: tf.Tensor(0.69246984, shape=(), dtype=float32) acc: tf.Tensor(0.48180714, shape=(), dtype=float32)\n",
      "Train time for epoch #18 (18 total steps): 2.4269771575927734\n",
      "Model test set loss: 0.6925 accuracy: 48.34%\n",
      "loss: tf.Tensor(0.69248104, shape=(), dtype=float32) acc: tf.Tensor(0.4833906, shape=(), dtype=float32)\n",
      "Train time for epoch #19 (19 total steps): 2.54768705368042\n",
      "Model test set loss: 0.6925 accuracy: 48.48%\n",
      "loss: tf.Tensor(0.69251275, shape=(), dtype=float32) acc: tf.Tensor(0.48480737, shape=(), dtype=float32)\n",
      "Train time for epoch #20 (20 total steps): 3.023158073425293\n",
      "Model test set loss: 0.6925 accuracy: 48.51%\n",
      "loss: tf.Tensor(0.692464, shape=(), dtype=float32) acc: tf.Tensor(0.48505154, shape=(), dtype=float32)\n",
      "Train time for epoch #21 (21 total steps): 2.768695116043091\n",
      "Model test set loss: 0.6926 accuracy: 48.45%\n",
      "loss: tf.Tensor(0.69255984, shape=(), dtype=float32) acc: tf.Tensor(0.48453608, shape=(), dtype=float32)\n",
      "Train time for epoch #22 (22 total steps): 2.418163776397705\n",
      "Model test set loss: 0.6927 accuracy: 48.55%\n",
      "loss: tf.Tensor(0.69271225, shape=(), dtype=float32) acc: tf.Tensor(0.48547328, shape=(), dtype=float32)\n",
      "Train time for epoch #23 (23 total steps): 2.6575911045074463\n",
      "Model test set loss: 0.6929 accuracy: 48.54%\n",
      "loss: tf.Tensor(0.69290924, shape=(), dtype=float32) acc: tf.Tensor(0.48543254, shape=(), dtype=float32)\n",
      "Train time for epoch #24 (24 total steps): 2.8476760387420654\n",
      "Model test set loss: 0.6930 accuracy: 48.56%\n",
      "loss: tf.Tensor(0.69299895, shape=(), dtype=float32) acc: tf.Tensor(0.48560998, shape=(), dtype=float32)\n",
      "Train time for epoch #25 (25 total steps): 3.584199905395508\n",
      "Model test set loss: 0.6931 accuracy: 48.62%\n",
      "loss: tf.Tensor(0.69308245, shape=(), dtype=float32) acc: tf.Tensor(0.48618558, shape=(), dtype=float32)\n",
      "Train time for epoch #26 (26 total steps): 3.844717264175415\n",
      "Model test set loss: 0.6932 accuracy: 48.49%\n",
      "loss: tf.Tensor(0.69316566, shape=(), dtype=float32) acc: tf.Tensor(0.4849326, shape=(), dtype=float32)\n",
      "Train time for epoch #27 (27 total steps): 3.287194013595581\n",
      "Model test set loss: 0.6932 accuracy: 48.49%\n",
      "loss: tf.Tensor(0.6932107, shape=(), dtype=float32) acc: tf.Tensor(0.4849179, shape=(), dtype=float32)\n",
      "Train time for epoch #28 (28 total steps): 3.1160919666290283\n",
      "Model test set loss: 0.6933 accuracy: 48.53%\n",
      "loss: tf.Tensor(0.69325614, shape=(), dtype=float32) acc: tf.Tensor(0.48527247, shape=(), dtype=float32)\n",
      "Train time for epoch #29 (29 total steps): 2.733707904815674\n",
      "Model test set loss: 0.6933 accuracy: 48.54%\n",
      "loss: tf.Tensor(0.69330525, shape=(), dtype=float32) acc: tf.Tensor(0.48542482, shape=(), dtype=float32)\n",
      "Train time for epoch #30 (30 total steps): 2.561228036880493\n",
      "Model test set loss: 0.6932 accuracy: 48.73%\n",
      "loss: tf.Tensor(0.69321, shape=(), dtype=float32) acc: tf.Tensor(0.48728523, shape=(), dtype=float32)\n",
      "Train time for epoch #31 (31 total steps): 2.6901700496673584\n",
      "Model test set loss: 0.6931 accuracy: 48.77%\n",
      "loss: tf.Tensor(0.6930878, shape=(), dtype=float32) acc: tf.Tensor(0.48769537, shape=(), dtype=float32)\n",
      "Train time for epoch #32 (32 total steps): 2.716831922531128\n",
      "Model test set loss: 0.6930 accuracy: 48.86%\n",
      "loss: tf.Tensor(0.6929811, shape=(), dtype=float32) acc: tf.Tensor(0.48856315, shape=(), dtype=float32)\n",
      "Train time for epoch #33 (33 total steps): 2.8986148834228516\n",
      "Model test set loss: 0.6929 accuracy: 49.00%\n",
      "loss: tf.Tensor(0.6929485, shape=(), dtype=float32) acc: tf.Tensor(0.49000314, shape=(), dtype=float32)\n",
      "Train time for epoch #34 (34 total steps): 3.543538808822632\n",
      "Model test set loss: 0.6930 accuracy: 49.06%\n",
      "loss: tf.Tensor(0.69296855, shape=(), dtype=float32) acc: tf.Tensor(0.49060038, shape=(), dtype=float32)\n",
      "Train time for epoch #35 (35 total steps): 3.347659111022949\n",
      "Model test set loss: 0.6930 accuracy: 49.22%\n",
      "loss: tf.Tensor(0.6929857, shape=(), dtype=float32) acc: tf.Tensor(0.4921944, shape=(), dtype=float32)\n",
      "Train time for epoch #36 (36 total steps): 2.641695976257324\n",
      "Model test set loss: 0.6930 accuracy: 49.14%\n",
      "loss: tf.Tensor(0.6929716, shape=(), dtype=float32) acc: tf.Tensor(0.49140894, shape=(), dtype=float32)\n",
      "Train time for epoch #37 (37 total steps): 2.9675662517547607\n",
      "Model test set loss: 0.6930 accuracy: 49.09%\n",
      "loss: tf.Tensor(0.69296503, shape=(), dtype=float32) acc: tf.Tensor(0.49094456, shape=(), dtype=float32)\n",
      "Train time for epoch #38 (38 total steps): 2.736844062805176\n",
      "Model test set loss: 0.6930 accuracy: 49.06%\n",
      "loss: tf.Tensor(0.69295526, shape=(), dtype=float32) acc: tf.Tensor(0.49064025, shape=(), dtype=float32)\n",
      "Train time for epoch #39 (39 total steps): 2.546103000640869\n",
      "Model test set loss: 0.6930 accuracy: 49.17%\n",
      "loss: tf.Tensor(0.6929953, shape=(), dtype=float32) acc: tf.Tensor(0.49167326, shape=(), dtype=float32)\n",
      "Train time for epoch #40 (40 total steps): 2.6223318576812744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 0.6929 accuracy: 49.10%\n",
      "loss: tf.Tensor(0.69294095, shape=(), dtype=float32) acc: tf.Tensor(0.49097937, shape=(), dtype=float32)\n",
      "Train time for epoch #41 (41 total steps): 2.557220220565796\n",
      "Model test set loss: 0.6929 accuracy: 49.15%\n",
      "loss: tf.Tensor(0.6929306, shape=(), dtype=float32) acc: tf.Tensor(0.49145085, shape=(), dtype=float32)\n",
      "Train time for epoch #42 (42 total steps): 2.578850269317627\n",
      "Model test set loss: 0.6930 accuracy: 49.08%\n",
      "loss: tf.Tensor(0.693042, shape=(), dtype=float32) acc: tf.Tensor(0.49079528, shape=(), dtype=float32)\n",
      "Train time for epoch #43 (43 total steps): 3.3559648990631104\n",
      "Model test set loss: 0.6931 accuracy: 49.14%\n",
      "loss: tf.Tensor(0.6931287, shape=(), dtype=float32) acc: tf.Tensor(0.49136898, shape=(), dtype=float32)\n",
      "Train time for epoch #44 (44 total steps): 3.602038860321045\n",
      "Model test set loss: 0.6932 accuracy: 49.17%\n",
      "loss: tf.Tensor(0.69324005, shape=(), dtype=float32) acc: tf.Tensor(0.4916823, shape=(), dtype=float32)\n",
      "Train time for epoch #45 (45 total steps): 3.1145241260528564\n",
      "Model test set loss: 0.6934 accuracy: 49.14%\n",
      "loss: tf.Tensor(0.69337976, shape=(), dtype=float32) acc: tf.Tensor(0.49140894, shape=(), dtype=float32)\n",
      "Train time for epoch #46 (46 total steps): 2.604785919189453\n",
      "Model test set loss: 0.6933 accuracy: 49.24%\n",
      "loss: tf.Tensor(0.6933135, shape=(), dtype=float32) acc: tf.Tensor(0.4923801, shape=(), dtype=float32)\n",
      "Train time for epoch #47 (47 total steps): 2.603058099746704\n",
      "Model test set loss: 0.6933 accuracy: 49.24%\n",
      "loss: tf.Tensor(0.69328284, shape=(), dtype=float32) acc: tf.Tensor(0.49243256, shape=(), dtype=float32)\n",
      "Train time for epoch #48 (48 total steps): 2.5295848846435547\n",
      "Model test set loss: 0.6932 accuracy: 49.26%\n",
      "loss: tf.Tensor(0.6931895, shape=(), dtype=float32) acc: tf.Tensor(0.49259022, shape=(), dtype=float32)\n",
      "Train time for epoch #49 (49 total steps): 2.523247241973877\n",
      "Model test set loss: 0.6931 accuracy: 49.24%\n",
      "loss: tf.Tensor(0.69312316, shape=(), dtype=float32) acc: tf.Tensor(0.49242583, shape=(), dtype=float32)\n",
      "Train time for epoch #50 (50 total steps): 2.5650229454040527\n",
      "Model test set loss: 0.6931 accuracy: 49.28%\n",
      "loss: tf.Tensor(0.69306004, shape=(), dtype=float32) acc: tf.Tensor(0.49278352, shape=(), dtype=float32)\n",
      "Train time for epoch #51 (51 total steps): 2.4467859268188477\n",
      "Model test set loss: 0.6930 accuracy: 49.31%\n",
      "loss: tf.Tensor(0.6929841, shape=(), dtype=float32) acc: tf.Tensor(0.49312714, shape=(), dtype=float32)\n",
      "Train time for epoch #52 (52 total steps): 2.4467928409576416\n",
      "Model test set loss: 0.6929 accuracy: 49.35%\n",
      "loss: tf.Tensor(0.6928691, shape=(), dtype=float32) acc: tf.Tensor(0.4934576, shape=(), dtype=float32)\n",
      "Train time for epoch #53 (53 total steps): 2.4297800064086914\n",
      "Model test set loss: 0.6928 accuracy: 49.42%\n",
      "loss: tf.Tensor(0.69281393, shape=(), dtype=float32) acc: tf.Tensor(0.49416456, shape=(), dtype=float32)\n",
      "Train time for epoch #54 (54 total steps): 2.4285941123962402\n",
      "Model test set loss: 0.6928 accuracy: 49.50%\n",
      "loss: tf.Tensor(0.69276977, shape=(), dtype=float32) acc: tf.Tensor(0.49503627, shape=(), dtype=float32)\n",
      "Train time for epoch #55 (55 total steps): 2.472468137741089\n",
      "Model test set loss: 0.6927 accuracy: 49.58%\n",
      "loss: tf.Tensor(0.6926714, shape=(), dtype=float32) acc: tf.Tensor(0.49578255, shape=(), dtype=float32)\n",
      "Train time for epoch #56 (56 total steps): 2.4601309299468994\n",
      "Model test set loss: 0.6926 accuracy: 49.59%\n",
      "loss: tf.Tensor(0.69262385, shape=(), dtype=float32) acc: tf.Tensor(0.49585786, shape=(), dtype=float32)\n",
      "Train time for epoch #57 (57 total steps): 2.4528849124908447\n",
      "Model test set loss: 0.6926 accuracy: 49.62%\n",
      "loss: tf.Tensor(0.6926341, shape=(), dtype=float32) acc: tf.Tensor(0.49620184, shape=(), dtype=float32)\n",
      "Train time for epoch #58 (58 total steps): 2.4812543392181396\n",
      "Model test set loss: 0.6926 accuracy: 49.65%\n",
      "loss: tf.Tensor(0.692621, shape=(), dtype=float32) acc: tf.Tensor(0.49653396, shape=(), dtype=float32)\n",
      "Train time for epoch #59 (59 total steps): 2.4951303005218506\n",
      "Model test set loss: 0.6926 accuracy: 49.62%\n",
      "loss: tf.Tensor(0.69262886, shape=(), dtype=float32) acc: tf.Tensor(0.49624324, shape=(), dtype=float32)\n",
      "Train time for epoch #60 (60 total steps): 2.481086015701294\n",
      "Model test set loss: 0.6927 accuracy: 49.66%\n",
      "loss: tf.Tensor(0.692696, shape=(), dtype=float32) acc: tf.Tensor(0.49664947, shape=(), dtype=float32)\n",
      "Train time for epoch #61 (61 total steps): 2.4460060596466064\n",
      "Model test set loss: 0.6927 accuracy: 49.68%\n",
      "loss: tf.Tensor(0.69272614, shape=(), dtype=float32) acc: tf.Tensor(0.49678892, shape=(), dtype=float32)\n",
      "Train time for epoch #62 (62 total steps): 2.453528881072998\n",
      "Model test set loss: 0.6927 accuracy: 49.72%\n",
      "loss: tf.Tensor(0.69272876, shape=(), dtype=float32) acc: tf.Tensor(0.49717325, shape=(), dtype=float32)\n",
      "Train time for epoch #63 (63 total steps): 2.4411630630493164\n",
      "Model test set loss: 0.6927 accuracy: 49.78%\n",
      "loss: tf.Tensor(0.69268274, shape=(), dtype=float32) acc: tf.Tensor(0.49779087, shape=(), dtype=float32)\n",
      "Train time for epoch #64 (64 total steps): 2.517086982727051\n",
      "Model test set loss: 0.6926 accuracy: 49.85%\n",
      "loss: tf.Tensor(0.69264376, shape=(), dtype=float32) acc: tf.Tensor(0.4984697, shape=(), dtype=float32)\n",
      "Train time for epoch #65 (65 total steps): 2.442656993865967\n",
      "Model test set loss: 0.6926 accuracy: 49.94%\n",
      "loss: tf.Tensor(0.6925617, shape=(), dtype=float32) acc: tf.Tensor(0.49936557, shape=(), dtype=float32)\n",
      "Train time for epoch #66 (66 total steps): 2.46099591255188\n",
      "Model test set loss: 0.6926 accuracy: 49.97%\n",
      "loss: tf.Tensor(0.692559, shape=(), dtype=float32) acc: tf.Tensor(0.4996876, shape=(), dtype=float32)\n",
      "Train time for epoch #67 (67 total steps): 2.4301538467407227\n",
      "Model test set loss: 0.6925 accuracy: 49.98%\n",
      "loss: tf.Tensor(0.6925499, shape=(), dtype=float32) acc: tf.Tensor(0.49976918, shape=(), dtype=float32)\n",
      "Train time for epoch #68 (68 total steps): 2.440916061401367\n",
      "Model test set loss: 0.6925 accuracy: 49.99%\n",
      "loss: tf.Tensor(0.69254327, shape=(), dtype=float32) acc: tf.Tensor(0.49992418, shape=(), dtype=float32)\n",
      "Train time for epoch #69 (69 total steps): 2.5381078720092773\n",
      "Model test set loss: 0.6925 accuracy: 49.99%\n",
      "loss: tf.Tensor(0.69252896, shape=(), dtype=float32) acc: tf.Tensor(0.4999253, shape=(), dtype=float32)\n",
      "Train time for epoch #70 (70 total steps): 2.5050649642944336\n",
      "Model test set loss: 0.6925 accuracy: 50.01%\n",
      "loss: tf.Tensor(0.6925212, shape=(), dtype=float32) acc: tf.Tensor(0.5000736, shape=(), dtype=float32)\n",
      "Train time for epoch #71 (71 total steps): 2.4062893390655518\n",
      "Model test set loss: 0.6925 accuracy: 50.01%\n",
      "loss: tf.Tensor(0.6925235, shape=(), dtype=float32) acc: tf.Tensor(0.5000726, shape=(), dtype=float32)\n",
      "Train time for epoch #72 (72 total steps): 2.417175054550171\n",
      "Model test set loss: 0.6925 accuracy: 49.97%\n",
      "loss: tf.Tensor(0.69254804, shape=(), dtype=float32) acc: tf.Tensor(0.49971363, shape=(), dtype=float32)\n",
      "Train time for epoch #73 (73 total steps): 2.436568021774292\n",
      "Model test set loss: 0.6926 accuracy: 50.01%\n",
      "loss: tf.Tensor(0.6925581, shape=(), dtype=float32) acc: tf.Tensor(0.5001412, shape=(), dtype=float32)\n",
      "Train time for epoch #74 (74 total steps): 2.4365246295928955\n",
      "Model test set loss: 0.6926 accuracy: 50.05%\n",
      "loss: tf.Tensor(0.69255817, shape=(), dtype=float32) acc: tf.Tensor(0.5004876, shape=(), dtype=float32)\n",
      "Train time for epoch #75 (75 total steps): 2.4584622383117676\n",
      "Model test set loss: 0.6926 accuracy: 50.10%\n",
      "loss: tf.Tensor(0.69262964, shape=(), dtype=float32) acc: tf.Tensor(0.5009622, shape=(), dtype=float32)\n",
      "Train time for epoch #76 (76 total steps): 2.4296388626098633\n",
      "Model test set loss: 0.6927 accuracy: 50.14%\n",
      "loss: tf.Tensor(0.6926634, shape=(), dtype=float32) acc: tf.Tensor(0.5014243, shape=(), dtype=float32)\n",
      "Train time for epoch #77 (77 total steps): 2.455491065979004\n",
      "Model test set loss: 0.6927 accuracy: 50.16%\n",
      "loss: tf.Tensor(0.69268334, shape=(), dtype=float32) acc: tf.Tensor(0.50160664, shape=(), dtype=float32)\n",
      "Train time for epoch #78 (78 total steps): 2.4795992374420166\n",
      "Model test set loss: 0.6927 accuracy: 50.18%\n",
      "loss: tf.Tensor(0.6926935, shape=(), dtype=float32) acc: tf.Tensor(0.5017843, shape=(), dtype=float32)\n",
      "Train time for epoch #79 (79 total steps): 2.515627145767212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 0.6926 accuracy: 50.15%\n",
      "loss: tf.Tensor(0.6926228, shape=(), dtype=float32) acc: tf.Tensor(0.5015007, shape=(), dtype=float32)\n",
      "Train time for epoch #80 (80 total steps): 2.4493470191955566\n",
      "Model test set loss: 0.6925 accuracy: 50.13%\n",
      "loss: tf.Tensor(0.69254863, shape=(), dtype=float32) acc: tf.Tensor(0.50128865, shape=(), dtype=float32)\n",
      "Train time for epoch #81 (81 total steps): 2.4646120071411133\n",
      "Model test set loss: 0.6925 accuracy: 50.17%\n",
      "loss: tf.Tensor(0.6925075, shape=(), dtype=float32) acc: tf.Tensor(0.50165457, shape=(), dtype=float32)\n",
      "Train time for epoch #82 (82 total steps): 2.3916893005371094\n",
      "Model test set loss: 0.6925 accuracy: 50.14%\n",
      "loss: tf.Tensor(0.692479, shape=(), dtype=float32) acc: tf.Tensor(0.50138295, shape=(), dtype=float32)\n",
      "Train time for epoch #83 (83 total steps): 2.4235281944274902\n",
      "Model test set loss: 0.6925 accuracy: 50.14%\n",
      "loss: tf.Tensor(0.69248295, shape=(), dtype=float32) acc: tf.Tensor(0.50142837, shape=(), dtype=float32)\n",
      "Train time for epoch #84 (84 total steps): 2.398689031600952\n",
      "Model test set loss: 0.6925 accuracy: 50.15%\n",
      "loss: tf.Tensor(0.69252443, shape=(), dtype=float32) acc: tf.Tensor(0.5014728, shape=(), dtype=float32)\n",
      "Train time for epoch #85 (85 total steps): 2.41526198387146\n",
      "Model test set loss: 0.6925 accuracy: 50.21%\n",
      "loss: tf.Tensor(0.69246906, shape=(), dtype=float32) acc: tf.Tensor(0.5021225, shape=(), dtype=float32)\n",
      "Train time for epoch #86 (86 total steps): 2.43083119392395\n",
      "Model test set loss: 0.6925 accuracy: 50.23%\n",
      "loss: tf.Tensor(0.69251454, shape=(), dtype=float32) acc: tf.Tensor(0.5022776, shape=(), dtype=float32)\n",
      "Train time for epoch #87 (87 total steps): 2.448739767074585\n",
      "Model test set loss: 0.6925 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.69250244, shape=(), dtype=float32) acc: tf.Tensor(0.5028439, shape=(), dtype=float32)\n",
      "Train time for epoch #88 (88 total steps): 2.4910330772399902\n",
      "Model test set loss: 0.6925 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.6924876, shape=(), dtype=float32) acc: tf.Tensor(0.5025773, shape=(), dtype=float32)\n",
      "Train time for epoch #89 (89 total steps): 2.449867010116577\n",
      "Model test set loss: 0.6926 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.692568, shape=(), dtype=float32) acc: tf.Tensor(0.50295377, shape=(), dtype=float32)\n",
      "Train time for epoch #90 (90 total steps): 2.4508657455444336\n",
      "Model test set loss: 0.6927 accuracy: 50.33%\n",
      "loss: tf.Tensor(0.69273716, shape=(), dtype=float32) acc: tf.Tensor(0.5033219, shape=(), dtype=float32)\n",
      "Train time for epoch #91 (91 total steps): 2.400954008102417\n",
      "Model test set loss: 0.6927 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6926978, shape=(), dtype=float32) acc: tf.Tensor(0.5030588, shape=(), dtype=float32)\n",
      "Train time for epoch #92 (92 total steps): 2.444591999053955\n",
      "Model test set loss: 0.6929 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6928597, shape=(), dtype=float32) acc: tf.Tensor(0.5029135, shape=(), dtype=float32)\n",
      "Train time for epoch #93 (93 total steps): 2.4504430294036865\n",
      "Model test set loss: 0.6928 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6927634, shape=(), dtype=float32) acc: tf.Tensor(0.5029376, shape=(), dtype=float32)\n",
      "Train time for epoch #94 (94 total steps): 2.443773031234741\n",
      "Model test set loss: 0.6927 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.69272184, shape=(), dtype=float32) acc: tf.Tensor(0.5028515, shape=(), dtype=float32)\n",
      "Train time for epoch #95 (95 total steps): 2.449143886566162\n",
      "Model test set loss: 0.6927 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.6926992, shape=(), dtype=float32) acc: tf.Tensor(0.5025502, shape=(), dtype=float32)\n",
      "Train time for epoch #96 (96 total steps): 2.424286127090454\n",
      "Model test set loss: 0.6927 accuracy: 50.23%\n",
      "loss: tf.Tensor(0.6926989, shape=(), dtype=float32) acc: tf.Tensor(0.50225514, shape=(), dtype=float32)\n",
      "Train time for epoch #97 (97 total steps): 2.4618942737579346\n",
      "Model test set loss: 0.6926 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.6926092, shape=(), dtype=float32) acc: tf.Tensor(0.50281644, shape=(), dtype=float32)\n",
      "Train time for epoch #98 (98 total steps): 2.410529136657715\n",
      "Model test set loss: 0.6926 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.6925596, shape=(), dtype=float32) acc: tf.Tensor(0.50284034, shape=(), dtype=float32)\n",
      "Train time for epoch #99 (99 total steps): 2.474165916442871\n",
      "Model test set loss: 0.6926 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.69255185, shape=(), dtype=float32) acc: tf.Tensor(0.5028637, shape=(), dtype=float32)\n",
      "Train time for epoch #100 (100 total steps): 2.421858072280884\n",
      "Model test set loss: 0.6924 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.69243324, shape=(), dtype=float32) acc: tf.Tensor(0.5025773, shape=(), dtype=float32)\n",
      "Train time for epoch #101 (101 total steps): 2.4014458656311035\n",
      "Model test set loss: 0.6924 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6923677, shape=(), dtype=float32) acc: tf.Tensor(0.5030622, shape=(), dtype=float32)\n",
      "Train time for epoch #102 (102 total steps): 2.405402183532715\n",
      "Model test set loss: 0.6924 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6923512, shape=(), dtype=float32) acc: tf.Tensor(0.50313324, shape=(), dtype=float32)\n",
      "Train time for epoch #103 (103 total steps): 2.458660125732422\n",
      "Model test set loss: 0.6924 accuracy: 50.36%\n",
      "loss: tf.Tensor(0.69235265, shape=(), dtype=float32) acc: tf.Tensor(0.5036032, shape=(), dtype=float32)\n",
      "Train time for epoch #104 (104 total steps): 2.4312679767608643\n",
      "Model test set loss: 0.6923 accuracy: 50.35%\n",
      "loss: tf.Tensor(0.6923429, shape=(), dtype=float32) acc: tf.Tensor(0.50346947, shape=(), dtype=float32)\n",
      "Train time for epoch #105 (105 total steps): 2.472214937210083\n",
      "Model test set loss: 0.6924 accuracy: 50.35%\n",
      "loss: tf.Tensor(0.69235045, shape=(), dtype=float32) acc: tf.Tensor(0.5034855, shape=(), dtype=float32)\n",
      "Train time for epoch #106 (106 total steps): 2.4161837100982666\n",
      "Model test set loss: 0.6924 accuracy: 50.34%\n",
      "loss: tf.Tensor(0.69237304, shape=(), dtype=float32) acc: tf.Tensor(0.5033554, shape=(), dtype=float32)\n",
      "Train time for epoch #107 (107 total steps): 2.418468952178955\n",
      "Model test set loss: 0.6924 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.69242436, shape=(), dtype=float32) acc: tf.Tensor(0.50303495, shape=(), dtype=float32)\n",
      "Train time for epoch #108 (108 total steps): 2.450989007949829\n",
      "Model test set loss: 0.6925 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6924802, shape=(), dtype=float32) acc: tf.Tensor(0.5028637, shape=(), dtype=float32)\n",
      "Train time for epoch #109 (109 total steps): 2.4771909713745117\n",
      "Model test set loss: 0.6924 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.69242823, shape=(), dtype=float32) acc: tf.Tensor(0.5025537, shape=(), dtype=float32)\n",
      "Train time for epoch #110 (110 total steps): 2.408689022064209\n",
      "Model test set loss: 0.6924 accuracy: 50.27%\n",
      "loss: tf.Tensor(0.69242597, shape=(), dtype=float32) acc: tf.Tensor(0.5027179, shape=(), dtype=float32)\n",
      "Train time for epoch #111 (111 total steps): 2.4331958293914795\n",
      "Model test set loss: 0.6924 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.6923981, shape=(), dtype=float32) acc: tf.Tensor(0.5027863, shape=(), dtype=float32)\n",
      "Train time for epoch #112 (112 total steps): 2.434828042984009\n",
      "Model test set loss: 0.6924 accuracy: 50.27%\n",
      "loss: tf.Tensor(0.69242156, shape=(), dtype=float32) acc: tf.Tensor(0.5026694, shape=(), dtype=float32)\n",
      "Train time for epoch #113 (113 total steps): 2.4026119709014893\n",
      "Model test set loss: 0.6924 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.69244367, shape=(), dtype=float32) acc: tf.Tensor(0.50296503, shape=(), dtype=float32)\n",
      "Train time for epoch #114 (114 total steps): 2.403841972351074\n",
      "Model test set loss: 0.6924 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.6923959, shape=(), dtype=float32) acc: tf.Tensor(0.50302947, shape=(), dtype=float32)\n",
      "Train time for epoch #115 (115 total steps): 2.3912978172302246\n",
      "Model test set loss: 0.6924 accuracy: 50.32%\n",
      "loss: tf.Tensor(0.69236046, shape=(), dtype=float32) acc: tf.Tensor(0.5031824, shape=(), dtype=float32)\n",
      "Train time for epoch #116 (116 total steps): 2.384917736053467\n",
      "Model test set loss: 0.6924 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.6923631, shape=(), dtype=float32) acc: tf.Tensor(0.50302166, shape=(), dtype=float32)\n",
      "Train time for epoch #117 (117 total steps): 2.4010009765625\n",
      "Model test set loss: 0.6924 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6923628, shape=(), dtype=float32) acc: tf.Tensor(0.50308394, shape=(), dtype=float32)\n",
      "Train time for epoch #118 (118 total steps): 2.45086407661438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 0.6924 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6923674, shape=(), dtype=float32) acc: tf.Tensor(0.5031452, shape=(), dtype=float32)\n",
      "Train time for epoch #119 (119 total steps): 2.415929079055786\n",
      "Model test set loss: 0.6924 accuracy: 50.32%\n",
      "loss: tf.Tensor(0.69236916, shape=(), dtype=float32) acc: tf.Tensor(0.5031621, shape=(), dtype=float32)\n",
      "Train time for epoch #120 (120 total steps): 2.40049409866333\n",
      "Model test set loss: 0.6924 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.69236517, shape=(), dtype=float32) acc: tf.Tensor(0.50309277, shape=(), dtype=float32)\n",
      "Train time for epoch #121 (121 total steps): 2.41888165473938\n",
      "Model test set loss: 0.6924 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.6923533, shape=(), dtype=float32) acc: tf.Tensor(0.5026412, shape=(), dtype=float32)\n",
      "Train time for epoch #122 (122 total steps): 2.367280960083008\n",
      "Model test set loss: 0.6924 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.69235325, shape=(), dtype=float32) acc: tf.Tensor(0.50261956, shape=(), dtype=float32)\n",
      "Train time for epoch #123 (123 total steps): 2.4066169261932373\n",
      "Model test set loss: 0.6924 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6923553, shape=(), dtype=float32) acc: tf.Tensor(0.50293356, shape=(), dtype=float32)\n",
      "Train time for epoch #124 (124 total steps): 2.393631935119629\n",
      "Model test set loss: 0.6924 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6923671, shape=(), dtype=float32) acc: tf.Tensor(0.50307614, shape=(), dtype=float32)\n",
      "Train time for epoch #125 (125 total steps): 2.409339189529419\n",
      "Model test set loss: 0.6924 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6923816, shape=(), dtype=float32) acc: tf.Tensor(0.50292784, shape=(), dtype=float32)\n",
      "Train time for epoch #126 (126 total steps): 2.4150776863098145\n",
      "Model test set loss: 0.6924 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6924048, shape=(), dtype=float32) acc: tf.Tensor(0.5028637, shape=(), dtype=float32)\n",
      "Train time for epoch #127 (127 total steps): 2.374216079711914\n",
      "Model test set loss: 0.6924 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.6924367, shape=(), dtype=float32) acc: tf.Tensor(0.5026382, shape=(), dtype=float32)\n",
      "Train time for epoch #128 (128 total steps): 2.450857162475586\n",
      "Model test set loss: 0.6924 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.69244003, shape=(), dtype=float32) acc: tf.Tensor(0.50277865, shape=(), dtype=float32)\n",
      "Train time for epoch #129 (129 total steps): 2.3972842693328857\n",
      "Model test set loss: 0.6925 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.6924633, shape=(), dtype=float32) acc: tf.Tensor(0.502917, shape=(), dtype=float32)\n",
      "Train time for epoch #130 (130 total steps): 2.46287202835083\n",
      "Model test set loss: 0.6925 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.6924834, shape=(), dtype=float32) acc: tf.Tensor(0.50277555, shape=(), dtype=float32)\n",
      "Train time for epoch #131 (131 total steps): 2.3638930320739746\n",
      "Model test set loss: 0.6927 accuracy: 50.25%\n",
      "loss: tf.Tensor(0.69267714, shape=(), dtype=float32) acc: tf.Tensor(0.5025183, shape=(), dtype=float32)\n",
      "Train time for epoch #132 (132 total steps): 2.4312829971313477\n",
      "Model test set loss: 0.6930 accuracy: 50.26%\n",
      "loss: tf.Tensor(0.6930035, shape=(), dtype=float32) acc: tf.Tensor(0.5025773, shape=(), dtype=float32)\n",
      "Train time for epoch #133 (133 total steps): 2.405954122543335\n",
      "Model test set loss: 0.6929 accuracy: 50.29%\n",
      "loss: tf.Tensor(0.69291866, shape=(), dtype=float32) acc: tf.Tensor(0.502868, shape=(), dtype=float32)\n",
      "Train time for epoch #134 (134 total steps): 2.4284720420837402\n",
      "Model test set loss: 0.6927 accuracy: 50.27%\n",
      "loss: tf.Tensor(0.69273126, shape=(), dtype=float32) acc: tf.Tensor(0.5027312, shape=(), dtype=float32)\n",
      "Train time for epoch #135 (135 total steps): 2.418117046356201\n",
      "Model test set loss: 0.6928 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.6927904, shape=(), dtype=float32) acc: tf.Tensor(0.50297827, shape=(), dtype=float32)\n",
      "Train time for epoch #136 (136 total steps): 2.406717300415039\n",
      "Model test set loss: 0.6927 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.6927142, shape=(), dtype=float32) acc: tf.Tensor(0.50303215, shape=(), dtype=float32)\n",
      "Train time for epoch #137 (137 total steps): 2.365844964981079\n",
      "Model test set loss: 0.6926 accuracy: 50.27%\n",
      "loss: tf.Tensor(0.69263077, shape=(), dtype=float32) acc: tf.Tensor(0.50270903, shape=(), dtype=float32)\n",
      "Train time for epoch #138 (138 total steps): 2.392120122909546\n",
      "Model test set loss: 0.6926 accuracy: 50.28%\n",
      "loss: tf.Tensor(0.69259, shape=(), dtype=float32) acc: tf.Tensor(0.5028014, shape=(), dtype=float32)\n",
      "Train time for epoch #139 (139 total steps): 2.3957581520080566\n",
      "Model test set loss: 0.6928 accuracy: 50.30%\n",
      "loss: tf.Tensor(0.69275105, shape=(), dtype=float32) acc: tf.Tensor(0.5030038, shape=(), dtype=float32)\n",
      "Train time for epoch #140 (140 total steps): 2.397221803665161\n",
      "Model test set loss: 0.6929 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6928787, shape=(), dtype=float32) acc: tf.Tensor(0.50309277, shape=(), dtype=float32)\n",
      "Train time for epoch #141 (141 total steps): 2.3969521522521973\n",
      "Model test set loss: 0.6928 accuracy: 50.31%\n",
      "loss: tf.Tensor(0.6927561, shape=(), dtype=float32) acc: tf.Tensor(0.50307083, shape=(), dtype=float32)\n",
      "Train time for epoch #142 (142 total steps): 2.454320192337036\n",
      "Model test set loss: 0.6927 accuracy: 50.33%\n",
      "loss: tf.Tensor(0.6927177, shape=(), dtype=float32) acc: tf.Tensor(0.50330335, shape=(), dtype=float32)\n",
      "Train time for epoch #143 (143 total steps): 2.6530282497406006\n",
      "Model test set loss: 0.6927 accuracy: 50.33%\n",
      "loss: tf.Tensor(0.6926683, shape=(), dtype=float32) acc: tf.Tensor(0.5032802, shape=(), dtype=float32)\n",
      "Train time for epoch #144 (144 total steps): 2.4039430618286133\n",
      "Model test set loss: 0.6925 accuracy: 50.33%\n",
      "loss: tf.Tensor(0.6924826, shape=(), dtype=float32) acc: tf.Tensor(0.50332904, shape=(), dtype=float32)\n",
      "Train time for epoch #145 (145 total steps): 2.4085350036621094\n",
      "Model test set loss: 0.6924 accuracy: 50.33%\n",
      "loss: tf.Tensor(0.69235814, shape=(), dtype=float32) acc: tf.Tensor(0.5032705, shape=(), dtype=float32)\n",
      "Train time for epoch #146 (146 total steps): 2.4443211555480957\n",
      "Model test set loss: 0.6923 accuracy: 50.33%\n",
      "loss: tf.Tensor(0.6923361, shape=(), dtype=float32) acc: tf.Tensor(0.5033187, shape=(), dtype=float32)\n",
      "Train time for epoch #147 (147 total steps): 2.400556802749634\n",
      "Model test set loss: 0.6923 accuracy: 50.34%\n",
      "loss: tf.Tensor(0.69232774, shape=(), dtype=float32) acc: tf.Tensor(0.50340134, shape=(), dtype=float32)\n",
      "Train time for epoch #148 (148 total steps): 2.3816089630126953\n",
      "Model test set loss: 0.6923 accuracy: 50.35%\n",
      "loss: tf.Tensor(0.6923288, shape=(), dtype=float32) acc: tf.Tensor(0.5034829, shape=(), dtype=float32)\n",
      "Train time for epoch #149 (149 total steps): 2.3560330867767334\n",
      "Model test set loss: 0.6923 accuracy: 50.37%\n",
      "loss: tf.Tensor(0.6923257, shape=(), dtype=float32) acc: tf.Tensor(0.50366706, shape=(), dtype=float32)\n",
      "Train time for epoch #150 (150 total steps): 2.374013900756836\n",
      "Model test set loss: 0.6923 accuracy: 50.40%\n",
      "loss: tf.Tensor(0.69232017, shape=(), dtype=float32) acc: tf.Tensor(0.5039519, shape=(), dtype=float32)\n",
      "Train time for epoch #151 (151 total steps): 2.381927251815796\n",
      "Model test set loss: 0.6923 accuracy: 50.38%\n",
      "loss: tf.Tensor(0.69231486, shape=(), dtype=float32) acc: tf.Tensor(0.5037892, shape=(), dtype=float32)\n",
      "Train time for epoch #152 (152 total steps): 2.385787010192871\n",
      "Model test set loss: 0.6923 accuracy: 50.39%\n",
      "loss: tf.Tensor(0.6923119, shape=(), dtype=float32) acc: tf.Tensor(0.50386596, shape=(), dtype=float32)\n",
      "Train time for epoch #153 (153 total steps): 2.344310998916626\n",
      "Model test set loss: 0.6923 accuracy: 50.39%\n",
      "loss: tf.Tensor(0.69231987, shape=(), dtype=float32) acc: tf.Tensor(0.5038744, shape=(), dtype=float32)\n",
      "Train time for epoch #154 (154 total steps): 2.402085304260254\n",
      "Model test set loss: 0.6923 accuracy: 50.40%\n",
      "loss: tf.Tensor(0.6923188, shape=(), dtype=float32) acc: tf.Tensor(0.50398314, shape=(), dtype=float32)\n",
      "Train time for epoch #155 (155 total steps): 2.388493061065674\n",
      "Model test set loss: 0.6924 accuracy: 50.40%\n",
      "loss: tf.Tensor(0.69241744, shape=(), dtype=float32) acc: tf.Tensor(0.50395745, shape=(), dtype=float32)\n",
      "Train time for epoch #156 (156 total steps): 2.4092671871185303\n",
      "Model test set loss: 0.6926 accuracy: 50.40%\n",
      "loss: tf.Tensor(0.6926266, shape=(), dtype=float32) acc: tf.Tensor(0.50399816, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #157 (157 total steps): 2.439507007598877\n",
      "Model test set loss: 0.6928 accuracy: 50.39%\n",
      "loss: tf.Tensor(0.69277215, shape=(), dtype=float32) acc: tf.Tensor(0.50393987, shape=(), dtype=float32)\n",
      "Train time for epoch #158 (158 total steps): 2.4086358547210693\n",
      "Model test set loss: 0.6928 accuracy: 50.41%\n",
      "loss: tf.Tensor(0.692843, shape=(), dtype=float32) acc: tf.Tensor(0.5041433, shape=(), dtype=float32)\n",
      "Train time for epoch #159 (159 total steps): 2.357584238052368\n",
      "Model test set loss: 0.6926 accuracy: 50.41%\n",
      "loss: tf.Tensor(0.69261, shape=(), dtype=float32) acc: tf.Tensor(0.50411725, shape=(), dtype=float32)\n",
      "Train time for epoch #160 (160 total steps): 2.4057531356811523\n",
      "Model test set loss: 0.6926 accuracy: 50.43%\n",
      "loss: tf.Tensor(0.69258934, shape=(), dtype=float32) acc: tf.Tensor(0.5042848, shape=(), dtype=float32)\n",
      "Train time for epoch #161 (161 total steps): 2.368582248687744\n",
      "Model test set loss: 0.6925 accuracy: 50.42%\n",
      "loss: tf.Tensor(0.6924649, shape=(), dtype=float32) acc: tf.Tensor(0.50416213, shape=(), dtype=float32)\n",
      "Train time for epoch #162 (162 total steps): 2.4168319702148438\n",
      "Model test set loss: 0.6924 accuracy: 50.43%\n",
      "loss: tf.Tensor(0.6923814, shape=(), dtype=float32) acc: tf.Tensor(0.50432736, shape=(), dtype=float32)\n",
      "Train time for epoch #163 (163 total steps): 2.351402997970581\n",
      "Model test set loss: 0.6923 accuracy: 50.44%\n",
      "loss: tf.Tensor(0.6923461, shape=(), dtype=float32) acc: tf.Tensor(0.5043641, shape=(), dtype=float32)\n",
      "Train time for epoch #164 (164 total steps): 2.39906907081604\n",
      "Model test set loss: 0.6924 accuracy: 50.45%\n",
      "loss: tf.Tensor(0.6923558, shape=(), dtype=float32) acc: tf.Tensor(0.504526, shape=(), dtype=float32)\n",
      "Train time for epoch #165 (165 total steps): 2.367281198501587\n",
      "Model test set loss: 0.6924 accuracy: 50.48%\n",
      "loss: tf.Tensor(0.6923907, shape=(), dtype=float32) acc: tf.Tensor(0.50477976, shape=(), dtype=float32)\n",
      "Train time for epoch #166 (166 total steps): 2.4023349285125732\n",
      "Model test set loss: 0.6925 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.6924976, shape=(), dtype=float32) acc: tf.Tensor(0.5047199, shape=(), dtype=float32)\n",
      "Train time for epoch #167 (167 total steps): 2.9273757934570312\n",
      "Model test set loss: 0.6925 accuracy: 50.45%\n",
      "loss: tf.Tensor(0.6925112, shape=(), dtype=float32) acc: tf.Tensor(0.5044756, shape=(), dtype=float32)\n",
      "Train time for epoch #168 (168 total steps): 2.4272170066833496\n",
      "Model test set loss: 0.6926 accuracy: 50.45%\n",
      "loss: tf.Tensor(0.69257873, shape=(), dtype=float32) acc: tf.Tensor(0.5045103, shape=(), dtype=float32)\n",
      "Train time for epoch #169 (169 total steps): 2.383301019668579\n",
      "Model test set loss: 0.6925 accuracy: 50.44%\n",
      "loss: tf.Tensor(0.69252145, shape=(), dtype=float32) acc: tf.Tensor(0.50439215, shape=(), dtype=float32)\n",
      "Train time for epoch #170 (170 total steps): 2.4801652431488037\n",
      "Model test set loss: 0.6925 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.6924732, shape=(), dtype=float32) acc: tf.Tensor(0.5046695, shape=(), dtype=float32)\n",
      "Train time for epoch #171 (171 total steps): 2.3607988357543945\n",
      "Model test set loss: 0.6924 accuracy: 50.48%\n",
      "loss: tf.Tensor(0.6923965, shape=(), dtype=float32) acc: tf.Tensor(0.5047929, shape=(), dtype=float32)\n",
      "Train time for epoch #172 (172 total steps): 2.3575732707977295\n",
      "Model test set loss: 0.6923 accuracy: 50.48%\n",
      "loss: tf.Tensor(0.69232243, shape=(), dtype=float32) acc: tf.Tensor(0.504795, shape=(), dtype=float32)\n",
      "Train time for epoch #173 (173 total steps): 2.4796760082244873\n",
      "Model test set loss: 0.6923 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.6923047, shape=(), dtype=float32) acc: tf.Tensor(0.5047375, shape=(), dtype=float32)\n",
      "Train time for epoch #174 (174 total steps): 2.355682849884033\n",
      "Model test set loss: 0.6923 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.69233996, shape=(), dtype=float32) acc: tf.Tensor(0.50468063, shape=(), dtype=float32)\n",
      "Train time for epoch #175 (175 total steps): 2.4094200134277344\n",
      "Model test set loss: 0.6923 accuracy: 50.44%\n",
      "loss: tf.Tensor(0.69233704, shape=(), dtype=float32) acc: tf.Tensor(0.5044477, shape=(), dtype=float32)\n",
      "Train time for epoch #176 (176 total steps): 2.3758089542388916\n",
      "Model test set loss: 0.6924 accuracy: 50.45%\n",
      "loss: tf.Tensor(0.6923673, shape=(), dtype=float32) acc: tf.Tensor(0.5045103, shape=(), dtype=float32)\n",
      "Train time for epoch #177 (177 total steps): 2.3840172290802\n",
      "Model test set loss: 0.6924 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.69244146, shape=(), dtype=float32) acc: tf.Tensor(0.5047178, shape=(), dtype=float32)\n",
      "Train time for epoch #178 (178 total steps): 2.378960132598877\n",
      "Model test set loss: 0.6927 accuracy: 50.48%\n",
      "loss: tf.Tensor(0.6926532, shape=(), dtype=float32) acc: tf.Tensor(0.5048071, shape=(), dtype=float32)\n",
      "Train time for epoch #179 (179 total steps): 2.392298698425293\n",
      "Model test set loss: 0.6929 accuracy: 50.48%\n",
      "loss: tf.Tensor(0.6929159, shape=(), dtype=float32) acc: tf.Tensor(0.5047515, shape=(), dtype=float32)\n",
      "Train time for epoch #180 (180 total steps): 2.411107063293457\n",
      "Model test set loss: 0.6929 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.6928922, shape=(), dtype=float32) acc: tf.Tensor(0.5046678, shape=(), dtype=float32)\n",
      "Train time for epoch #181 (181 total steps): 2.3811540603637695\n",
      "Model test set loss: 0.6929 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.692903, shape=(), dtype=float32) acc: tf.Tensor(0.5047275, shape=(), dtype=float32)\n",
      "Train time for epoch #182 (182 total steps): 2.4844930171966553\n",
      "Model test set loss: 0.6928 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.6927503, shape=(), dtype=float32) acc: tf.Tensor(0.5047298, shape=(), dtype=float32)\n",
      "Train time for epoch #183 (183 total steps): 2.6304261684417725\n",
      "Model test set loss: 0.6927 accuracy: 50.49%\n",
      "loss: tf.Tensor(0.69267, shape=(), dtype=float32) acc: tf.Tensor(0.5049011, shape=(), dtype=float32)\n",
      "Train time for epoch #184 (184 total steps): 2.3864970207214355\n",
      "Model test set loss: 0.6927 accuracy: 50.47%\n",
      "loss: tf.Tensor(0.69269717, shape=(), dtype=float32) acc: tf.Tensor(0.50467837, shape=(), dtype=float32)\n",
      "Train time for epoch #185 (185 total steps): 2.6081552505493164\n",
      "Model test set loss: 0.6927 accuracy: 50.49%\n",
      "loss: tf.Tensor(0.69272125, shape=(), dtype=float32) acc: tf.Tensor(0.504876, shape=(), dtype=float32)\n",
      "Train time for epoch #186 (186 total steps): 2.526931047439575\n",
      "Model test set loss: 0.6926 accuracy: 50.50%\n",
      "loss: tf.Tensor(0.69261307, shape=(), dtype=float32) acc: tf.Tensor(0.5049884, shape=(), dtype=float32)\n",
      "Train time for epoch #187 (187 total steps): 2.5860848426818848\n",
      "Model test set loss: 0.6925 accuracy: 50.51%\n",
      "loss: tf.Tensor(0.692531, shape=(), dtype=float32) acc: tf.Tensor(0.50509953, shape=(), dtype=float32)\n",
      "Train time for epoch #188 (188 total steps): 2.3527770042419434\n",
      "Model test set loss: 0.6925 accuracy: 50.53%\n",
      "loss: tf.Tensor(0.69245684, shape=(), dtype=float32) acc: tf.Tensor(0.5053192, shape=(), dtype=float32)\n",
      "Train time for epoch #189 (189 total steps): 2.374814987182617\n",
      "Model test set loss: 0.6925 accuracy: 50.53%\n",
      "loss: tf.Tensor(0.6924614, shape=(), dtype=float32) acc: tf.Tensor(0.50526375, shape=(), dtype=float32)\n",
      "Train time for epoch #190 (190 total steps): 2.710784912109375\n",
      "Model test set loss: 0.6924 accuracy: 50.55%\n",
      "loss: tf.Tensor(0.69241166, shape=(), dtype=float32) acc: tf.Tensor(0.50545305, shape=(), dtype=float32)\n",
      "Train time for epoch #191 (191 total steps): 2.9628870487213135\n",
      "Model test set loss: 0.6924 accuracy: 50.54%\n",
      "loss: tf.Tensor(0.69239223, shape=(), dtype=float32) acc: tf.Tensor(0.50537056, shape=(), dtype=float32)\n",
      "Train time for epoch #192 (192 total steps): 2.7293219566345215\n",
      "Model test set loss: 0.6925 accuracy: 50.52%\n",
      "loss: tf.Tensor(0.692542, shape=(), dtype=float32) acc: tf.Tensor(0.5052352, shape=(), dtype=float32)\n",
      "Train time for epoch #193 (193 total steps): 2.34850811958313\n",
      "Model test set loss: 0.6927 accuracy: 50.53%\n",
      "loss: tf.Tensor(0.6926548, shape=(), dtype=float32) acc: tf.Tensor(0.5052615, shape=(), dtype=float32)\n",
      "Train time for epoch #194 (194 total steps): 2.42443585395813\n",
      "Model test set loss: 0.6927 accuracy: 50.51%\n",
      "loss: tf.Tensor(0.6927072, shape=(), dtype=float32) acc: tf.Tensor(0.5051281, shape=(), dtype=float32)\n",
      "Train time for epoch #195 (195 total steps): 2.3669393062591553\n",
      "Model test set loss: 0.6928 accuracy: 50.50%\n",
      "loss: tf.Tensor(0.69275004, shape=(), dtype=float32) acc: tf.Tensor(0.50502247, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #196 (196 total steps): 2.3607659339904785\n",
      "Model test set loss: 0.6927 accuracy: 50.53%\n",
      "loss: tf.Tensor(0.6927086, shape=(), dtype=float32) acc: tf.Tensor(0.50528616, shape=(), dtype=float32)\n",
      "Train time for epoch #197 (197 total steps): 2.4353790283203125\n",
      "Model test set loss: 0.6925 accuracy: 50.54%\n",
      "loss: tf.Tensor(0.69245446, shape=(), dtype=float32) acc: tf.Tensor(0.5054163, shape=(), dtype=float32)\n",
      "Train time for epoch #198 (198 total steps): 2.417189836502075\n",
      "Model test set loss: 0.6924 accuracy: 50.53%\n",
      "loss: tf.Tensor(0.6923752, shape=(), dtype=float32) acc: tf.Tensor(0.5052848, shape=(), dtype=float32)\n",
      "Train time for epoch #199 (199 total steps): 2.409574270248413\n",
      "Model test set loss: 0.6924 accuracy: 50.54%\n",
      "loss: tf.Tensor(0.69238615, shape=(), dtype=float32) acc: tf.Tensor(0.5053878, shape=(), dtype=float32)\n",
      "Train time for epoch #200 (200 total steps): 2.363121747970581\n",
      "Model test set loss: 0.6924 accuracy: 50.54%\n",
      "loss: tf.Tensor(0.6923847, shape=(), dtype=float32) acc: tf.Tensor(0.5053866, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_EPOCHS = 200\n",
    "\n",
    "for i in range(NUM_TRAIN_EPOCHS):\n",
    "    start = time.time()\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((trainX, trainy))\n",
    "    train_ds = train_ds.shuffle(200).batch(100)\n",
    "    #   with train_summary_writer.as_default():\n",
    "    train(CNN_model, optimizer, train_ds, log_freq=500)\n",
    "    end = time.time()\n",
    "    print('Train time for epoch #{} ({} total steps): {}'.format(\n",
    "        i + 1, int(optimizer.iterations), end - start))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((testX, testy))\n",
    "    test_ds = test_ds.batch(80)\n",
    "    test(CNN_model, test_ds, optimizer.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: CNN_model_covid_pneumonia/assets\n"
     ]
    }
   ],
   "source": [
    "CNN_model.save('CNN_model_covid_pneumonia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet \n",
    "\n",
    "Here we train a tf.keras implementation of ResNet-18\n",
    "\n",
    "Includes cell dividers for running with IPython!\n",
    "\n",
    "![](resnet.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(channels, stride=1, kernel=(3, 3)):\n",
    "    return keras.layers.Conv2D(channels, kernel, strides=stride, padding='same',\n",
    "                               use_bias=False,\n",
    "                            kernel_initializer=tf.random_normal_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(keras.Model):\n",
    "\n",
    "    def __init__(self, channels, strides=1, residual_path=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.residual_path = residual_path\n",
    "\n",
    "        self.conv1 = conv3x3(channels, strides)\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = conv3x3(channels)\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "\n",
    "        if residual_path:\n",
    "            self.down_conv = conv3x3(channels, strides, kernel=(1, 1))\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.bn1(inputs, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # this module can be added into self.\n",
    "        # however, module in for can not be added.\n",
    "        if self.residual_path:\n",
    "            residual = self.down_bn(inputs, training=training)\n",
    "            residual = tf.nn.relu(residual)\n",
    "            residual = self.down_conv(residual)\n",
    "\n",
    "        x = x + residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(keras.Model):\n",
    "\n",
    "    def __init__(self, block_list, num_classes, initial_filters=16, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_blocks = len(block_list)\n",
    "        self.block_list = block_list\n",
    "\n",
    "        self.in_channels = initial_filters\n",
    "        self.out_channels = initial_filters\n",
    "        self.conv_initial = conv3x3(self.out_channels)\n",
    "\n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "\n",
    "        # build all the blocks\n",
    "        for block_id in range(len(block_list)):\n",
    "            for layer_id in range(block_list[block_id]):\n",
    "\n",
    "                if block_id != 0 and layer_id == 0:\n",
    "                    block = ResnetBlock(self.out_channels, strides=2, residual_path=True)\n",
    "                else:\n",
    "                    if self.in_channels != self.out_channels:\n",
    "                        residual_path = True\n",
    "                    else:\n",
    "                        residual_path = False\n",
    "                    block = ResnetBlock(self.out_channels, residual_path=residual_path)\n",
    "\n",
    "                self.in_channels = self.out_channels\n",
    "\n",
    "                self.blocks.add(block)\n",
    "\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.final_bn = keras.layers.BatchNormalization()\n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        out = self.conv_initial(inputs)\n",
    "\n",
    "        out = self.blocks(out, training=training)\n",
    "\n",
    "        out = self.final_bn(out, training=training)\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in the model : 297\n",
      "Model: \"res_net_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           multiple                  432       \n",
      "_________________________________________________________________\n",
      "dynamic-blocks (Sequential)  multiple                  501760    \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat multiple                  256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  195       \n",
      "=================================================================\n",
      "Total params: 502,643\n",
      "Trainable params: 499,443\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n",
      "Train on 97 samples, validate on 97 samples\n",
      "Epoch 1/200\n",
      "97/97 [==============================] - 189s 2s/sample - loss: 1.0074 - accuracy: 0.5773 - val_loss: 55.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.6107 - accuracy: 0.7938 - val_loss: 99.9637 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "97/97 [==============================] - 176s 2s/sample - loss: 0.4258 - accuracy: 0.8969 - val_loss: 160.3505 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "97/97 [==============================] - 177s 2s/sample - loss: 0.4032 - accuracy: 0.8866 - val_loss: 163.9037 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "97/97 [==============================] - 180s 2s/sample - loss: 0.3228 - accuracy: 0.9485 - val_loss: 90.5695 - val_accuracy: 0.0309\n",
      "Epoch 6/200\n",
      "97/97 [==============================] - 179s 2s/sample - loss: 0.2945 - accuracy: 0.9072 - val_loss: 57.9668 - val_accuracy: 0.4845\n",
      "Epoch 7/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.2667 - accuracy: 0.8969 - val_loss: 34.3318 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "97/97 [==============================] - 176s 2s/sample - loss: 0.2391 - accuracy: 0.9588 - val_loss: 21.2189 - val_accuracy: 0.0309\n",
      "Epoch 9/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.2024 - accuracy: 0.9691 - val_loss: 26.2116 - val_accuracy: 0.4845\n",
      "Epoch 10/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.2702 - accuracy: 0.9278 - val_loss: 34.2052 - val_accuracy: 0.4845\n",
      "Epoch 11/200\n",
      "97/97 [==============================] - 187s 2s/sample - loss: 0.1892 - accuracy: 0.9485 - val_loss: 31.8382 - val_accuracy: 0.4845\n",
      "Epoch 12/200\n",
      "97/97 [==============================] - 183s 2s/sample - loss: 0.1835 - accuracy: 0.9794 - val_loss: 20.1067 - val_accuracy: 0.4845\n",
      "Epoch 13/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.1584 - accuracy: 0.9794 - val_loss: 17.7230 - val_accuracy: 0.4948\n",
      "Epoch 14/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.1247 - accuracy: 1.0000 - val_loss: 16.4313 - val_accuracy: 0.5052\n",
      "Epoch 15/200\n",
      "97/97 [==============================] - 177s 2s/sample - loss: 0.1457 - accuracy: 0.9588 - val_loss: 8.6630 - val_accuracy: 0.5258\n",
      "Epoch 16/200\n",
      "97/97 [==============================] - 179s 2s/sample - loss: 0.1860 - accuracy: 0.9485 - val_loss: 20.9495 - val_accuracy: 0.5155\n",
      "Epoch 17/200\n",
      "97/97 [==============================] - 186s 2s/sample - loss: 0.1660 - accuracy: 0.9794 - val_loss: 5.7151 - val_accuracy: 0.5155\n",
      "Epoch 18/200\n",
      "97/97 [==============================] - 174s 2s/sample - loss: 0.1254 - accuracy: 0.9897 - val_loss: 9.5674 - val_accuracy: 0.5464\n",
      "Epoch 19/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1443 - accuracy: 0.9691 - val_loss: 4.7096 - val_accuracy: 0.6082\n",
      "Epoch 20/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1128 - accuracy: 0.9897 - val_loss: 4.0889 - val_accuracy: 0.5876\n",
      "Epoch 21/200\n",
      "97/97 [==============================] - 177s 2s/sample - loss: 0.1280 - accuracy: 0.9897 - val_loss: 4.2792 - val_accuracy: 0.6392\n",
      "Epoch 22/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1760 - accuracy: 0.9588 - val_loss: 1.9199 - val_accuracy: 0.7732\n",
      "Epoch 23/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1419 - accuracy: 0.9794 - val_loss: 8.0118 - val_accuracy: 0.6392\n",
      "Epoch 24/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1504 - accuracy: 0.9691 - val_loss: 12.6541 - val_accuracy: 0.5361\n",
      "Epoch 25/200\n",
      "97/97 [==============================] - 171s 2s/sample - loss: 0.1378 - accuracy: 0.9691 - val_loss: 6.2469 - val_accuracy: 0.6082\n",
      "Epoch 26/200\n",
      "97/97 [==============================] - 174s 2s/sample - loss: 0.1349 - accuracy: 0.9794 - val_loss: 1.3202 - val_accuracy: 0.8144\n",
      "Epoch 27/200\n",
      "97/97 [==============================] - 173s 2s/sample - loss: 0.1300 - accuracy: 0.9794 - val_loss: 1.6890 - val_accuracy: 0.8557\n",
      "Epoch 28/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1393 - accuracy: 0.9794 - val_loss: 1.4430 - val_accuracy: 0.8454\n",
      "Epoch 29/200\n",
      "97/97 [==============================] - 171s 2s/sample - loss: 0.1184 - accuracy: 0.9691 - val_loss: 2.8389 - val_accuracy: 0.6082\n",
      "Epoch 30/200\n",
      "97/97 [==============================] - 171s 2s/sample - loss: 0.0848 - accuracy: 1.0000 - val_loss: 4.8105 - val_accuracy: 0.5052\n",
      "Epoch 31/200\n",
      "97/97 [==============================] - 173s 2s/sample - loss: 0.0828 - accuracy: 1.0000 - val_loss: 8.0084 - val_accuracy: 0.4948\n",
      "Epoch 32/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1185 - accuracy: 0.9588 - val_loss: 8.3043 - val_accuracy: 0.4845\n",
      "Epoch 33/200\n",
      "97/97 [==============================] - 177s 2s/sample - loss: 0.1123 - accuracy: 0.9794 - val_loss: 21.9039 - val_accuracy: 0.4845\n",
      "Epoch 34/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.0982 - accuracy: 0.9897 - val_loss: 59.9210 - val_accuracy: 0.4845\n",
      "Epoch 35/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.0874 - accuracy: 0.9794 - val_loss: 89.5122 - val_accuracy: 0.4845\n",
      "Epoch 36/200\n",
      "97/97 [==============================] - 171s 2s/sample - loss: 0.0994 - accuracy: 0.9897 - val_loss: 97.0112 - val_accuracy: 0.4845\n",
      "Epoch 37/200\n",
      "97/97 [==============================] - 173s 2s/sample - loss: 0.1085 - accuracy: 0.9794 - val_loss: 65.0442 - val_accuracy: 0.4948\n",
      "Epoch 38/200\n",
      "97/97 [==============================] - 187s 2s/sample - loss: 0.2341 - accuracy: 0.9072 - val_loss: 14.0473 - val_accuracy: 0.6598\n",
      "Epoch 39/200\n",
      "97/97 [==============================] - 174s 2s/sample - loss: 0.1496 - accuracy: 0.9588 - val_loss: 220.6130 - val_accuracy: 0.5155\n",
      "Epoch 40/200\n",
      "97/97 [==============================] - 176s 2s/sample - loss: 0.1624 - accuracy: 0.9588 - val_loss: 184.9170 - val_accuracy: 0.5155\n",
      "Epoch 41/200\n",
      "97/97 [==============================] - 180s 2s/sample - loss: 0.1333 - accuracy: 0.9691 - val_loss: 50.6912 - val_accuracy: 0.5155\n",
      "Epoch 42/200\n",
      "97/97 [==============================] - 174s 2s/sample - loss: 0.1941 - accuracy: 0.9381 - val_loss: 33.4618 - val_accuracy: 0.6392\n",
      "Epoch 43/200\n",
      "97/97 [==============================] - 177s 2s/sample - loss: 0.1374 - accuracy: 0.9691 - val_loss: 34.7124 - val_accuracy: 0.6701\n",
      "Epoch 44/200\n",
      "97/97 [==============================] - 175s 2s/sample - loss: 0.1239 - accuracy: 0.9691 - val_loss: 8.5222 - val_accuracy: 0.7629\n",
      "Epoch 45/200\n",
      "97/97 [==============================] - 178s 2s/sample - loss: 0.1044 - accuracy: 0.9794 - val_loss: 8.8018 - val_accuracy: 0.7010\n",
      "Epoch 46/200\n",
      "97/97 [==============================] - 176s 2s/sample - loss: 0.1200 - accuracy: 0.9794 - val_loss: 23.2595 - val_accuracy: 0.5258\n",
      "Epoch 47/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.1423 - accuracy: 0.9588 - val_loss: 4.1713 - val_accuracy: 0.8247\n",
      "Epoch 48/200\n",
      "97/97 [==============================] - 173s 2s/sample - loss: 0.0851 - accuracy: 0.9897 - val_loss: 4.2838 - val_accuracy: 0.8041\n",
      "Epoch 49/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.0791 - accuracy: 0.9794 - val_loss: 9.4118 - val_accuracy: 0.7010\n",
      "Epoch 50/200\n",
      "97/97 [==============================] - 184s 2s/sample - loss: 0.0738 - accuracy: 0.9897 - val_loss: 18.7719 - val_accuracy: 0.5464\n",
      "Epoch 51/200\n",
      "97/97 [==============================] - 173s 2s/sample - loss: 0.0694 - accuracy: 0.9897 - val_loss: 25.3706 - val_accuracy: 0.4845\n",
      "Epoch 52/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.0766 - accuracy: 0.9794 - val_loss: 21.3849 - val_accuracy: 0.4845\n",
      "Epoch 53/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.0518 - accuracy: 1.0000 - val_loss: 13.5854 - val_accuracy: 0.4845\n",
      "Epoch 54/200\n",
      "97/97 [==============================] - 171s 2s/sample - loss: 0.0570 - accuracy: 0.9897 - val_loss: 8.6759 - val_accuracy: 0.5052\n",
      "Epoch 55/200\n",
      "97/97 [==============================] - 174s 2s/sample - loss: 0.0579 - accuracy: 1.0000 - val_loss: 8.5339 - val_accuracy: 0.5155\n",
      "Epoch 56/200\n",
      "97/97 [==============================] - 172s 2s/sample - loss: 0.0487 - accuracy: 1.0000 - val_loss: 6.2231 - val_accuracy: 0.5670\n",
      "Epoch 57/200\n",
      "97/97 [==============================] - 175s 2s/sample - loss: 0.0618 - accuracy: 0.9897 - val_loss: 4.6140 - val_accuracy: 0.5361\n",
      "Epoch 58/200\n",
      "97/97 [==============================] - 173s 2s/sample - loss: 0.0672 - accuracy: 0.9897 - val_loss: 10.4017 - val_accuracy: 0.4845\n",
      "Epoch 59/200\n",
      "97/97 [==============================] - 171s 2s/sample - loss: 0.0656 - accuracy: 1.0000 - val_loss: 6.5799 - val_accuracy: 0.5155\n",
      "Epoch 60/200\n",
      "97/97 [==============================] - 174s 2s/sample - loss: 0.0786 - accuracy: 0.9794 - val_loss: 0.3194 - val_accuracy: 0.9072\n",
      "Epoch 61/200\n",
      "32/97 [========>.....................] - ETA: 29:45"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-670cc564c80d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m ResNet_model.fit(trainX, y_ohe, batch_size=batch_size, epochs=epochs,\n\u001b[0;32m---> 19\u001b[0;31m           validation_data=(testX, testy_ohe), verbose=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "# build model and optimizer\n",
    "ResNet_model = ResNet([16, 8, 4], num_classes)\n",
    "ResNet_model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "ResNet_model.build(input_shape=(None, 200,200,3))\n",
    "print(\"Number of variables in the model :\", len(ResNet_model.variables))\n",
    "ResNet_model.summary()\n",
    "\n",
    "y_ohe = tf.one_hot(trainy, depth=3).numpy()\n",
    "testy_ohe = tf.one_hot(testy, depth=3).numpy()\n",
    "\n",
    "# train\n",
    "ResNet_model.fit(trainX, y_ohe, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(testX, testy_ohe), verbose=1)\n",
    "\n",
    "# evaluate on test set\n",
    "scores = ResNet_model.evaluate(testX, testy_ohe, batch_size, verbose=1)\n",
    "print(\"Final test loss and accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ResNet_Model_Covid_Pneumonia/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(ResNet_model,'ResNet_Model_Covid_Pneumonia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16\n",
    "\n",
    "Fitting a VGG-16 network for image classification!\n",
    "We use gradient clipping for faster convergence.\n",
    "\n",
    "A complete implementation of VGG-16 is available in network.py\n",
    "\n",
    "![](vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(models.Model):\n",
    "\n",
    "\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_shape: [32, 32, 3]\n",
    "        \"\"\"\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        weight_decay = 0.000\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=input_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(self.num_classes))\n",
    "        # model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 1.0220255851745605 acc: 0.5154639\n",
      "test acc: 0.48453608\n",
      "1 0 loss: 1.2034764289855957 acc: 0.48453608\n",
      "test acc: 0.5154639\n",
      "2 0 loss: 2.202988624572754 acc: 0.5154639\n",
      "test acc: 0.52577317\n",
      "3 0 loss: 0.645288348197937 acc: 0.556701\n",
      "test acc: 0.48453608\n",
      "4 0 loss: 0.7542040944099426 acc: 0.48453608\n",
      "test acc: 0.48453608\n",
      "5 0 loss: 0.6500425338745117 acc: 0.49484536\n",
      "test acc: 0.5154639\n",
      "6 0 loss: 0.634027361869812 acc: 0.556701\n",
      "test acc: 0.62886596\n",
      "7 0 loss: 0.5975534915924072 acc: 0.68041235\n",
      "test acc: 0.9484536\n",
      "8 0 loss: 0.5367076396942139 acc: 0.96907216\n",
      "test acc: 0.88659793\n",
      "9 0 loss: 0.4725761413574219 acc: 0.9484536\n",
      "test acc: 0.9072165\n",
      "10 0 loss: 0.37413936853408813 acc: 0.9587629\n",
      "test acc: 0.9484536\n",
      "11 0 loss: 0.25634706020355225 acc: 0.97938144\n",
      "test acc: 0.8969072\n",
      "12 0 loss: 0.20906873047351837 acc: 0.9587629\n",
      "test acc: 0.6082474\n",
      "13 0 loss: 0.6709789037704468 acc: 0.6494845\n",
      "test acc: 0.9587629\n",
      "14 0 loss: 0.0733010321855545 acc: 0.96907216\n",
      "test acc: 0.8453608\n",
      "15 0 loss: 0.3378726541996002 acc: 0.7938144\n",
      "test acc: 0.9484536\n",
      "16 0 loss: 0.08308956027030945 acc: 0.9896907\n",
      "test acc: 0.8659794\n",
      "17 0 loss: 0.2193550169467926 acc: 0.91752577\n",
      "test acc: 0.96907216\n",
      "18 0 loss: 0.05324726924300194 acc: 0.97938144\n",
      "test acc: 0.88659793\n",
      "19 0 loss: 0.14662568271160126 acc: 0.9484536\n",
      "test acc: 0.9587629\n",
      "20 0 loss: 0.05331561341881752 acc: 0.96907216\n",
      "test acc: 0.97938144\n",
      "21 0 loss: 0.06279326230287552 acc: 0.9896907\n",
      "test acc: 0.9484536\n",
      "22 0 loss: 0.08848001807928085 acc: 0.97938144\n",
      "test acc: 0.9896907\n",
      "23 0 loss: 0.04334143176674843 acc: 0.9896907\n",
      "test acc: 0.9381443\n",
      "24 0 loss: 0.032832637429237366 acc: 0.9896907\n",
      "test acc: 0.91752577\n",
      "25 0 loss: 0.05430612713098526 acc: 0.97938144\n",
      "test acc: 0.9381443\n",
      "26 0 loss: 0.0306999534368515 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "27 0 loss: 0.02205990068614483 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "28 0 loss: 0.028571218252182007 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "29 0 loss: 0.028125334531068802 acc: 0.9896907\n",
      "test acc: 0.96907216\n",
      "30 0 loss: 0.01809847168624401 acc: 0.9896907\n",
      "test acc: 0.9381443\n",
      "31 0 loss: 0.010392257943749428 acc: 1.0\n",
      "test acc: 0.92783505\n",
      "32 0 loss: 0.014264529570937157 acc: 1.0\n",
      "test acc: 0.92783505\n",
      "33 0 loss: 0.013800641521811485 acc: 1.0\n",
      "test acc: 0.92783505\n",
      "34 0 loss: 0.007265944965183735 acc: 1.0\n",
      "test acc: 0.9587629\n",
      "35 0 loss: 0.004336483310908079 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "36 0 loss: 0.005647770594805479 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "37 0 loss: 0.006625000387430191 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "38 0 loss: 0.00426187738776207 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "39 0 loss: 0.001996597507968545 acc: 1.0\n",
      "test acc: 0.9484536\n",
      "40 0 loss: 0.0015996714355424047 acc: 1.0\n",
      "test acc: 0.92783505\n",
      "41 0 loss: 0.0020887358114123344 acc: 1.0\n",
      "test acc: 0.92783505\n",
      "42 0 loss: 0.002462671371176839 acc: 1.0\n",
      "test acc: 0.92783505\n",
      "43 0 loss: 0.0021159453317523003 acc: 1.0\n",
      "test acc: 0.9381443\n",
      "44 0 loss: 0.0013670320622622967 acc: 1.0\n",
      "test acc: 0.9484536\n",
      "45 0 loss: 0.0007873200811445713 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "46 0 loss: 0.0005227300571277738 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "47 0 loss: 0.0004885828238911927 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "48 0 loss: 0.0005795892793685198 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "49 0 loss: 0.0006806018645875156 acc: 1.0\n",
      "test acc: 0.96907216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1b478ad64bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVGG16_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# MUST clip gradient here or it will disconverge!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    604\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    607\u001b[0m   ]\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VGG16_model = VGG16([200, 200, 3], 3)\n",
    "\n",
    "\n",
    "# must specify from_logits=True!\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((trainX, trainy)).batch(256)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(256)\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    for step, (x, y) in enumerate(db_train):\n",
    "        # [b, 1] => [b]\n",
    "        # y = tf.squeeze(y, axis=1)\n",
    "        # [b, 10]\n",
    "        y = tf.one_hot(y, depth=3)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = VGG16_model(x)\n",
    "            loss = criteon(y, logits)\n",
    "            # loss2 = compute_loss(logits, tf.argmax(y, axis=1))\n",
    "            # mse_loss = tf.reduce_sum(tf.square(y-logits))\n",
    "            # print(y.shape, logits.shape)\n",
    "            metric.update_state(y, logits)\n",
    "\n",
    "        grads = tape.gradient(loss, VGG16_model.trainable_variables)\n",
    "        # MUST clip gradient here or it will disconverge!\n",
    "        grads = [ tf.clip_by_norm(g, 15) for g in grads]\n",
    "        optimizer.apply_gradients(zip(grads, VGG16_model.trainable_variables))\n",
    "\n",
    "        if step % 40 == 0:\n",
    "            # for g in grads:\n",
    "            #     print(tf.norm(g).numpy())\n",
    "            print(epoch, step, 'loss:', float(loss), 'acc:', metric.result().numpy())\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "\n",
    "        metric = keras.metrics.CategoricalAccuracy()\n",
    "        for x, y in db_test:\n",
    "            # [b, 1] => [b]\n",
    "            # y = tf.squeeze(y, axis=1)\n",
    "            # [b, 10]\n",
    "            y = tf.one_hot(y, depth=3)\n",
    "\n",
    "            logits = VGG16_model.predict(x)\n",
    "            # be careful, these functions can accept y as [b] without warnning.\n",
    "            metric.update_state(y, logits)\n",
    "        print('test acc:', metric.result().numpy())\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_Model_Covid_Pneumonia/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(VGG16_model,'VGG16_Model_Covid_Pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
