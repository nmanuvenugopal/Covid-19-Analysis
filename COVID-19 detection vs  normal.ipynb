{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from os.path import isdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(filename, required_size=(200, 200)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    image = image.resize(required_size)\n",
    "    pixels = asarray(image, dtype=np.float32)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        img = extract_images(path)\n",
    "        # store\n",
    "        images.append(img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in ['Covid', 'NORMAL']:\n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_images(path)\n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 94 examples for class: Covid\n",
      ">loaded 100 examples for class: NORMAL\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy = load_dataset('xray_dataset_covid19/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "trainy = le.fit_transform(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 200, 200, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainy, testy = train_test_split(trainX, trainy, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 200, 200, 3), (97,), (97, 200, 200, 3), (97,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainy.shape,testX.shape,testy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "\n",
    "Now that we've gotten our feet we with a simple DNN, let's try something more advanced. Although the process is the same, we'll be working with some additional features:\n",
    "- Convolution, pooling, and dropout layers for building more complex models\n",
    "- Visualizing training with TensorBoard\n",
    "- Validation and test set evaluation for measuring generalizability\n",
    "- Exporting with SavedModel to save training progress and deploy trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = tf.keras.Sequential([\n",
    "    layers.Reshape(\n",
    "        target_shape=[200, 200, 3],\n",
    "        input_shape=(200, 200,3)),\n",
    "    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation=tf.nn.relu),\n",
    "    layers.Dropout(rate=0.4),\n",
    "    layers.Dense(3)])\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, images, labels):\n",
    "\n",
    "    # Record the operations used to compute the loss, so that the gradient\n",
    "    # of the loss with respect to the variables can be computed.\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(images, training=True)\n",
    "        loss = compute_loss(labels, logits)\n",
    "        compute_accuracy(labels, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataset, log_freq=50):\n",
    "    \"\"\"\n",
    "    Trains model on `dataset` using `optimizer`.\n",
    "    \"\"\"\n",
    "    # Metrics are stateful. They accumulate values and return a cumulative\n",
    "    # result when you call .result(). Clear accumulated values with .reset_states()\n",
    "    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "    # Datasets can be iterated over like any other Python iterable.\n",
    "    for images, labels in dataset:\n",
    "        loss = train_step(model, optimizer, images, labels)\n",
    "        avg_loss(loss)\n",
    "\n",
    "        if tf.equal(optimizer.iterations % log_freq, 0):\n",
    "            # summary_ops_v2.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
    "            # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=optimizer.iterations)\n",
    "            print('step:', int(optimizer.iterations),\n",
    "                  'loss:', avg_loss.result().numpy(),\n",
    "                  'acc:', compute_accuracy.result().numpy())\n",
    "            avg_loss.reset_states()\n",
    "            compute_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, step_num):\n",
    "    \"\"\"\n",
    "    Perform an evaluation of `model` on the examples from `dataset`.\n",
    "    \"\"\"\n",
    "    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n",
    "\n",
    "    for (images, labels) in dataset:\n",
    "        logits = model(images, training=False)\n",
    "        avg_loss(compute_loss(labels, logits))\n",
    "        compute_accuracy(labels, logits)\n",
    "\n",
    "    print('Model test set loss: {:0.4f} accuracy: {:0.2f}%'.format(\n",
    "        avg_loss.result(), compute_accuracy.result() * 100))\n",
    "\n",
    "    print('loss:', avg_loss.result(), 'acc:', compute_accuracy.result())\n",
    "    # summary_ops_v2.scalar('loss', avg_loss.result(), step=step_num)\n",
    "    # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=step_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #1 (1 total steps): 2.43776798248291\n",
      "Model test set loss: 1.8741 accuracy: 51.55%\n",
      "loss: tf.Tensor(1.87413, shape=(), dtype=float32) acc: tf.Tensor(0.5154639, shape=(), dtype=float32)\n",
      "Train time for epoch #2 (2 total steps): 2.2177484035491943\n",
      "Model test set loss: 1.5606 accuracy: 52.84%\n",
      "loss: tf.Tensor(1.5606363, shape=(), dtype=float32) acc: tf.Tensor(0.52835053, shape=(), dtype=float32)\n",
      "Train time for epoch #3 (3 total steps): 2.021822929382324\n",
      "Model test set loss: 1.1231 accuracy: 56.01%\n",
      "loss: tf.Tensor(1.1231394, shape=(), dtype=float32) acc: tf.Tensor(0.56013745, shape=(), dtype=float32)\n",
      "Train time for epoch #4 (4 total steps): 2.000344753265381\n",
      "Model test set loss: 1.0319 accuracy: 58.12%\n",
      "loss: tf.Tensor(1.0318534, shape=(), dtype=float32) acc: tf.Tensor(0.5811856, shape=(), dtype=float32)\n",
      "Train time for epoch #5 (5 total steps): 2.033550977706909\n",
      "Model test set loss: 1.0130 accuracy: 61.24%\n",
      "loss: tf.Tensor(1.013025, shape=(), dtype=float32) acc: tf.Tensor(0.61237115, shape=(), dtype=float32)\n",
      "Train time for epoch #6 (6 total steps): 2.0939080715179443\n",
      "Model test set loss: 0.8826 accuracy: 62.89%\n",
      "loss: tf.Tensor(0.8826473, shape=(), dtype=float32) acc: tf.Tensor(0.62886596, shape=(), dtype=float32)\n",
      "Train time for epoch #7 (7 total steps): 2.065984010696411\n",
      "Model test set loss: 0.8784 accuracy: 62.15%\n",
      "loss: tf.Tensor(0.8784497, shape=(), dtype=float32) acc: tf.Tensor(0.6215022, shape=(), dtype=float32)\n",
      "Train time for epoch #8 (8 total steps): 2.13828182220459\n",
      "Model test set loss: 0.9775 accuracy: 62.24%\n",
      "loss: tf.Tensor(0.97750986, shape=(), dtype=float32) acc: tf.Tensor(0.6224227, shape=(), dtype=float32)\n",
      "Train time for epoch #9 (9 total steps): 2.309122085571289\n",
      "Model test set loss: 0.9818 accuracy: 63.86%\n",
      "loss: tf.Tensor(0.9818198, shape=(), dtype=float32) acc: tf.Tensor(0.6386025, shape=(), dtype=float32)\n",
      "Train time for epoch #10 (10 total steps): 2.206130027770996\n",
      "Model test set loss: 0.8944 accuracy: 65.21%\n",
      "loss: tf.Tensor(0.8944395, shape=(), dtype=float32) acc: tf.Tensor(0.6520619, shape=(), dtype=float32)\n",
      "Train time for epoch #11 (11 total steps): 2.1779000759124756\n",
      "Model test set loss: 0.9910 accuracy: 64.71%\n",
      "loss: tf.Tensor(0.99103045, shape=(), dtype=float32) acc: tf.Tensor(0.6471415, shape=(), dtype=float32)\n",
      "Train time for epoch #12 (12 total steps): 2.29119610786438\n",
      "Model test set loss: 0.9867 accuracy: 65.38%\n",
      "loss: tf.Tensor(0.9867377, shape=(), dtype=float32) acc: tf.Tensor(0.65378004, shape=(), dtype=float32)\n",
      "Train time for epoch #13 (13 total steps): 2.221115827560425\n",
      "Model test set loss: 0.9938 accuracy: 66.10%\n",
      "loss: tf.Tensor(0.993803, shape=(), dtype=float32) acc: tf.Tensor(0.6609833, shape=(), dtype=float32)\n",
      "Train time for epoch #14 (14 total steps): 2.2022788524627686\n",
      "Model test set loss: 1.0130 accuracy: 66.75%\n",
      "loss: tf.Tensor(1.0130284, shape=(), dtype=float32) acc: tf.Tensor(0.66752577, shape=(), dtype=float32)\n",
      "Train time for epoch #15 (15 total steps): 2.220306158065796\n",
      "Model test set loss: 1.0366 accuracy: 67.32%\n",
      "loss: tf.Tensor(1.0366435, shape=(), dtype=float32) acc: tf.Tensor(0.6731959, shape=(), dtype=float32)\n",
      "Train time for epoch #16 (16 total steps): 2.2611887454986572\n",
      "Model test set loss: 1.0741 accuracy: 67.88%\n",
      "loss: tf.Tensor(1.0740806, shape=(), dtype=float32) acc: tf.Tensor(0.67880154, shape=(), dtype=float32)\n",
      "Train time for epoch #17 (17 total steps): 2.459796190261841\n",
      "Model test set loss: 1.0951 accuracy: 68.44%\n",
      "loss: tf.Tensor(1.0951113, shape=(), dtype=float32) acc: tf.Tensor(0.6843541, shape=(), dtype=float32)\n",
      "Train time for epoch #18 (18 total steps): 2.3066070079803467\n",
      "Model test set loss: 1.1045 accuracy: 68.96%\n",
      "loss: tf.Tensor(1.1044637, shape=(), dtype=float32) acc: tf.Tensor(0.68957615, shape=(), dtype=float32)\n",
      "Train time for epoch #19 (19 total steps): 2.2806670665740967\n",
      "Model test set loss: 1.1586 accuracy: 69.37%\n",
      "loss: tf.Tensor(1.1585977, shape=(), dtype=float32) acc: tf.Tensor(0.6937059, shape=(), dtype=float32)\n",
      "Train time for epoch #20 (20 total steps): 2.2800722122192383\n",
      "Model test set loss: 1.1362 accuracy: 69.87%\n",
      "loss: tf.Tensor(1.1361732, shape=(), dtype=float32) acc: tf.Tensor(0.69871134, shape=(), dtype=float32)\n",
      "Train time for epoch #21 (21 total steps): 2.3663179874420166\n",
      "Model test set loss: 1.1276 accuracy: 70.23%\n",
      "loss: tf.Tensor(1.1276221, shape=(), dtype=float32) acc: tf.Tensor(0.7022582, shape=(), dtype=float32)\n",
      "Train time for epoch #22 (22 total steps): 2.561047077178955\n",
      "Model test set loss: 1.0441 accuracy: 70.69%\n",
      "loss: tf.Tensor(1.044146, shape=(), dtype=float32) acc: tf.Tensor(0.7068885, shape=(), dtype=float32)\n",
      "Train time for epoch #23 (23 total steps): 2.3362419605255127\n",
      "Model test set loss: 1.0231 accuracy: 71.13%\n",
      "loss: tf.Tensor(1.0230864, shape=(), dtype=float32) acc: tf.Tensor(0.7113402, shape=(), dtype=float32)\n",
      "Train time for epoch #24 (24 total steps): 2.309253215789795\n",
      "Model test set loss: 1.0157 accuracy: 71.59%\n",
      "loss: tf.Tensor(1.0156844, shape=(), dtype=float32) acc: tf.Tensor(0.71585053, shape=(), dtype=float32)\n",
      "Train time for epoch #25 (25 total steps): 2.3790500164031982\n",
      "Model test set loss: 1.0025 accuracy: 71.98%\n",
      "loss: tf.Tensor(1.0025148, shape=(), dtype=float32) acc: tf.Tensor(0.7197938, shape=(), dtype=float32)\n",
      "Train time for epoch #26 (26 total steps): 2.3383548259735107\n",
      "Model test set loss: 0.9941 accuracy: 72.46%\n",
      "loss: tf.Tensor(0.9940702, shape=(), dtype=float32) acc: tf.Tensor(0.7246233, shape=(), dtype=float32)\n",
      "Train time for epoch #27 (27 total steps): 2.4006640911102295\n",
      "Model test set loss: 0.9759 accuracy: 72.74%\n",
      "loss: tf.Tensor(0.9759155, shape=(), dtype=float32) acc: tf.Tensor(0.7273769, shape=(), dtype=float32)\n",
      "Train time for epoch #28 (28 total steps): 2.5319018363952637\n",
      "Model test set loss: 0.9760 accuracy: 73.10%\n",
      "loss: tf.Tensor(0.97604144, shape=(), dtype=float32) acc: tf.Tensor(0.7310383, shape=(), dtype=float32)\n",
      "Train time for epoch #29 (29 total steps): 2.38687801361084\n",
      "Model test set loss: 1.0132 accuracy: 73.46%\n",
      "loss: tf.Tensor(1.0132172, shape=(), dtype=float32) acc: tf.Tensor(0.734625, shape=(), dtype=float32)\n",
      "Train time for epoch #30 (30 total steps): 2.4102861881256104\n",
      "Model test set loss: 0.9789 accuracy: 73.76%\n",
      "loss: tf.Tensor(0.9789101, shape=(), dtype=float32) acc: tf.Tensor(0.7376289, shape=(), dtype=float32)\n",
      "Train time for epoch #31 (31 total steps): 2.4116079807281494\n",
      "Model test set loss: 0.9964 accuracy: 74.06%\n",
      "loss: tf.Tensor(0.9964012, shape=(), dtype=float32) acc: tf.Tensor(0.74060524, shape=(), dtype=float32)\n",
      "Train time for epoch #32 (32 total steps): 2.4069979190826416\n",
      "Model test set loss: 1.0198 accuracy: 74.32%\n",
      "loss: tf.Tensor(1.0198038, shape=(), dtype=float32) acc: tf.Tensor(0.7432345, shape=(), dtype=float32)\n",
      "Train time for epoch #33 (33 total steps): 2.3966591358184814\n",
      "Model test set loss: 1.0245 accuracy: 74.60%\n",
      "loss: tf.Tensor(1.024521, shape=(), dtype=float32) acc: tf.Tensor(0.74601686, shape=(), dtype=float32)\n",
      "Train time for epoch #34 (34 total steps): 2.3851778507232666\n",
      "Model test set loss: 1.0625 accuracy: 74.92%\n",
      "loss: tf.Tensor(1.0625291, shape=(), dtype=float32) acc: tf.Tensor(0.74924195, shape=(), dtype=float32)\n",
      "Train time for epoch #35 (35 total steps): 2.610975980758667\n",
      "Model test set loss: 1.0794 accuracy: 75.21%\n",
      "loss: tf.Tensor(1.0794382, shape=(), dtype=float32) acc: tf.Tensor(0.7521355, shape=(), dtype=float32)\n",
      "Train time for epoch #36 (36 total steps): 2.385225296020508\n",
      "Model test set loss: 1.1138 accuracy: 75.50%\n",
      "loss: tf.Tensor(1.1137664, shape=(), dtype=float32) acc: tf.Tensor(0.75501144, shape=(), dtype=float32)\n",
      "Train time for epoch #37 (37 total steps): 2.5445396900177\n",
      "Model test set loss: 1.1351 accuracy: 75.77%\n",
      "loss: tf.Tensor(1.1350851, shape=(), dtype=float32) acc: tf.Tensor(0.757732, shape=(), dtype=float32)\n",
      "Train time for epoch #38 (38 total steps): 2.4364547729492188\n",
      "Model test set loss: 1.1286 accuracy: 76.02%\n",
      "loss: tf.Tensor(1.1285619, shape=(), dtype=float32) acc: tf.Tensor(0.7601736, shape=(), dtype=float32)\n",
      "Train time for epoch #39 (39 total steps): 2.409165859222412\n",
      "Model test set loss: 1.1520 accuracy: 76.24%\n",
      "loss: tf.Tensor(1.1520041, shape=(), dtype=float32) acc: tf.Tensor(0.7623579, shape=(), dtype=float32)\n",
      "Train time for epoch #40 (40 total steps): 2.4377641677856445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test set loss: 1.1649 accuracy: 76.48%\n",
      "loss: tf.Tensor(1.1648993, shape=(), dtype=float32) acc: tf.Tensor(0.76481956, shape=(), dtype=float32)\n",
      "Train time for epoch #41 (41 total steps): 2.6416828632354736\n",
      "Model test set loss: 1.1763 accuracy: 76.78%\n",
      "loss: tf.Tensor(1.176276, shape=(), dtype=float32) acc: tf.Tensor(0.7677898, shape=(), dtype=float32)\n",
      "Train time for epoch #42 (42 total steps): 2.386920928955078\n",
      "Model test set loss: 1.1638 accuracy: 77.05%\n",
      "loss: tf.Tensor(1.1638184, shape=(), dtype=float32) acc: tf.Tensor(0.77049583, shape=(), dtype=float32)\n",
      "Train time for epoch #43 (43 total steps): 2.3940248489379883\n",
      "Model test set loss: 1.1488 accuracy: 77.28%\n",
      "loss: tf.Tensor(1.1487575, shape=(), dtype=float32) acc: tf.Tensor(0.77283627, shape=(), dtype=float32)\n",
      "Train time for epoch #44 (44 total steps): 2.450796127319336\n",
      "Model test set loss: 1.1717 accuracy: 77.48%\n",
      "loss: tf.Tensor(1.1716943, shape=(), dtype=float32) acc: tf.Tensor(0.774836, shape=(), dtype=float32)\n",
      "Train time for epoch #45 (45 total steps): 2.6402039527893066\n",
      "Model test set loss: 1.1850 accuracy: 77.66%\n",
      "loss: tf.Tensor(1.184968, shape=(), dtype=float32) acc: tf.Tensor(0.7766323, shape=(), dtype=float32)\n",
      "Train time for epoch #46 (46 total steps): 2.434668779373169\n",
      "Model test set loss: 1.2111 accuracy: 77.86%\n",
      "loss: tf.Tensor(1.2110986, shape=(), dtype=float32) acc: tf.Tensor(0.77857465, shape=(), dtype=float32)\n",
      "Train time for epoch #47 (47 total steps): 2.412613868713379\n",
      "Model test set loss: 1.2191 accuracy: 78.03%\n",
      "loss: tf.Tensor(1.2191377, shape=(), dtype=float32) acc: tf.Tensor(0.78032464, shape=(), dtype=float32)\n",
      "Train time for epoch #48 (48 total steps): 2.492361068725586\n",
      "Model test set loss: 1.2485 accuracy: 78.20%\n",
      "loss: tf.Tensor(1.2484605, shape=(), dtype=float32) acc: tf.Tensor(0.78200173, shape=(), dtype=float32)\n",
      "Train time for epoch #49 (49 total steps): 2.454402208328247\n",
      "Model test set loss: 1.2619 accuracy: 78.34%\n",
      "loss: tf.Tensor(1.2618625, shape=(), dtype=float32) acc: tf.Tensor(0.78339994, shape=(), dtype=float32)\n",
      "Train time for epoch #50 (50 total steps): 2.7034378051757812\n",
      "Model test set loss: 1.2737 accuracy: 78.49%\n",
      "loss: tf.Tensor(1.2737477, shape=(), dtype=float32) acc: tf.Tensor(0.78494847, shape=(), dtype=float32)\n",
      "Train time for epoch #51 (51 total steps): 2.433444023132324\n",
      "Model test set loss: 1.2634 accuracy: 78.66%\n",
      "loss: tf.Tensor(1.263387, shape=(), dtype=float32) acc: tf.Tensor(0.7866384, shape=(), dtype=float32)\n",
      "Train time for epoch #52 (52 total steps): 2.4645450115203857\n",
      "Model test set loss: 1.2829 accuracy: 78.82%\n",
      "loss: tf.Tensor(1.2829279, shape=(), dtype=float32) acc: tf.Tensor(0.78816414, shape=(), dtype=float32)\n",
      "Train time for epoch #53 (53 total steps): 2.4166100025177\n",
      "Model test set loss: 1.2723 accuracy: 78.98%\n",
      "loss: tf.Tensor(1.2723227, shape=(), dtype=float32) acc: tf.Tensor(0.78982687, shape=(), dtype=float32)\n",
      "Train time for epoch #54 (54 total steps): 2.434346914291382\n",
      "Model test set loss: 1.2441 accuracy: 79.12%\n",
      "loss: tf.Tensor(1.2440925, shape=(), dtype=float32) acc: tf.Tensor(0.7912371, shape=(), dtype=float32)\n",
      "Train time for epoch #55 (55 total steps): 2.41682505607605\n",
      "Model test set loss: 1.2485 accuracy: 79.26%\n",
      "loss: tf.Tensor(1.2485285, shape=(), dtype=float32) acc: tf.Tensor(0.79259604, shape=(), dtype=float32)\n",
      "Train time for epoch #56 (56 total steps): 2.780202865600586\n",
      "Model test set loss: 1.2453 accuracy: 79.43%\n",
      "loss: tf.Tensor(1.245333, shape=(), dtype=float32) acc: tf.Tensor(0.7942747, shape=(), dtype=float32)\n",
      "Train time for epoch #57 (57 total steps): 2.985198736190796\n",
      "Model test set loss: 1.2497 accuracy: 79.57%\n",
      "loss: tf.Tensor(1.249737, shape=(), dtype=float32) acc: tf.Tensor(0.7957135, shape=(), dtype=float32)\n",
      "Train time for epoch #58 (58 total steps): 2.527465343475342\n",
      "Model test set loss: 1.2571 accuracy: 79.73%\n",
      "loss: tf.Tensor(1.2571156, shape=(), dtype=float32) acc: tf.Tensor(0.7972805, shape=(), dtype=float32)\n",
      "Train time for epoch #59 (59 total steps): 2.6539201736450195\n",
      "Model test set loss: 1.2549 accuracy: 79.89%\n",
      "loss: tf.Tensor(1.2548616, shape=(), dtype=float32) acc: tf.Tensor(0.7988817, shape=(), dtype=float32)\n",
      "Train time for epoch #60 (60 total steps): 2.449877977371216\n",
      "Model test set loss: 1.2386 accuracy: 80.01%\n",
      "loss: tf.Tensor(1.2386091, shape=(), dtype=float32) acc: tf.Tensor(0.8000859, shape=(), dtype=float32)\n",
      "Train time for epoch #61 (61 total steps): 2.431316375732422\n",
      "Model test set loss: 1.2301 accuracy: 80.13%\n",
      "loss: tf.Tensor(1.2301095, shape=(), dtype=float32) acc: tf.Tensor(0.80133516, shape=(), dtype=float32)\n",
      "Train time for epoch #62 (62 total steps): 2.392502784729004\n",
      "Model test set loss: 1.2194 accuracy: 80.26%\n",
      "loss: tf.Tensor(1.2194059, shape=(), dtype=float32) acc: tf.Tensor(0.8026272, shape=(), dtype=float32)\n",
      "Train time for epoch #63 (63 total steps): 2.5864450931549072\n",
      "Model test set loss: 1.2427 accuracy: 80.37%\n",
      "loss: tf.Tensor(1.2426636, shape=(), dtype=float32) acc: tf.Tensor(0.80371463, shape=(), dtype=float32)\n",
      "Train time for epoch #64 (64 total steps): 2.4522552490234375\n",
      "Model test set loss: 1.2699 accuracy: 80.48%\n",
      "loss: tf.Tensor(1.2698674, shape=(), dtype=float32) acc: tf.Tensor(0.804768, shape=(), dtype=float32)\n",
      "Train time for epoch #65 (65 total steps): 2.5344607830047607\n",
      "Model test set loss: 1.2756 accuracy: 80.56%\n",
      "loss: tf.Tensor(1.2755802, shape=(), dtype=float32) acc: tf.Tensor(0.80563045, shape=(), dtype=float32)\n",
      "Train time for epoch #66 (66 total steps): 2.799683094024658\n",
      "Model test set loss: 1.2897 accuracy: 80.67%\n",
      "loss: tf.Tensor(1.2897058, shape=(), dtype=float32) acc: tf.Tensor(0.806701, shape=(), dtype=float32)\n",
      "Train time for epoch #67 (67 total steps): 2.4755730628967285\n",
      "Model test set loss: 1.3269 accuracy: 80.77%\n",
      "loss: tf.Tensor(1.3268578, shape=(), dtype=float32) acc: tf.Tensor(0.8077397, shape=(), dtype=float32)\n",
      "Train time for epoch #68 (68 total steps): 2.733682870864868\n",
      "Model test set loss: 1.3498 accuracy: 80.89%\n",
      "loss: tf.Tensor(1.3498218, shape=(), dtype=float32) acc: tf.Tensor(0.80889934, shape=(), dtype=float32)\n",
      "Train time for epoch #69 (69 total steps): 2.973076820373535\n",
      "Model test set loss: 1.3576 accuracy: 80.98%\n",
      "loss: tf.Tensor(1.357635, shape=(), dtype=float32) acc: tf.Tensor(0.8098013, shape=(), dtype=float32)\n",
      "Train time for epoch #70 (70 total steps): 2.775324821472168\n",
      "Model test set loss: 1.3774 accuracy: 81.06%\n",
      "loss: tf.Tensor(1.3774337, shape=(), dtype=float32) acc: tf.Tensor(0.81060386, shape=(), dtype=float32)\n",
      "Train time for epoch #71 (71 total steps): 2.7744181156158447\n",
      "Model test set loss: 1.3799 accuracy: 81.15%\n",
      "loss: tf.Tensor(1.3798554, shape=(), dtype=float32) acc: tf.Tensor(0.8114564, shape=(), dtype=float32)\n",
      "Train time for epoch #72 (72 total steps): 2.3984367847442627\n",
      "Model test set loss: 1.3817 accuracy: 81.23%\n",
      "loss: tf.Tensor(1.3817451, shape=(), dtype=float32) acc: tf.Tensor(0.81228524, shape=(), dtype=float32)\n",
      "Train time for epoch #73 (73 total steps): 2.5480966567993164\n",
      "Model test set loss: 1.3602 accuracy: 81.31%\n",
      "loss: tf.Tensor(1.3602351, shape=(), dtype=float32) acc: tf.Tensor(0.8130914, shape=(), dtype=float32)\n",
      "Train time for epoch #74 (74 total steps): 3.5383641719818115\n",
      "Model test set loss: 1.3644 accuracy: 81.39%\n",
      "loss: tf.Tensor(1.3644105, shape=(), dtype=float32) acc: tf.Tensor(0.8139454, shape=(), dtype=float32)\n",
      "Train time for epoch #75 (75 total steps): 3.3302900791168213\n",
      "Model test set loss: 1.3561 accuracy: 81.46%\n",
      "loss: tf.Tensor(1.3561368, shape=(), dtype=float32) acc: tf.Tensor(0.81463915, shape=(), dtype=float32)\n",
      "Train time for epoch #76 (76 total steps): 2.679241895675659\n",
      "Model test set loss: 1.3568 accuracy: 81.55%\n",
      "loss: tf.Tensor(1.3567706, shape=(), dtype=float32) acc: tf.Tensor(0.8155182, shape=(), dtype=float32)\n",
      "Train time for epoch #77 (77 total steps): 2.7830610275268555\n",
      "Model test set loss: 1.4151 accuracy: 81.63%\n",
      "loss: tf.Tensor(1.4151301, shape=(), dtype=float32) acc: tf.Tensor(0.8163074, shape=(), dtype=float32)\n",
      "Train time for epoch #78 (78 total steps): 2.736495018005371\n",
      "Model test set loss: 1.4403 accuracy: 81.71%\n",
      "loss: tf.Tensor(1.4403119, shape=(), dtype=float32) acc: tf.Tensor(0.8170764, shape=(), dtype=float32)\n",
      "Train time for epoch #79 (79 total steps): 3.0035130977630615\n",
      "Model test set loss: 1.4485 accuracy: 81.79%\n",
      "loss: tf.Tensor(1.4484844, shape=(), dtype=float32) acc: tf.Tensor(0.8178912, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time for epoch #80 (80 total steps): 3.0494930744171143\n",
      "Model test set loss: 1.4541 accuracy: 81.88%\n",
      "loss: tf.Tensor(1.4540889, shape=(), dtype=float32) acc: tf.Tensor(0.81875, shape=(), dtype=float32)\n",
      "Train time for epoch #81 (81 total steps): 2.866715908050537\n",
      "Model test set loss: 1.4599 accuracy: 81.95%\n",
      "loss: tf.Tensor(1.4598786, shape=(), dtype=float32) acc: tf.Tensor(0.819524, shape=(), dtype=float32)\n",
      "Train time for epoch #82 (82 total steps): 2.8500380516052246\n",
      "Model test set loss: 1.4461 accuracy: 82.02%\n",
      "loss: tf.Tensor(1.4460534, shape=(), dtype=float32) acc: tf.Tensor(0.82015336, shape=(), dtype=float32)\n",
      "Train time for epoch #83 (83 total steps): 3.4102540016174316\n",
      "Model test set loss: 1.4381 accuracy: 82.08%\n",
      "loss: tf.Tensor(1.4380969, shape=(), dtype=float32) acc: tf.Tensor(0.8207676, shape=(), dtype=float32)\n",
      "Train time for epoch #84 (84 total steps): 2.620802164077759\n",
      "Model test set loss: 1.4330 accuracy: 82.15%\n",
      "loss: tf.Tensor(1.432991, shape=(), dtype=float32) acc: tf.Tensor(0.82148993, shape=(), dtype=float32)\n",
      "Train time for epoch #85 (85 total steps): 3.318679094314575\n",
      "Model test set loss: 1.4347 accuracy: 82.22%\n",
      "loss: tf.Tensor(1.4347012, shape=(), dtype=float32) acc: tf.Tensor(0.8221953, shape=(), dtype=float32)\n",
      "Train time for epoch #86 (86 total steps): 2.906606912612915\n",
      "Model test set loss: 1.4476 accuracy: 82.26%\n",
      "loss: tf.Tensor(1.4476073, shape=(), dtype=float32) acc: tf.Tensor(0.8226445, shape=(), dtype=float32)\n",
      "Train time for epoch #87 (87 total steps): 2.879629135131836\n",
      "Model test set loss: 1.4526 accuracy: 82.33%\n",
      "loss: tf.Tensor(1.452632, shape=(), dtype=float32) acc: tf.Tensor(0.823261, shape=(), dtype=float32)\n",
      "Train time for epoch #88 (88 total steps): 2.9516711235046387\n",
      "Model test set loss: 1.4527 accuracy: 82.38%\n",
      "loss: tf.Tensor(1.4527076, shape=(), dtype=float32) acc: tf.Tensor(0.82380503, shape=(), dtype=float32)\n",
      "Train time for epoch #89 (89 total steps): 2.7350919246673584\n",
      "Model test set loss: 1.4578 accuracy: 82.45%\n",
      "loss: tf.Tensor(1.4577897, shape=(), dtype=float32) acc: tf.Tensor(0.8245106, shape=(), dtype=float32)\n",
      "Train time for epoch #90 (90 total steps): 4.056103944778442\n",
      "Model test set loss: 1.4703 accuracy: 82.52%\n",
      "loss: tf.Tensor(1.4702631, shape=(), dtype=float32) acc: tf.Tensor(0.82520044, shape=(), dtype=float32)\n",
      "Train time for epoch #91 (91 total steps): 2.6202380657196045\n",
      "Model test set loss: 1.4883 accuracy: 82.59%\n",
      "loss: tf.Tensor(1.4882505, shape=(), dtype=float32) acc: tf.Tensor(0.82587516, shape=(), dtype=float32)\n",
      "Train time for epoch #92 (92 total steps): 2.8710811138153076\n",
      "Model test set loss: 1.5082 accuracy: 82.65%\n",
      "loss: tf.Tensor(1.5081658, shape=(), dtype=float32) acc: tf.Tensor(0.82653517, shape=(), dtype=float32)\n",
      "Train time for epoch #93 (93 total steps): 3.1672840118408203\n",
      "Model test set loss: 1.5053 accuracy: 82.71%\n",
      "loss: tf.Tensor(1.5052917, shape=(), dtype=float32) acc: tf.Tensor(0.8271256, shape=(), dtype=float32)\n",
      "Train time for epoch #94 (94 total steps): 3.4004287719726562\n",
      "Model test set loss: 1.4939 accuracy: 82.77%\n",
      "loss: tf.Tensor(1.4938763, shape=(), dtype=float32) acc: tf.Tensor(0.8277034, shape=(), dtype=float32)\n",
      "Train time for epoch #95 (95 total steps): 3.164102077484131\n",
      "Model test set loss: 1.4930 accuracy: 82.83%\n",
      "loss: tf.Tensor(1.492995, shape=(), dtype=float32) acc: tf.Tensor(0.82832336, shape=(), dtype=float32)\n",
      "Train time for epoch #96 (96 total steps): 2.936692953109741\n",
      "Model test set loss: 1.4705 accuracy: 82.88%\n",
      "loss: tf.Tensor(1.4704503, shape=(), dtype=float32) acc: tf.Tensor(0.8287693, shape=(), dtype=float32)\n",
      "Train time for epoch #97 (97 total steps): 2.4902989864349365\n",
      "Model test set loss: 1.4795 accuracy: 82.93%\n",
      "loss: tf.Tensor(1.4795153, shape=(), dtype=float32) acc: tf.Tensor(0.8292592, shape=(), dtype=float32)\n",
      "Train time for epoch #98 (98 total steps): 2.4856958389282227\n",
      "Model test set loss: 1.4999 accuracy: 82.96%\n",
      "loss: tf.Tensor(1.4998505, shape=(), dtype=float32) acc: tf.Tensor(0.8296339, shape=(), dtype=float32)\n",
      "Train time for epoch #99 (99 total steps): 2.5312278270721436\n",
      "Model test set loss: 1.5228 accuracy: 83.03%\n",
      "loss: tf.Tensor(1.5227927, shape=(), dtype=float32) acc: tf.Tensor(0.83026135, shape=(), dtype=float32)\n",
      "Train time for epoch #100 (100 total steps): 2.549802780151367\n",
      "Model test set loss: 1.5397 accuracy: 83.08%\n",
      "loss: tf.Tensor(1.5397282, shape=(), dtype=float32) acc: tf.Tensor(0.83082473, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_EPOCHS = 100\n",
    "\n",
    "for i in range(NUM_TRAIN_EPOCHS):\n",
    "    start = time.time()\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((trainX, trainy))\n",
    "    train_ds = train_ds.shuffle(200).batch(100)\n",
    "    #   with train_summary_writer.as_default():\n",
    "    train(CNN_model, optimizer, train_ds, log_freq=500)\n",
    "    end = time.time()\n",
    "    print('Train time for epoch #{} ({} total steps): {}'.format(\n",
    "        i + 1, int(optimizer.iterations), end - start))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((testX, testy))\n",
    "    test_ds = test_ds.batch(80)\n",
    "    test(CNN_model, test_ds, optimizer.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.save('CNN_model_covid_pneumonia_normal.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet \n",
    "\n",
    "Here we train a tf.keras implementation of ResNet-18\n",
    "\n",
    "Includes cell dividers for running with IPython!\n",
    "\n",
    "![](resnet.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(channels, stride=1, kernel=(3, 3)):\n",
    "    return keras.layers.Conv2D(channels, kernel, strides=stride, padding='same',\n",
    "                               use_bias=False,\n",
    "                            kernel_initializer=tf.random_normal_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(keras.Model):\n",
    "\n",
    "    def __init__(self, channels, strides=1, residual_path=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.residual_path = residual_path\n",
    "\n",
    "        self.conv1 = conv3x3(channels, strides)\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = conv3x3(channels)\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "\n",
    "        if residual_path:\n",
    "            self.down_conv = conv3x3(channels, strides, kernel=(1, 1))\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.bn1(inputs, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # this module can be added into self.\n",
    "        # however, module in for can not be added.\n",
    "        if self.residual_path:\n",
    "            residual = self.down_bn(inputs, training=training)\n",
    "            residual = tf.nn.relu(residual)\n",
    "            residual = self.down_conv(residual)\n",
    "\n",
    "        x = x + residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(keras.Model):\n",
    "\n",
    "    def __init__(self, block_list, num_classes, initial_filters=16, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_blocks = len(block_list)\n",
    "        self.block_list = block_list\n",
    "\n",
    "        self.in_channels = initial_filters\n",
    "        self.out_channels = initial_filters\n",
    "        self.conv_initial = conv3x3(self.out_channels)\n",
    "\n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "\n",
    "        # build all the blocks\n",
    "        for block_id in range(len(block_list)):\n",
    "            for layer_id in range(block_list[block_id]):\n",
    "\n",
    "                if block_id != 0 and layer_id == 0:\n",
    "                    block = ResnetBlock(self.out_channels, strides=2, residual_path=True)\n",
    "                else:\n",
    "                    if self.in_channels != self.out_channels:\n",
    "                        residual_path = True\n",
    "                    else:\n",
    "                        residual_path = False\n",
    "                    block = ResnetBlock(self.out_channels, residual_path=residual_path)\n",
    "\n",
    "                self.in_channels = self.out_channels\n",
    "\n",
    "                self.blocks.add(block)\n",
    "\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.final_bn = keras.layers.BatchNormalization()\n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        out = self.conv_initial(inputs)\n",
    "\n",
    "        out = self.blocks(out, training=training)\n",
    "\n",
    "        out = self.final_bn(out, training=training)\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables in the model : 77\n",
      "Model: \"res_net_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           multiple                  432       \n",
      "_________________________________________________________________\n",
      "dynamic-blocks (Sequential)  multiple                  174848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  195       \n",
      "=================================================================\n",
      "Total params: 175,731\n",
      "Trainable params: 174,707\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Train on 97 samples, validate on 97 samples\n",
      "Epoch 1/50\n",
      "97/97 [==============================] - 58s 595ms/sample - loss: 1.1594 - accuracy: 0.1649 - val_loss: 2.2890 - val_accuracy: 0.3505\n",
      "Epoch 2/50\n",
      "97/97 [==============================] - 48s 498ms/sample - loss: 0.5931 - accuracy: 0.9175 - val_loss: 1.6414 - val_accuracy: 0.4124\n",
      "Epoch 3/50\n",
      "97/97 [==============================] - 41s 424ms/sample - loss: 0.4199 - accuracy: 0.9381 - val_loss: 1.0039 - val_accuracy: 0.5155\n",
      "Epoch 4/50\n",
      "97/97 [==============================] - 34s 353ms/sample - loss: 0.3247 - accuracy: 0.9588 - val_loss: 3.7101 - val_accuracy: 0.4124\n",
      "Epoch 5/50\n",
      "97/97 [==============================] - 38s 391ms/sample - loss: 0.2716 - accuracy: 0.9691 - val_loss: 1.3730 - val_accuracy: 0.5979\n",
      "Epoch 6/50\n",
      "97/97 [==============================] - 34s 354ms/sample - loss: 0.2356 - accuracy: 0.9588 - val_loss: 1.7647 - val_accuracy: 0.5979\n",
      "Epoch 7/50\n",
      "97/97 [==============================] - 44s 457ms/sample - loss: 0.2321 - accuracy: 0.9588 - val_loss: 5.3191 - val_accuracy: 0.4124\n",
      "Epoch 8/50\n",
      "97/97 [==============================] - 47s 481ms/sample - loss: 0.2263 - accuracy: 0.9588 - val_loss: 5.4688 - val_accuracy: 0.4124\n",
      "Epoch 9/50\n",
      "97/97 [==============================] - 48s 490ms/sample - loss: 0.2056 - accuracy: 0.9691 - val_loss: 5.7386 - val_accuracy: 0.4124\n",
      "Epoch 10/50\n",
      "97/97 [==============================] - 109s 1s/sample - loss: 0.2179 - accuracy: 0.9485 - val_loss: 5.2195 - val_accuracy: 0.4124\n",
      "Epoch 11/50\n",
      "97/97 [==============================] - 135s 1s/sample - loss: 0.1762 - accuracy: 0.9794 - val_loss: 5.0835 - val_accuracy: 0.4124\n",
      "Epoch 12/50\n",
      "97/97 [==============================] - 104s 1s/sample - loss: 0.1863 - accuracy: 0.9691 - val_loss: 0.6983 - val_accuracy: 0.6907\n",
      "Epoch 13/50\n",
      "97/97 [==============================] - 48s 494ms/sample - loss: 0.2225 - accuracy: 0.9278 - val_loss: 4.5045 - val_accuracy: 0.4124\n",
      "Epoch 14/50\n",
      "97/97 [==============================] - 50s 512ms/sample - loss: 0.1699 - accuracy: 0.9794 - val_loss: 7.0769 - val_accuracy: 0.4124\n",
      "Epoch 15/50\n",
      "97/97 [==============================] - 48s 493ms/sample - loss: 0.1653 - accuracy: 0.9588 - val_loss: 7.5440 - val_accuracy: 0.4124\n",
      "Epoch 16/50\n",
      "97/97 [==============================] - 50s 516ms/sample - loss: 0.1676 - accuracy: 0.9691 - val_loss: 8.0227 - val_accuracy: 0.4124\n",
      "Epoch 17/50\n",
      "97/97 [==============================] - 48s 500ms/sample - loss: 0.1268 - accuracy: 0.9794 - val_loss: 6.2311 - val_accuracy: 0.4124\n",
      "Epoch 18/50\n",
      "97/97 [==============================] - 48s 492ms/sample - loss: 0.1581 - accuracy: 0.9691 - val_loss: 7.6678 - val_accuracy: 0.4124\n",
      "Epoch 19/50\n",
      "97/97 [==============================] - 57s 590ms/sample - loss: 0.1269 - accuracy: 1.0000 - val_loss: 7.8147 - val_accuracy: 0.4124\n",
      "Epoch 20/50\n",
      "97/97 [==============================] - 64s 659ms/sample - loss: 0.1129 - accuracy: 0.9897 - val_loss: 5.6526 - val_accuracy: 0.4124\n",
      "Epoch 21/50\n",
      "97/97 [==============================] - 61s 625ms/sample - loss: 0.1241 - accuracy: 0.9691 - val_loss: 3.0818 - val_accuracy: 0.4124\n",
      "Epoch 22/50\n",
      "97/97 [==============================] - 64s 655ms/sample - loss: 0.1159 - accuracy: 0.9794 - val_loss: 3.6200 - val_accuracy: 0.4124\n",
      "Epoch 23/50\n",
      "97/97 [==============================] - 58s 601ms/sample - loss: 0.1175 - accuracy: 0.9794 - val_loss: 0.6315 - val_accuracy: 0.7113\n",
      "Epoch 24/50\n",
      "97/97 [==============================] - 46s 474ms/sample - loss: 0.1358 - accuracy: 0.9794 - val_loss: 7.0876 - val_accuracy: 0.4124\n",
      "Epoch 25/50\n",
      "97/97 [==============================] - 47s 489ms/sample - loss: 0.1177 - accuracy: 0.9794 - val_loss: 7.1706 - val_accuracy: 0.4124\n",
      "Epoch 26/50\n",
      "97/97 [==============================] - 46s 470ms/sample - loss: 0.1005 - accuracy: 0.9897 - val_loss: 3.9177 - val_accuracy: 0.4124\n",
      "Epoch 27/50\n",
      "97/97 [==============================] - 47s 490ms/sample - loss: 0.1119 - accuracy: 0.9794 - val_loss: 1.9832 - val_accuracy: 0.4124\n",
      "Epoch 28/50\n",
      "97/97 [==============================] - 46s 476ms/sample - loss: 0.1287 - accuracy: 0.9691 - val_loss: 1.0113 - val_accuracy: 0.6289\n",
      "Epoch 29/50\n",
      "97/97 [==============================] - 48s 495ms/sample - loss: 0.1146 - accuracy: 0.9588 - val_loss: 1.4034 - val_accuracy: 0.5876\n",
      "Epoch 30/50\n",
      "97/97 [==============================] - 30s 304ms/sample - loss: 0.1083 - accuracy: 0.9691 - val_loss: 1.1662 - val_accuracy: 0.6186\n",
      "Epoch 31/50\n",
      "97/97 [==============================] - 30s 309ms/sample - loss: 0.1050 - accuracy: 0.9794 - val_loss: 4.5279 - val_accuracy: 0.4124\n",
      "Epoch 32/50\n",
      "97/97 [==============================] - 33s 342ms/sample - loss: 0.0949 - accuracy: 0.9897 - val_loss: 5.8790 - val_accuracy: 0.4124\n",
      "Epoch 33/50\n",
      "97/97 [==============================] - 38s 394ms/sample - loss: 0.0961 - accuracy: 1.0000 - val_loss: 5.8315 - val_accuracy: 0.4124\n",
      "Epoch 34/50\n",
      "97/97 [==============================] - 43s 442ms/sample - loss: 0.1505 - accuracy: 0.9691 - val_loss: 5.2365 - val_accuracy: 0.4124\n",
      "Epoch 35/50\n",
      "97/97 [==============================] - 84s 865ms/sample - loss: 0.1029 - accuracy: 0.9897 - val_loss: 3.1641 - val_accuracy: 0.4433\n",
      "Epoch 36/50\n",
      "97/97 [==============================] - 60s 622ms/sample - loss: 0.1114 - accuracy: 0.9794 - val_loss: 2.2622 - val_accuracy: 0.5052\n",
      "Epoch 37/50\n",
      "97/97 [==============================] - 59s 613ms/sample - loss: 0.1163 - accuracy: 0.9588 - val_loss: 2.6727 - val_accuracy: 0.4227\n",
      "Epoch 38/50\n",
      "97/97 [==============================] - 77s 798ms/sample - loss: 0.1009 - accuracy: 0.9794 - val_loss: 3.0126 - val_accuracy: 0.4124\n",
      "Epoch 39/50\n",
      "97/97 [==============================] - 60s 619ms/sample - loss: 0.0955 - accuracy: 0.9794 - val_loss: 2.0220 - val_accuracy: 0.4124\n",
      "Epoch 40/50\n",
      "97/97 [==============================] - 59s 609ms/sample - loss: 0.1213 - accuracy: 0.9691 - val_loss: 0.8602 - val_accuracy: 0.6289\n",
      "Epoch 41/50\n",
      "97/97 [==============================] - 78s 799ms/sample - loss: 0.0874 - accuracy: 0.9794 - val_loss: 0.8326 - val_accuracy: 0.4433\n",
      "Epoch 42/50\n",
      "97/97 [==============================] - 61s 628ms/sample - loss: 0.0763 - accuracy: 0.9897 - val_loss: 2.5476 - val_accuracy: 0.4124\n",
      "Epoch 43/50\n",
      "97/97 [==============================] - 59s 606ms/sample - loss: 0.1136 - accuracy: 0.9897 - val_loss: 0.7979 - val_accuracy: 0.6289\n",
      "Epoch 44/50\n",
      "97/97 [==============================] - 82s 847ms/sample - loss: 0.0687 - accuracy: 0.9897 - val_loss: 0.3932 - val_accuracy: 0.8144\n",
      "Epoch 45/50\n",
      "97/97 [==============================] - 61s 624ms/sample - loss: 0.0910 - accuracy: 0.9691 - val_loss: 0.2949 - val_accuracy: 0.9072\n",
      "Epoch 46/50\n",
      "97/97 [==============================] - 60s 615ms/sample - loss: 0.0944 - accuracy: 0.9897 - val_loss: 0.3239 - val_accuracy: 0.8557\n",
      "Epoch 47/50\n",
      "97/97 [==============================] - 65s 675ms/sample - loss: 0.0734 - accuracy: 1.0000 - val_loss: 3.3354 - val_accuracy: 0.5979\n",
      "Epoch 48/50\n",
      "97/97 [==============================] - 50s 519ms/sample - loss: 0.0989 - accuracy: 0.9897 - val_loss: 3.5050 - val_accuracy: 0.5979\n",
      "Epoch 49/50\n",
      "97/97 [==============================] - 53s 548ms/sample - loss: 0.0928 - accuracy: 1.0000 - val_loss: 1.2151 - val_accuracy: 0.7010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "97/97 [==============================] - 52s 538ms/sample - loss: 0.1131 - accuracy: 0.9897 - val_loss: 0.3000 - val_accuracy: 0.8969\n",
      "97/1 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 10s 108ms/sample - loss: 0.3297 - accuracy: 0.8969\n",
      "Final test loss and accuracy : [0.2999743601096045, 0.8969072]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# build model and optimizer\n",
    "ResNet_model = ResNet([2, 2, 2], num_classes)\n",
    "ResNet_model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "ResNet_model.build(input_shape=(None, 200,200,3))\n",
    "print(\"Number of variables in the model :\", len(ResNet_model.variables))\n",
    "ResNet_model.summary()\n",
    "\n",
    "y_ohe = tf.one_hot(trainy, depth=3).numpy()\n",
    "testy_ohe = tf.one_hot(testy, depth=3).numpy()\n",
    "\n",
    "# train\n",
    "ResNet_model.fit(trainX, y_ohe, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(testX, testy_ohe), verbose=1)\n",
    "\n",
    "# evaluate on test set\n",
    "scores = ResNet_model.evaluate(testX, testy_ohe, batch_size, verbose=1)\n",
    "print(\"Final test loss and accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Network\n",
    "\n",
    "Here we train a tf.keras implementation of InceptionV3\n",
    "\n",
    "\n",
    "![](inception.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(keras.Model):\n",
    "    \n",
    "    def __init__(self, ch, kernelsz=3, strides=1, padding='same'):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        \n",
    "        self.model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(ch, kernelsz, strides=strides, padding=padding),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU()\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        x = self.model(x, training=training)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlk(keras.Model):\n",
    "    \n",
    "    def __init__(self, ch, strides=1):\n",
    "        super(InceptionBlk, self).__init__()\n",
    "        \n",
    "        self.ch = ch\n",
    "        self.strides = strides\n",
    "        \n",
    "        self.conv1 = ConvBNRelu(ch, strides=strides)\n",
    "        self.conv2 = ConvBNRelu(ch, kernelsz=3, strides=strides)\n",
    "        self.conv3_1 = ConvBNRelu(ch, kernelsz=3, strides=strides)\n",
    "        self.conv3_2 = ConvBNRelu(ch, kernelsz=3, strides=1)\n",
    "        \n",
    "        self.pool = keras.layers.MaxPooling2D(3, strides=1, padding='same')\n",
    "        self.pool_conv = ConvBNRelu(ch, strides=strides)\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        \n",
    "        x1 = self.conv1(x, training=training)\n",
    "\n",
    "        x2 = self.conv2(x, training=training)\n",
    "                \n",
    "        x3_1 = self.conv3_1(x, training=training)\n",
    "        x3_2 = self.conv3_2(x3_1, training=training)\n",
    "                \n",
    "        x4 = self.pool(x)\n",
    "        x4 = self.pool_conv(x4, training=training)\n",
    "        \n",
    "        # concat along axis=channel\n",
    "        x = tf.concat([x1, x2, x3_2, x4], axis=3)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(keras.Model):\n",
    "    \n",
    "    def __init__(self, num_layers, num_classes, init_ch=16, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        \n",
    "        self.in_channels = init_ch\n",
    "        self.out_channels = init_ch\n",
    "        self.num_layers = num_layers\n",
    "        self.init_ch = init_ch\n",
    "        \n",
    "        self.conv1 = ConvBNRelu(init_ch)\n",
    "        \n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "        \n",
    "        for block_id in range(num_layers):\n",
    "            \n",
    "            for layer_id in range(2):\n",
    "                \n",
    "                if layer_id == 0:\n",
    "                    \n",
    "                    block = InceptionBlk(self.out_channels, strides=2)\n",
    "                    \n",
    "                else:\n",
    "                    block = InceptionBlk(self.out_channels, strides=1)\n",
    "                    \n",
    "                self.blocks.add(block)\n",
    "            \n",
    "            # enlarger out_channels per block    \n",
    "            self.out_channels *= 2\n",
    "            \n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "        \n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        out = self.conv1(x, training=training)\n",
    "        \n",
    "        out = self.blocks(out, training=training)\n",
    "        \n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_relu_42 (ConvBNRelu) multiple                  512       \n",
      "_________________________________________________________________\n",
      "dynamic-blocks (Sequential)  multiple                  292704    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  387       \n",
      "=================================================================\n",
      "Total params: 293,603\n",
      "Trainable params: 292,611\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "0 0 loss: 4.1779428\n",
      "0 evaluation acc: 0.3265306\n",
      "1 0 loss: 43.183533\n",
      "1 evaluation acc: 0.34013605\n",
      "2 0 loss: 20.469946\n",
      "2 evaluation acc: 0.3265306\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-61951ed3c396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# print(x.shape, y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# [b, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInception_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# [b] vs [b, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-6b98db3ffd01>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-720f42375c48>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx3_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   3813\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3815\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5641\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5642\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ksize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5643\u001b[0;31m         \"strides\", strides, \"padding\", padding, \"data_format\", data_format)\n\u001b[0m\u001b[1;32m   5644\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build model and optimizer\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "Inception_model = Inception(2, 3)\n",
    "# derive input shape for every layers.\n",
    "Inception_model.build(input_shape=(None, 200, 200, 3))\n",
    "Inception_model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "acc_meter = keras.metrics.Accuracy()\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((trainX, trainy)).batch(256)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(256)\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    for step, (x, y) in enumerate(db_train):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # print(x.shape, y.shape)\n",
    "            # [b, 10]\n",
    "            logits = Inception_model(x)\n",
    "            # [b] vs [b, 10]\n",
    "            loss = criteon(tf.one_hot(y, depth=3), logits)\n",
    "\n",
    "        grads = tape.gradient(loss, Inception_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, Inception_model.trainable_variables))\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(epoch, step, 'loss:', loss.numpy())\n",
    "\n",
    "\n",
    "    acc_meter.reset_states()\n",
    "    for x, y in db_test:\n",
    "        # [b, 10]\n",
    "        logits = Inception_model(x, training=False)\n",
    "        # [b, 10] => [b]\n",
    "        pred = tf.argmax(logits, axis=1)\n",
    "        # [b] vs [b, 10]\n",
    "        acc_meter.update_state(y, pred)\n",
    "\n",
    "    print(epoch, 'evaluation acc:', acc_meter.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16\n",
    "\n",
    "Fitting a VGG-16 network for image classification!\n",
    "We use gradient clipping for faster convergence.\n",
    "\n",
    "A complete implementation of VGG-16 is available in network.py\n",
    "\n",
    "![](vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(models.Model):\n",
    "\n",
    "\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_shape: [32, 32, 3]\n",
    "        \"\"\"\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        weight_decay = 0.000\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=input_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(self.num_classes))\n",
    "        # model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 0.9745582342147827 acc: 0.5154639\n",
      "test acc: 0.48453608\n",
      "1 0 loss: 1.7481777667999268 acc: 0.48453608\n",
      "test acc: 0.5154639\n",
      "2 0 loss: 3.1571853160858154 acc: 0.5154639\n",
      "test acc: 0.5154639\n",
      "3 0 loss: 0.7141163349151611 acc: 0.5154639\n",
      "test acc: 0.48453608\n",
      "4 0 loss: 0.8749623894691467 acc: 0.48453608\n",
      "test acc: 0.48453608\n",
      "5 0 loss: 0.6982256174087524 acc: 0.48453608\n",
      "test acc: 0.9587629\n",
      "6 0 loss: 0.6503109335899353 acc: 0.91752577\n",
      "test acc: 0.5154639\n",
      "7 0 loss: 0.638228178024292 acc: 0.5154639\n",
      "test acc: 0.5463917\n",
      "8 0 loss: 0.6018865704536438 acc: 0.57731956\n",
      "test acc: 0.9484536\n",
      "9 0 loss: 0.5470068454742432 acc: 0.92783505\n",
      "test acc: 0.8969072\n",
      "10 0 loss: 0.4932529330253601 acc: 0.8556701\n",
      "test acc: 0.96907216\n",
      "11 0 loss: 0.42065703868865967 acc: 0.92783505\n",
      "test acc: 0.9072165\n",
      "12 0 loss: 0.33522695302963257 acc: 0.88659793\n",
      "test acc: 0.96907216\n",
      "13 0 loss: 0.29068467020988464 acc: 0.92783505\n",
      "test acc: 0.6494845\n",
      "14 0 loss: 0.5618012547492981 acc: 0.77319586\n",
      "test acc: 0.92783505\n",
      "15 0 loss: 0.30020034313201904 acc: 0.88659793\n",
      "test acc: 0.96907216\n",
      "16 0 loss: 0.17935428023338318 acc: 0.9381443\n",
      "test acc: 0.8969072\n",
      "17 0 loss: 0.2619474232196808 acc: 0.87628865\n",
      "test acc: 0.9381443\n",
      "18 0 loss: 0.15872348845005035 acc: 0.92783505\n",
      "test acc: 0.96907216\n",
      "19 0 loss: 0.22378338873386383 acc: 0.92783505\n",
      "test acc: 0.9381443\n",
      "20 0 loss: 0.14262445271015167 acc: 0.92783505\n",
      "test acc: 0.9072165\n",
      "21 0 loss: 0.18796557188034058 acc: 0.8969072\n",
      "test acc: 0.96907216\n",
      "22 0 loss: 0.12150432169437408 acc: 0.9484536\n",
      "test acc: 0.96907216\n",
      "23 0 loss: 0.15531694889068604 acc: 0.9484536\n",
      "test acc: 0.97938144\n",
      "24 0 loss: 0.10504267364740372 acc: 0.96907216\n",
      "test acc: 0.91752577\n",
      "25 0 loss: 0.12226937711238861 acc: 0.9072165\n",
      "test acc: 0.9587629\n",
      "26 0 loss: 0.09105135500431061 acc: 0.9587629\n",
      "test acc: 0.9896907\n",
      "27 0 loss: 0.09310174733400345 acc: 0.96907216\n",
      "test acc: 0.9896907\n",
      "28 0 loss: 0.08286035060882568 acc: 0.96907216\n",
      "test acc: 0.96907216\n",
      "29 0 loss: 0.06797134131193161 acc: 0.97938144\n",
      "test acc: 0.9484536\n",
      "30 0 loss: 0.07212120294570923 acc: 0.97938144\n",
      "test acc: 0.9896907\n",
      "31 0 loss: 0.05477986857295036 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "32 0 loss: 0.06098289415240288 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "33 0 loss: 0.041973602026700974 acc: 0.9896907\n",
      "test acc: 0.9484536\n",
      "34 0 loss: 0.05164438486099243 acc: 0.97938144\n",
      "test acc: 0.9896907\n",
      "35 0 loss: 0.03312492370605469 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "36 0 loss: 0.036533817648887634 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "37 0 loss: 0.027447525411844254 acc: 0.9896907\n",
      "test acc: 0.96907216\n",
      "38 0 loss: 0.02340869791805744 acc: 1.0\n",
      "test acc: 0.96907216\n",
      "39 0 loss: 0.01995350420475006 acc: 1.0\n",
      "test acc: 0.9896907\n",
      "40 0 loss: 0.015142695978283882 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "41 0 loss: 0.014868722297251225 acc: 0.9896907\n",
      "test acc: 0.9896907\n",
      "42 0 loss: 0.008015262894332409 acc: 1.0\n",
      "test acc: 0.97938144\n",
      "43 0 loss: 0.00993889756500721 acc: 1.0\n",
      "test acc: 0.9896907\n",
      "44 0 loss: 0.005243384744971991 acc: 1.0\n",
      "test acc: 0.9896907\n",
      "45 0 loss: 0.004455625545233488 acc: 1.0\n",
      "test acc: 0.9896907\n",
      "46 0 loss: 0.004730228800326586 acc: 1.0\n",
      "test acc: 0.9896907\n",
      "47 0 loss: 0.002581997076049447 acc: 1.0\n",
      "test acc: 0.9896907\n",
      "48 0 loss: 0.001831352710723877 acc: 1.0\n",
      "test acc: 0.97938144\n",
      "49 0 loss: 0.002289147349074483 acc: 1.0\n",
      "test acc: 0.97938144\n",
      "50 0 loss: 0.0017067258013412356 acc: 1.0\n",
      "test acc: 0.9896907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1b478ad64bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVGG16_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# MUST clip gradient here or it will disconverge!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    604\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    607\u001b[0m   ]\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VGG16_model = VGG16([200, 200, 3], 3)\n",
    "\n",
    "\n",
    "# must specify from_logits=True!\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices((trainX, trainy)).batch(256)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(256)\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    for step, (x, y) in enumerate(db_train):\n",
    "        # [b, 1] => [b]\n",
    "        # y = tf.squeeze(y, axis=1)\n",
    "        # [b, 10]\n",
    "        y = tf.one_hot(y, depth=3)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = VGG16_model(x)\n",
    "            loss = criteon(y, logits)\n",
    "            # loss2 = compute_loss(logits, tf.argmax(y, axis=1))\n",
    "            # mse_loss = tf.reduce_sum(tf.square(y-logits))\n",
    "            # print(y.shape, logits.shape)\n",
    "            metric.update_state(y, logits)\n",
    "\n",
    "        grads = tape.gradient(loss, VGG16_model.trainable_variables)\n",
    "        # MUST clip gradient here or it will disconverge!\n",
    "        grads = [ tf.clip_by_norm(g, 15) for g in grads]\n",
    "        optimizer.apply_gradients(zip(grads, VGG16_model.trainable_variables))\n",
    "\n",
    "        if step % 40 == 0:\n",
    "            # for g in grads:\n",
    "            #     print(tf.norm(g).numpy())\n",
    "            print(epoch, step, 'loss:', float(loss), 'acc:', metric.result().numpy())\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "\n",
    "        metric = keras.metrics.CategoricalAccuracy()\n",
    "        for x, y in db_test:\n",
    "            # [b, 1] => [b]\n",
    "            # y = tf.squeeze(y, axis=1)\n",
    "            # [b, 10]\n",
    "            y = tf.one_hot(y, depth=3)\n",
    "\n",
    "            logits = VGG16_model.predict(x)\n",
    "            # be careful, these functions can accept y as [b] without warnning.\n",
    "            metric.update_state(y, logits)\n",
    "        print('test acc:', metric.result().numpy())\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VGG16_Model_Covid_Normal/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(VGG16_model,'VGG16_Model_Covid_Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
